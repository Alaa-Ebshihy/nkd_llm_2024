{
  "paper_id": "1512.03385",
  "sections": [
    {
      "section_name": "Abstract",
      "selected_sentences": [
        {
          "par_id": 0,
          "sentences": [
            {
              "sent": "Deeper neural networks are more difficult to train.",
              "tag": "Claim"
            },
            {
              "sent": "We present a residual learning framework to ease the training of networks that are substantially deeper than those used previously.",
              "tag": "Claim"
            },
            {
              "sent": "We explicitly reformulate the layers as learning residual functions with reference to the layer inputs, instead of learning unreferenced functions.",
              "tag": "Method"
            },
            {
              "sent": "We provide comprehensive empirical evidence showing that these residual networks are easier to optimize, and can gain accuracy from considerably increased depth.",
              "tag": "Method"
            },
            {
              "sent": "On the ImageNet dataset we evaluate residual nets with a depth of up to 152 layers-8\u00d7 deeper than VGG nets [41] but still having lower complexity.",
              "tag": "Method"
            },
            {
              "sent": "An ensemble of these residual nets achieves 3.57% error on the ImageNet test set.",
              "tag": "Result"
            },
            {
              "sent": "This result won the 1st place on the ILSVRC 2015 classification task.",
              "tag": "Method"
            },
            {
              "sent": "We also present analysis on CIFAR-10 with 100 and 1000 layers.",
              "tag": "Method"
            },
            {
              "sent": "The depth of representations is of central importance for many visual recognition tasks.",
              "tag": "Result"
            },
            {
              "sent": "Solely due to our extremely deep representations, we obtain a 28% relative improvement on the COCO object detection dataset.",
              "tag": "Method"
            },
            {
              "sent": "Deep residual nets are foundations of our submissions to ILSVRC & COCO 2015 competitions 1 , where we also won the 1st places on the tasks of ImageNet detection, ImageNet localization, COCO detection, and COCO segmentation.",
              "tag": "Method"
            }
          ]
        }
      ]
    },
    {
      "section_name": "Introduction",
      "selected_sentences": [
        {
          "par_id": 3,
          "sentences": [
            {
              "sent": "Deep convolutional neural networks [22,21] have led to a series of breakthroughs for image classification [21,50,40].",
              "tag": "Claim"
            },
            {
              "sent": "Deep networks naturally integrate low/mid/highlevel features [50] and classifiers in an end-to-end multilayer fashion, and the \"levels\" of features can be enriched by the number of stacked layers (depth).",
              "tag": "Claim"
            },
            {
              "sent": "Recent evidence [41,44] reveals that network depth is of crucial importance, and the leading results [41,44,13,16] on the challenging ImageNet dataset [36] all exploit \"very deep\" [41] models, with a depth of sixteen [41] to thirty [16].",
              "tag": "Claim"
            },
            {
              "sent": "Many other nontrivial visual recognition tasks [8,12,7,32,27] have also 1 http://image-net.org/challenges/LSVRC/2015/ greatly benefited from very deep models.",
              "tag": "Claim"
            }
          ]
        },
        {
          "par_id": 5,
          "sentences": [
            {
              "sent": "When deeper networks are able to start converging, a degradation problem has been exposed: with the network depth increasing, accuracy gets saturated (which might be unsurprising) and then degrades rapidly.",
              "tag": "Claim"
            },
            {
              "sent": "Unexpectedly, such degradation is not caused by overfitting, and adding more layers to a suitably deep model leads to higher training error, as reported in [11,42] and thoroughly verified by our experiments.",
              "tag": "Claim"
            },
            {
              "sent": "Figure 1 shows a typical example.",
              "tag": "Claim"
            }
          ]
        },
        {
          "par_id": 6,
          "sentences": [
            {
              "sent": "The degradation (of training accuracy) indicates that not all systems are similarly easy to optimize.",
              "tag": "Method"
            },
            {
              "sent": "Let us consider a shallower architecture and its deeper counterpart that adds more layers onto it.",
              "tag": "Method"
            },
            {
              "sent": "There exists a solution by construction to the deeper model: the added layers are identity mapping, and the other layers are copied from the learned shallower model.",
              "tag": "Method"
            },
            {
              "sent": "The existence of this constructed solution indicates that a deeper model should produce no higher training error than its shallower counterpart.",
              "tag": "Result"
            },
            {
              "sent": "But experiments show that our current solvers on hand are unable to find solutions that are comparably good or better than the constructed solution (or unable to do so in feasible time).",
              "tag": "Claim"
            }
          ]
        },
        {
          "par_id": 7,
          "sentences": [
            {
              "sent": "In this paper, we address the degradation problem by introducing a deep residual learning framework.",
              "tag": "Claim"
            },
            {
              "sent": "Instead of hoping each few stacked layers directly fit a desired underlying mapping, we explicitly let these layers fit a residual mapping.",
              "tag": "Method"
            },
            {
              "sent": "Formally, denoting the desired underlying mapping as H(x), we let the stacked nonlinear layers fit another mapping of F(x) := H(x) \u2212 x.",
              "tag": "Method"
            },
            {
              "sent": "The original mapping is recast into F(x)+x.",
              "tag": "Claim"
            },
            {
              "sent": "We hypothesize that it is easier to optimize the residual mapping than to optimize the original, unreferenced mapping.",
              "tag": "Claim"
            },
            {
              "sent": "To the extreme, if an identity mapping were optimal, it would be easier to push the residual to zero than to fit an identity mapping by a stack of nonlinear layers.",
              "tag": "Method"
            }
          ]
        },
        {
          "par_id": 9,
          "sentences": [
            {
              "sent": "We present comprehensive experiments on ImageNet [36] to show the degradation problem and evaluate our method.",
              "tag": "Method"
            },
            {
              "sent": "We show that: 1) Our extremely deep residual nets are easy to optimize, but the counterpart \"plain\" nets (that simply stack layers) exhibit higher training error when the depth increases; 2) Our deep residual nets can easily enjoy accuracy gains from greatly increased depth, producing results substantially better than previous networks.",
              "tag": "Conclusion"
            }
          ]
        },
        {
          "par_id": 10,
          "sentences": [
            {
              "sent": "Similar phenomena are also shown on the CIFAR-10 set [20], suggesting that the optimization difficulties and the effects of our method are not just akin to a particular dataset.",
              "tag": "Method"
            },
            {
              "sent": "We present successfully trained models on this dataset with over 100 layers, and explore models with over 1000 layers.",
              "tag": "Method"
            }
          ]
        },
        {
          "par_id": 11,
          "sentences": [
            {
              "sent": "On the ImageNet classification dataset [36], we obtain excellent results by extremely deep residual nets.",
              "tag": "Result"
            },
            {
              "sent": "Our 152layer residual net is the deepest network ever presented on ImageNet, while still having lower complexity than VGG nets [41].",
              "tag": "Method"
            },
            {
              "sent": "Our ensemble has 3.57% top-5 error on the ImageNet test set, and won the 1st place in the ILSVRC 2015 classification competition.",
              "tag": "Result"
            },
            {
              "sent": "The extremely deep representations also have excellent generalization performance on other recognition tasks, and lead us to further win the 1st places on: ImageNet detection, ImageNet localization, COCO detection, and COCO segmentation in ILSVRC & COCO 2015 competitions.",
              "tag": "Conclusion"
            },
            {
              "sent": "This strong evidence shows that the residual learning principle is generic, and we expect that it is applicable in other vision and non-vision problems.",
              "tag": "Claim"
            }
          ]
        }
      ]
    },
    {
      "section_name": "Related Work",
      "selected_sentences": [
        {
          "par_id": 12,
          "sentences": [
            {
              "sent": "In image recognition, VLAD [18] is a representation that encodes by the residual vectors with respect to a dictionary, and Fisher Vector [30] can be formulated as a probabilistic version [18] of VLAD.",
              "tag": "Claim"
            },
            {
              "sent": "Both of them are powerful shallow representations for image retrieval and classification [4,48].",
              "tag": "Claim"
            },
            {
              "sent": "For vector quantization, encoding residual vectors [17] is shown to be more effective than encoding original vectors.",
              "tag": "Claim"
            }
          ]
        },
        {
          "par_id": 13,
          "sentences": [
            {
              "sent": "In low-level vision and computer graphics, for solving Partial Differential Equations (PDEs), the widely used Multigrid method [3] reformulates the system as subproblems at multiple scales, where each subproblem is responsible for the residual solution between a coarser and a finer scale.",
              "tag": "Claim"
            },
            {
              "sent": "An alternative to Multigrid is hierarchical basis preconditioning [45,46], which relies on variables that represent residual vectors between two scales.",
              "tag": "Claim"
            },
            {
              "sent": "It has been shown [3,45,46] that these solvers converge much faster than standard solvers that are unaware of the residual nature of the solutions.",
              "tag": "Claim"
            },
            {
              "sent": "These methods suggest that a good reformulation or preconditioning can simplify the optimization.",
              "tag": "Claim"
            },
            {
              "sent": "Practices and theories that lead to shortcut connections [2,34,49] have been studied for a long time.",
              "tag": "Claim"
            },
            {
              "sent": "An early practice of training multi-layer perceptrons (MLPs) is to add a linear layer connected from the network input to the output [34,49].",
              "tag": "Claim"
            },
            {
              "sent": "In [44,24], a few intermediate layers are directly connected to auxiliary classifiers for addressing vanishing/exploding gradients.",
              "tag": "Claim"
            },
            {
              "sent": "The papers of [39,38,31,47] propose methods for centering layer responses, gradients, and propagated errors, implemented by shortcut connections.",
              "tag": "Claim"
            },
            {
              "sent": "In [44], an \"inception\" layer is composed of a shortcut branch and a few deeper branches.",
              "tag": "Claim"
            }
          ]
        },
        {
          "par_id": 14,
          "sentences": [
            {
              "sent": "Concurrent with our work, \"highway networks\" [42,43] present shortcut connections with gating functions [15].",
              "tag": "Method"
            },
            {
              "sent": "These gates are data-dependent and have parameters, in contrast to our identity shortcuts that are parameter-free.",
              "tag": "Claim"
            },
            {
              "sent": "When a gated shortcut is \"closed\" (approaching zero), the layers in highway networks represent non-residual functions.",
              "tag": "Result"
            },
            {
              "sent": "On the contrary, our formulation always learns residual functions; our identity shortcuts are never closed, and all information is always passed through, with additional residual functions to be learned.",
              "tag": "Result"
            },
            {
              "sent": "In addition, high-way networks have not demonstrated accuracy gains with extremely increased depth (eg, over 100 layers).",
              "tag": "Method"
            }
          ]
        }
      ]
    },
    {
      "section_name": "Residual Learning",
      "selected_sentences": [
        {
          "par_id": 15,
          "sentences": [
            {
              "sent": "Let us consider H(x) as an underlying mapping to be fit by a few stacked layers (not necessarily the entire net), with x denoting the inputs to the first of these layers.",
              "tag": "Claim"
            },
            {
              "sent": "If one hypothesizes that multiple nonlinear layers can asymptotically approximate complicated functions 2 , then it is equivalent to hypothesize that they can asymptotically approximate the residual functions, ie, H(x) \u2212 x (assuming that the input and output are of the same dimensions).",
              "tag": "Claim"
            },
            {
              "sent": "So rather than expect stacked layers to approximate H(x), we explicitly let these layers approximate a residual function F(x) := H(x) \u2212 x.",
              "tag": "Method"
            },
            {
              "sent": "The original function thus becomes F(x)+x.",
              "tag": "Claim"
            },
            {
              "sent": "Although both forms should be able to asymptotically approximate the desired functions (as hypothesized), the ease of learning might be different.",
              "tag": "Method"
            }
          ]
        }
      ]
    },
    {
      "section_name": "Identity Mapping by Shortcuts",
      "selected_sentences": [
        {
          "par_id": 18,
          "sentences": [
            {
              "sent": "We adopt residual learning to every few stacked layers.",
              "tag": "Method"
            },
            {
              "sent": "A building block is shown in Figure 2. Formally, in this paper we consider a building block defined as:",
              "tag": "Method"
            }
          ]
        }
      ]
    },
    {
      "section_name": "Network Architectures",
      "selected_sentences": [
        {
          "par_id": 24,
          "sentences": [
            {
              "sent": "Our plain baselines (Figure 3, middle) are mainly inspired by the philosophy of VGG nets [41] (Figure 3, left).",
              "tag": "Method"
            },
            {
              "sent": "The convolutional layers mostly have 3\u00d73 filters and follow two simple design rules: (i) for the same output feature map size, the layers have the same number of filters; and (ii) if the feature map size is halved, the number of filters is doubled so as to preserve the time complexity per layer.",
              "tag": "Method"
            },
            {
              "sent": "We perform downsampling directly by convolutional layers that have a stride of 2. The network ends with a global average pooling layer and a 1000-way fully-connected layer with softmax.",
              "tag": "Method"
            },
            {
              "sent": "The total number of weighted layers is 34 in Figure 3",
              "tag": "Result"
            }
          ]
        }
      ]
    },
    {
      "section_name": "(middle).",
      "selected_sentences": [
        {
          "par_id": 25,
          "sentences": [
            {
              "sent": "It is worth noticing that our model has fewer filters and lower complexity than VGG nets [41] (Figure 3 Residual Network.",
              "tag": "Method"
            },
            {
              "sent": "Based on the above plain network, we insert shortcut connections (Figure 3, right) which turn the network into its counterpart residual version.",
              "tag": "Method"
            },
            {
              "sent": "1)) can be directly used when the input and output are of the same dimensions (solid line shortcuts in Figure 3).",
              "tag": "Claim"
            },
            {
              "sent": "When the dimensions increase (dotted line shortcuts in Figure 3), we consider two options: (A) The shortcut still performs identity mapping, with extra zero entries padded for increasing dimensions.",
              "tag": "Method"
            },
            {
              "sent": "This option introduces no extra parameter; (B) The projection shortcut in Eqn.( 2) is used to match dimensions (done by 1\u00d71 convolutions).",
              "tag": "Method"
            },
            {
              "sent": "For both options, when the shortcuts go across feature maps of two sizes, they are performed with a stride of 2.",
              "tag": "Result"
            }
          ]
        }
      ]
    },
    {
      "section_name": "Implementation",
      "selected_sentences": []
    },
    {
      "section_name": "ImageNet Classification",
      "selected_sentences": [
        {
          "par_id": 34,
          "sentences": [
            {
              "sent": "We have three major observations from Table 2 and Figure 4. First, the situation is reversed with residual learning -the 34-layer ResNet is better than the 18-layer ResNet (by 2.8%).",
              "tag": "Result"
            },
            {
              "sent": "More importantly, the 34-layer ResNet exhibits considerably lower training error and is generalizable to the validation data.",
              "tag": "Result"
            },
            {
              "sent": "This indicates that the degradation problem is well addressed in this setting and we manage to obtain accuracy gains from increased depth.",
              "tag": "Result"
            }
          ]
        },
        {
          "par_id": 36,
          "sentences": [
            {
              "sent": "Table 5. Error rates (%) of ensembles.",
              "tag": "Method"
            },
            {
              "sent": "The top-5 error is on the test set of ImageNet and reported by the test server.",
              "tag": "Result"
            }
          ]
        },
        {
          "par_id": 37,
          "sentences": [
            {
              "sent": "ResNet reduces the top-1 error by 3.5% (Table 2), resulting from the successfully reduced training error (Figure 4 right vs. left).",
              "tag": "Result"
            },
            {
              "sent": "This comparison verifies the effectiveness of residual learning on extremely deep systems.",
              "tag": "Result"
            },
            {
              "sent": "Last, we also note that the 18-layer plain/residual nets are comparably accurate (Table 2), but the 18-layer ResNet converges faster (Figure 4 right vs. left).",
              "tag": "Result"
            },
            {
              "sent": "When the net is \"not overly deep\" (18 layers here), the current SGD solver is still able to find good solutions to the plain net.",
              "tag": "Claim"
            },
            {
              "sent": "In this case, the ResNet eases the optimization by providing faster convergence at the early stage.",
              "tag": "Method"
            }
          ]
        },
        {
          "par_id": 39,
          "sentences": [
            {
              "sent": "Next we describe our deeper nets for ImageNet.",
              "tag": "Method"
            },
            {
              "sent": "Because of concerns on the training time that we can afford, we modify the building block as a bottleneck design 4 .",
              "tag": "Method"
            },
            {
              "sent": "For each residual function F, we use a stack of 3 layers instead of 2 (Figure 5).",
              "tag": "Method"
            },
            {
              "sent": "The three layers are 1\u00d71, 3\u00d73, and 1\u00d71 convolutions, where the 1\u00d71 layers are responsible for reducing and then increasing (restoring) dimensions, leaving the 3\u00d73 layer a bottleneck with smaller input/output dimensions.",
              "tag": "Method"
            },
            {
              "sent": "Figure 5 shows an example, where both designs have similar time complexity.",
              "tag": "Claim"
            }
          ]
        },
        {
          "par_id": 40,
          "sentences": [
            {
              "sent": "The parameter-free identity shortcuts are particularly important for the bottleneck architectures.",
              "tag": "Result"
            },
            {
              "sent": "If the identity shortcut in Figure 5 (right) is replaced with projection, one can show that the time complexity and model size are doubled, as the shortcut is connected to the two high-dimensional ends.",
              "tag": "Result"
            },
            {
              "sent": "So identity shortcuts lead to more efficient models for the bottleneck designs.",
              "tag": "Result"
            },
            {
              "sent": "The 50/101/152-layer ResNets are more accurate than the 34-layer ones by considerable margins (Table 3 and 4).",
              "tag": "Result"
            },
            {
              "sent": "We do not observe the degradation problem and thus enjoy significant accuracy gains from considerably increased depth.",
              "tag": "Result"
            },
            {
              "sent": "The benefits of depth are witnessed for all evaluation metrics (Table 3 and 4).",
              "tag": "Result"
            }
          ]
        },
        {
          "par_id": 41,
          "sentences": [
            {
              "sent": "In Table 4 we compare with the previous best single-model results.",
              "tag": "Result"
            },
            {
              "sent": "Our baseline 34-layer ResNets have achieved very competitive accuracy.",
              "tag": "Result"
            },
            {
              "sent": "Our 152-layer ResNet has a single-model top-5 validation error of 4.49%.",
              "tag": "Result"
            },
            {
              "sent": "This single-model result outperforms all previous ensemble results (Table 5).",
              "tag": "Result"
            },
            {
              "sent": "We combine six models of different depth to form an ensemble (only with two 152-layer ones at the time of submitting).",
              "tag": "Result"
            },
            {
              "sent": "This leads to 3.57% top-5 error on the test set (Table 5).",
              "tag": "Result"
            },
            {
              "sent": "This entry won the 1st place in ILSVRC 2015.",
              "tag": "Method"
            }
          ]
        }
      ]
    },
    {
      "section_name": "CIFAR-10 and Analysis",
      "selected_sentences": [
        {
          "par_id": 42,
          "sentences": [
            {
              "sent": "We conducted more studies on the CIFAR-10 dataset [20], which consists of 50k training images and 10k testing images in 10 classes.",
              "tag": "Method"
            },
            {
              "sent": "We present experiments trained on the training set and evaluated on the test set.",
              "tag": "Method"
            },
            {
              "sent": "Our focus is on the behaviors of extremely deep networks, but not on pushing the state-of-the-art results, so we intentionally use simple architectures as follows.",
              "tag": "Method"
            }
          ]
        },
        {
          "par_id": 44,
          "sentences": [
            {
              "sent": "We compare n = {3, 5, 7, 9}, leading to 20, 32, 44, and 56-layer networks.",
              "tag": "Method"
            },
            {
              "sent": "Figure 6 (left) shows the behaviors of the plain nets.",
              "tag": "Result"
            },
            {
              "sent": "The deep plain nets suffer from increased depth, and exhibit higher training error when going deeper.",
              "tag": "Conclusion"
            },
            {
              "sent": "This phenomenon is similar to that on ImageNet (Figure 4, left) and on MNIST (see [42]), suggesting that such an optimization difficulty is a fundamental problem.",
              "tag": "Result"
            }
          ]
        },
        {
          "par_id": 45,
          "sentences": [
            {
              "sent": "Figure 6 (middle) shows the behaviors of ResNets.",
              "tag": "Result"
            },
            {
              "sent": "Also similar to the ImageNet cases (Figure 4, right), our ResNets manage to overcome the optimization difficulty and demonstrate accuracy gains when the depth increases.",
              "tag": "Method"
            }
          ]
        },
        {
          "par_id": 48,
          "sentences": [
            {
              "sent": "We explore an aggressively deep model of over 1000 layers.",
              "tag": "Method"
            },
            {
              "sent": "We set n = 200 that leads to a 1202-layer network, which is trained as described above.",
              "tag": "Method"
            },
            {
              "sent": "Our method shows no optimization difficulty, and this 10 3 -layer network is able to achieve training error <0.1% (Figure 6, right).",
              "tag": "Result"
            },
            {
              "sent": "Its test error is still fairly good (7.93%, have similar training error.",
              "tag": "Conclusion"
            },
            {
              "sent": "We argue that this is because of overfitting.",
              "tag": "Conclusion"
            },
            {
              "sent": "The 1202-layer network may be unnecessarily large (19.4M) for this small dataset.",
              "tag": "Method"
            },
            {
              "sent": "Strong regularization such as maxout [10] or dropout [14] is applied to obtain the best results ( [10,25,24,35]) on this dataset.",
              "tag": "Claim"
            },
            {
              "sent": "In this paper, we use no maxout/dropout and just simply impose regularization via deep and thin architectures by design, without distracting from the focus on the difficulties of optimization.",
              "tag": "Method"
            },
            {
              "sent": "But combining with stronger regularization may improve results, which we will study in the future.",
              "tag": "Other"
            }
          ]
        }
      ]
    },
    {
      "section_name": "Object Detection on PASCAL and MS COCO",
      "selected_sentences": [
        {
          "par_id": 49,
          "sentences": [
            {
              "sent": "Our method has good generalization performance on other recognition tasks.",
              "tag": "Method"
            },
            {
              "sent": "Table 7 and 8 show the object detection baseline results on PASCAL VOC 2007 and 2012 [5] and COCO [26].",
              "tag": "Method"
            },
            {
              "sent": "We adopt Faster RCNN [32] as the detection method.",
              "tag": "Method"
            },
            {
              "sent": "Here we are interested in the improvements of replacing VGG-16 [41] with ResNet-101.",
              "tag": "Method"
            },
            {
              "sent": "The detection implementation (see appendix) of using both models is the same, so the gains can only be attributed to better networks.",
              "tag": "Result"
            },
            {
              "sent": "Most remarkably, on the challenging COCO dataset we obtain a 6.0% increase in COCO's standard metric (mAP@[.5, which is a 28% relative improvement.",
              "tag": "Result"
            },
            {
              "sent": "This gain is solely due to the learned representations.",
              "tag": "Method"
            }
          ]
        },
        {
          "par_id": 50,
          "sentences": [
            {
              "sent": "Based on deep residual nets, we won the 1st places in several tracks in ILSVRC & COCO 2015 competitions: Im-ageNet detection, ImageNet localization, COCO detection, and COCO segmentation.",
              "tag": "Method"
            },
            {
              "sent": "The details are in the appendix.",
              "tag": "Method"
            }
          ]
        }
      ]
    },
    {
      "section_name": "A. Object Detection Baselines",
      "selected_sentences": [
        {
          "par_id": 51,
          "sentences": [
            {
              "sent": "In this section we introduce our detection method based on the baseline Faster RCNN [32] system.",
              "tag": "Method"
            },
            {
              "sent": "The models are initialized by the ImageNet classification models, and then fine-tuned on the object detection data.",
              "tag": "Method"
            },
            {
              "sent": "We have experimented with ResNet-50/101 at the time of the ILSVRC & COCO 2015 detection competitions.",
              "tag": "Method"
            }
          ]
        }
      ]
    },
    {
      "section_name": "PASCAL VOC",
      "selected_sentences": [
        {
          "par_id": 64,
          "sentences": [
            {
              "sent": "We revisit the PASCAL VOC dataset based on the above model.",
              "tag": "Method"
            },
            {
              "sent": "With the single model on the COCO dataset (55.7% mAP@.5 in Table 9), we fine-tune this model on the PASCAL VOC sets.",
              "tag": "Result"
            },
            {
              "sent": "The improvements of box refinement, context, and multi-scale testing are also adopted.",
              "tag": "Method"
            },
            {
              "sent": "Our results (mAP, %) on the ImageNet detection dataset.",
              "tag": "Method"
            }
          ]
        }
      ]
    },
    {
      "section_name": "MS COCO",
      "selected_sentences": [
        {
          "par_id": 56,
          "sentences": [
            {
              "sent": "Table 8 shows the results on the MS COCO validation set.",
              "tag": "Result"
            },
            {
              "sent": "ResNet-101 has a 6% increase of mAP@[.5, .95] over VGG-16, which is a 28% relative improvement, solely contributed by the features learned by the better network. absolute increase (6.0%) is nearly as big as mAP@.5's",
              "tag": "Result"
            },
            {
              "sent": "This suggests that a deeper network can improve both recognition and localization.",
              "tag": "Method"
            }
          ]
        }
      ]
    },
    {
      "section_name": "B. Object Detection Improvements",
      "selected_sentences": []
    },
    {
      "section_name": "ImageNet Detection",
      "selected_sentences": [
        {
          "par_id": 67,
          "sentences": [
            {
              "sent": "The ImageNet Detection (DET) task involves 200 object categories.",
              "tag": "Method"
            },
            {
              "sent": "The accuracy is evaluated by mAP@.5.",
              "tag": "Method"
            },
            {
              "sent": "Our object detection algorithm for ImageNet DET is the same as that for MS COCO in Table 9.",
              "tag": "Method"
            },
            {
              "sent": "The networks are pretrained on the 1000-class ImageNet classification set, and are fine-tuned on the DET data.",
              "tag": "Method"
            },
            {
              "sent": "We split the validation set into two parts (val1/val2) following [8].",
              "tag": "Method"
            },
            {
              "sent": "We fine-tune the detection models using the DET training set and the val1 set.",
              "tag": "Method"
            },
            {
              "sent": "The val2 set is used for validation.",
              "tag": "Method"
            },
            {
              "sent": "We do not use other ILSVRC 2015 data.",
              "tag": "Method"
            },
            {
              "sent": "Localization error (%) on the ImageNet validation.",
              "tag": "Method"
            },
            {
              "sent": "In the column of \"LOC error on GT class\" ( [41]), the ground truth class is used.",
              "tag": "Method"
            },
            {
              "sent": "In the \"testing\" column, \"1-crop\" denotes testing on a center crop of 224\u00d7224 pixels, \"dense\" denotes dense (fully convolutional) and multi-scale testing.",
              "tag": "Result"
            }
          ]
        },
        {
          "par_id": 68,
          "sentences": [
            {
              "sent": "58.8% mAP and our ensemble of 3 models has 62.1% mAP on the DET test set (Table 12).",
              "tag": "Result"
            },
            {
              "sent": "This result won the 1st place in the ImageNet detection task in ILSVRC 2015, surpassing the second place by 8.5 points (absolute).",
              "tag": "Result"
            }
          ]
        }
      ]
    },
    {
      "section_name": "C. ImageNet Localization",
      "selected_sentences": [
        {
          "par_id": 69,
          "sentences": [
            {
              "sent": "The ImageNet Localization (LOC) task [36] requires to classify and localize the objects.",
              "tag": "Method"
            },
            {
              "sent": "Following [40,41], we assume that the image-level classifiers are first adopted for predicting the class labels of an image, and the localization algorithm only accounts for predicting bounding boxes based on the predicted classes.",
              "tag": "Method"
            },
            {
              "sent": "We adopt the \"per-class regression\" (PCR) strategy [40,41], learning a bounding box regressor for each class.",
              "tag": "Method"
            },
            {
              "sent": "We pre-train the networks for Im-ageNet classification and then fine-tune them for localization.",
              "tag": "Method"
            },
            {
              "sent": "We train networks on the provided 1000-class Ima-geNet training set.",
              "tag": "Method"
            }
          ]
        },
        {
          "par_id": 70,
          "sentences": [
            {
              "sent": "Our localization algorithm is based on the RPN framework of [32] with a few modifications.",
              "tag": "Method"
            },
            {
              "sent": "Unlike the way in [32] that is category-agnostic, our RPN for localization is designed in a per-class form.",
              "tag": "Method"
            },
            {
              "sent": "This RPN ends with two sibling 1\u00d71 convolutional layers for binary classification (cls) and box regression (reg), as in [32].",
              "tag": "Method"
            },
            {
              "sent": "The cls and reg layers are both in a per-class from, in contrast to [32].",
              "tag": "Method"
            },
            {
              "sent": "Specifically, the cls layer has a 1000-d output, and each dimension is binary logistic regression for predicting being or not being an object class; the reg layer has a 1000\u00d74-d output consisting of box regressors for 1000 classes.",
              "tag": "Method"
            },
            {
              "sent": "As in [32], our bounding box regression is with reference to multiple translation-invariant \"anchor\" boxes at each position.",
              "tag": "Result"
            }
          ]
        },
        {
          "par_id": 74,
          "sentences": [
            {
              "sent": "This method reduces the top-5 localization error to 10.6% (Table 13).",
              "tag": "Result"
            },
            {
              "sent": "This is our single-model result on the validation set.",
              "tag": "Result"
            },
            {
              "sent": "Using an ensemble of networks for both classification and localization, we achieve a top-5 localization error of 9.0% on the test set.",
              "tag": "Result"
            },
            {
              "sent": "This number significantly outperforms the ILSVRC 14 results (Table 14), showing a 64% relative reduction of error.",
              "tag": "Result"
            },
            {
              "sent": "This result won the 1st place in the ImageNet localization task in ILSVRC 2015.",
              "tag": "Result"
            }
          ]
        }
      ]
    }
  ],
  "title": "Deep Residual Learning for Image Recognition"
}