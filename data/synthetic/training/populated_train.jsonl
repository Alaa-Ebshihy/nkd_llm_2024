{"doc_id": "000f90380d768a85e2316225854fc377c079b5c4", "arxiv_id": "1611.08323", "title": "Full-Resolution Residual Networks for Semantic Segmentation in Street Scenes", "n_ary_relations": [{"Material": "Cityscapes", "Method": "FRRN", "Metric": "Frame__fps_", "Task": "Real-Time_Semantic_Segmentation", "score": "2.1"}, {"Material": "Cityscapes", "Method": "FRRN", "Metric": "Mean_IoU", "Task": "Semantic_Segmentation", "score": "71.8%"}, {"Material": "Cityscapes", "Method": "FRRN", "Metric": "Time__ms_", "Task": "Real-Time_Semantic_Segmentation", "score": "469"}, {"Material": "Cityscapes", "Method": "FRRN", "Metric": "mIoU", "Task": "Real-Time_Semantic_Segmentation", "score": "71.8%"}]}
{"doc_id": "0012de6bec1f25599e4f02517637e531a71909b9", "arxiv_id": "1606.04797", "title": "V-Net: Fully Convolutional Neural Networks for Volumetric Medical Image Segmentation", "n_ary_relations": [{"Material": "PROMISE_2012", "Method": "V-Net___Dice-based_loss", "Metric": "Dice_Score", "Task": "Volumetric_Medical_Image_Segmentation", "score": "0.869"}]}
{"doc_id": "007ab5528b3bd310a80d553cccad4b78dc496b02", "arxiv_id": "", "title": "B I -D IRECTIONAL A TTENTION F LOW FOR M ACHINE C OMPREHENSION", "n_ary_relations": [{"Material": "CNN___Daily_Mail", "Method": "BiDAF", "Metric": "CNN", "Task": "Question_Answering", "score": "76.9"}, {"Material": "CNN___Daily_Mail", "Method": "BiDAF", "Metric": "Daily_Mail", "Task": "Question_Answering", "score": "79.6"}, {"Material": "MS_MARCO", "Method": "BiDaF_Baseline", "Metric": "BLEU-1", "Task": "Question_Answering", "score": "10.64"}, {"Material": "MS_MARCO", "Method": "BiDaF_Baseline", "Metric": "Rouge-L", "Task": "Question_Answering", "score": "23.96"}, {"Material": "NarrativeQA", "Method": "BiDAF", "Metric": "BLEU-1", "Task": "Question_Answering", "score": "33.45"}, {"Material": "NarrativeQA", "Method": "BiDAF", "Metric": "BLEU-4", "Task": "Question_Answering", "score": "15.69"}, {"Material": "NarrativeQA", "Method": "BiDAF", "Metric": "METEOR", "Task": "Question_Answering", "score": "15.68"}, {"Material": "NarrativeQA", "Method": "BiDAF", "Metric": "Rouge-L", "Task": "Question_Answering", "score": "36.74"}, {"Material": "Quasar", "Method": "BiDAF", "Metric": "EM__Quasar-T_", "Task": "Open-Domain_Question_Answering", "score": "25.9"}, {"Material": "Quasar", "Method": "BiDAF", "Metric": "F1__Quasar-T_", "Task": "Open-Domain_Question_Answering", "score": "28.5"}, {"Material": "SQuAD1_1", "Method": "BiDAF__ensemble_", "Metric": "EM", "Task": "Question_Answering", "score": "73.744"}, {"Material": "SQuAD1_1", "Method": "BiDAF__single_model_", "Metric": "EM", "Task": "Question_Answering", "score": "67.974"}, {"Material": "SQuAD1_1", "Method": "BiDAF__ensemble_", "Metric": "F1", "Task": "Question_Answering", "score": "81.525"}, {"Material": "SQuAD1_1", "Method": "BiDAF__single_model_", "Metric": "F1", "Task": "Question_Answering", "score": "77.323"}]}
{"doc_id": "0095c269e7d0c990249312687fc43521019809c4", "arxiv_id": "1605.05573", "title": "Modelling Interaction of Sentence Pair with Coupled-LSTMs", "n_ary_relations": [{"Material": "SNLI", "Method": "50D_stacked_TC-LSTMs", "Metric": "__Test_Accuracy", "Task": "Natural_Language_Inference", "score": "85.1"}, {"Material": "SNLI", "Method": "50D_stacked_TC-LSTMs", "Metric": "__Train_Accuracy", "Task": "Natural_Language_Inference", "score": "86.7"}, {"Material": "SNLI", "Method": "50D_stacked_TC-LSTMs", "Metric": "Parameters", "Task": "Natural_Language_Inference", "score": "190k"}]}
{"doc_id": "00b1cdc5bd77bf27f9b1ca630365eeeb456913b4", "arxiv_id": "1712.01815", "title": "Mastering Chess and Shogi by Self-Play with a General Reinforcement Learning Algorithm", "n_ary_relations": [{"Material": "ELO_Ratings", "Method": "AlphaGo_Zero", "Metric": "ELO_Rating", "Task": "Game_of_Go", "score": "5185"}, {"Material": "ELO_Ratings", "Method": "AlphaZero", "Metric": "ELO_Rating", "Task": "Game_of_Shogi", "score": "4650"}]}
{"doc_id": "01125e3c68edb420b8d884ff53fb38d9fbe4f2b8", "arxiv_id": "1703.07834", "title": "Large Pose 3D Face Reconstruction from a Single Image via Direct Volumetric CNN Regression", "n_ary_relations": [{"Material": "Florence", "Method": "VRN-Guided", "Metric": "Mean_NME_", "Task": "3D_Face_Reconstruction", "score": "5.2667%"}]}
{"doc_id": "0116899fce00ffa4afee08b505300bb3968faf9f", "arxiv_id": "1709.08624", "title": "Long Text Generation via Adversarial Training with Leaked Information", "n_ary_relations": [{"Material": "COCO_Captions", "Method": "LeakGAN", "Metric": "BLEU-2", "Task": "Text_Generation", "score": "0.950"}, {"Material": "COCO_Captions", "Method": "LeakGAN", "Metric": "BLEU-3", "Task": "Text_Generation", "score": "0.880"}, {"Material": "COCO_Captions", "Method": "LeakGAN", "Metric": "BLEU-4", "Task": "Text_Generation", "score": "0.778"}, {"Material": "COCO_Captions", "Method": "LeakGAN", "Metric": "BLEU-5", "Task": "Text_Generation", "score": "0.686"}, {"Material": "Chinese_Poems", "Method": "LeakGAN", "Metric": "BLEU-2", "Task": "Text_Generation", "score": "0.881"}, {"Material": "EMNLP2017_WMT", "Method": "LeakGAN", "Metric": "BLEU-2", "Task": "Text_Generation", "score": "0.956"}, {"Material": "EMNLP2017_WMT", "Method": "LeakGAN", "Metric": "BLEU-3", "Task": "Text_Generation", "score": "0.819"}, {"Material": "EMNLP2017_WMT", "Method": "LeakGAN", "Metric": "BLEU-4", "Task": "Text_Generation", "score": "0.627"}, {"Material": "EMNLP2017_WMT", "Method": "LeakGAN", "Metric": "BLEU-5", "Task": "Text_Generation", "score": "0.498"}]}
{"doc_id": "0171bdeb1c6e333287be655c667cfba5edb89b76", "arxiv_id": "1611.05431", "title": "Aggregated Residual Transformations for Deep Neural Networks", "n_ary_relations": [{"Material": "ImageNet", "Method": "ResNeXt-101", "Metric": "Top_1_Accuracy", "Task": "Image_Classification", "score": "80.9%"}, {"Material": "ImageNet", "Method": "ResNeXt-101", "Metric": "Top_5_Accuracy", "Task": "Image_Classification", "score": "95.6%"}]}
{"doc_id": "01959ef569f74c286956024866c1d107099199f7", "arxiv_id": "1505.00468", "title": "VQA: Visual Question Answering", "n_ary_relations": [{"Material": "COCO_Visual_Question_Answering__VQA__abstract_1_0_multiple_choice", "Method": "Dualnet_ensemble", "Metric": "Percentage_correct", "Task": "Visual_Question_Answering", "score": 71.18}, {"Material": "COCO_Visual_Question_Answering__VQA__abstract_1_0_multiple_choice", "Method": "LSTM___global_features", "Metric": "Percentage_correct", "Task": "Visual_Question_Answering", "score": 69.21}, {"Material": "COCO_Visual_Question_Answering__VQA__abstract_1_0_multiple_choice", "Method": "LSTM_blind", "Metric": "Percentage_correct", "Task": "Visual_Question_Answering", "score": 61.41}, {"Material": "COCO_Visual_Question_Answering__VQA__abstract_images_1_0_open_ended", "Method": "Dualnet_ensemble", "Metric": "Percentage_correct", "Task": "Visual_Question_Answering", "score": 69.73}, {"Material": "COCO_Visual_Question_Answering__VQA__abstract_images_1_0_open_ended", "Method": "LSTM___global_features", "Metric": "Percentage_correct", "Task": "Visual_Question_Answering", "score": 65.02}, {"Material": "COCO_Visual_Question_Answering__VQA__abstract_images_1_0_open_ended", "Method": "LSTM_blind", "Metric": "Percentage_correct", "Task": "Visual_Question_Answering", "score": 57.19}, {"Material": "COCO_Visual_Question_Answering__VQA__real_images_1_0_multiple_choice", "Method": "LSTM_Q_I", "Metric": "Percentage_correct", "Task": "Visual_Question_Answering", "score": 63.1}, {"Material": "COCO_Visual_Question_Answering__VQA__real_images_1_0_open_ended", "Method": "LSTM_Q_I", "Metric": "Percentage_correct", "Task": "Visual_Question_Answering", "score": 58.2}, {"Material": "COCO_Visual_Question_Answering__VQA__real_images_2_0_open_ended", "Method": "DLAIT", "Metric": "Percentage_correct", "Task": "Visual_Question_Answering", "score": 68.07}, {"Material": "COCO_Visual_Question_Answering__VQA__real_images_2_0_open_ended", "Method": "HDU-USYD-UNCC", "Metric": "Percentage_correct", "Task": "Visual_Question_Answering", "score": 68.16}]}
{"doc_id": "01c824989d24a8cae214c3156edd9d4492faa579", "arxiv_id": "1612.04357", "title": "Stacked Generative Adversarial Networks", "n_ary_relations": [{"Material": "CIFAR-10", "Method": "SGAN", "Metric": "Inception_score", "Task": "Conditional_Image_Generation", "score": "8.59"}]}
{"doc_id": "0209389b8369aaa2a08830ac3b2036d4901ba1f1", "arxiv_id": "1803.02188", "title": "DenseReg: Fully Convolutional Dense Shape Regression In-the-Wild", "n_ary_relations": [{"Material": "DensePose-COCO", "Method": "DensePose___keypoints", "Metric": "AP", "Task": "Pose_Estimation", "score": "55.8"}]}
{"doc_id": "020a9aba95bce75dca08e3c499efc9e100f1cbb6", "arxiv_id": "1507.00814", "title": "Incentivizing Exploration In Reinforcement Learning With Deep Predictive Models", "n_ary_relations": [{"Material": "Atari_2600_Freeway", "Method": "MP-EB", "Metric": "Score", "Task": "Atari_Games", "score": 27.0}, {"Material": "Atari_2600_Frostbite", "Method": "MP-EB", "Metric": "Score", "Task": "Atari_Games", "score": 507.0}, {"Material": "Atari_2600_Montezuma_s_Revenge", "Method": "MP-EB", "Metric": "Score", "Task": "Atari_Games", "score": 142.0}, {"Material": "Atari_2600_Q_Bert", "Method": "MP-EB", "Metric": "Score", "Task": "Atari_Games", "score": 15805.0}, {"Material": "Atari_2600_Venture", "Method": "MP-EB", "Metric": "Score", "Task": "Atari_Games", "score": 0.0}]}
{"doc_id": "0217fb2a54a4f324ddf82babc6ec6692a3f6194f", "arxiv_id": "1606.03657", "title": "InfoGAN: Interpretable Representation Learning by Information Maximizing Generative Adversarial Nets", "n_ary_relations": [{"Material": "MNIST", "Method": "InfoGAN", "Metric": "Accuracy", "Task": "Unsupervised_MNIST", "score": "95"}, {"Material": "MNIST", "Method": "InfoGAN", "Metric": "Accuracy", "Task": "Unsupervised_image_classification", "score": "95"}]}
{"doc_id": "023cc7f9f3544436553df9548a7d0575bb309c2e", "arxiv_id": "1607.01759", "title": "Bag of Tricks for Efficient Text Classification", "n_ary_relations": [{"Material": "AG_News", "Method": "fastText", "Metric": "Error", "Task": "Text_Classification", "score": "7.5"}, {"Material": "Amazon_Review_Full", "Method": "FastText", "Metric": "Accuracy", "Task": "Sentiment_Analysis", "score": "60.2"}, {"Material": "Amazon_Review_Polarity", "Method": "FastText", "Metric": "Accuracy", "Task": "Sentiment_Analysis", "score": "94.6"}, {"Material": "DBpedia", "Method": "FastText", "Metric": "Error", "Task": "Text_Classification", "score": "1.4"}, {"Material": "Sogou_News", "Method": "fastText", "Metric": "Accuracy", "Task": "Sentiment_Analysis", "score": "96.8"}, {"Material": "Yahoo__Answers", "Method": "FastText", "Metric": "Accuracy", "Task": "Text_Classification", "score": "72.3"}, {"Material": "Yelp_Binary_classification", "Method": "FastText", "Metric": "Error", "Task": "Sentiment_Analysis", "score": "4.3"}, {"Material": "Yelp_Fine-grained_classification", "Method": "FastText", "Metric": "Error", "Task": "Sentiment_Analysis", "score": "36.1"}]}
{"doc_id": "027f9695189355d18ec6be8e48f3d23ea25db35d", "arxiv_id": "1707.02786", "title": "Learning to Compose Task-Specific Tree Structures", "n_ary_relations": [{"Material": "SNLI", "Method": "300D_Gumbel_TreeLSTM_encoders", "Metric": "__Test_Accuracy", "Task": "Natural_Language_Inference", "score": "85.6"}, {"Material": "SNLI", "Method": "600D_Gumbel_TreeLSTM_encoders", "Metric": "__Test_Accuracy", "Task": "Natural_Language_Inference", "score": "86.0"}, {"Material": "SNLI", "Method": "300D_Gumbel_TreeLSTM_encoders", "Metric": "__Train_Accuracy", "Task": "Natural_Language_Inference", "score": "91.2"}, {"Material": "SNLI", "Method": "600D_Gumbel_TreeLSTM_encoders", "Metric": "__Train_Accuracy", "Task": "Natural_Language_Inference", "score": "93.1"}, {"Material": "SNLI", "Method": "300D_Gumbel_TreeLSTM_encoders", "Metric": "Parameters", "Task": "Natural_Language_Inference", "score": "2.9m"}, {"Material": "SNLI", "Method": "600D_Gumbel_TreeLSTM_encoders", "Metric": "Parameters", "Task": "Natural_Language_Inference", "score": "10m"}]}
{"doc_id": "02a5b7a41ffa8518eb3b7cae9914a2bd2bbc886b", "arxiv_id": "1812.05050", "title": "Fast Online Object Tracking and Segmentation: A Unifying Approach", "n_ary_relations": [{"Material": "VOT2017_18", "Method": "SiamMask", "Metric": "Expected_Average_Overlap__EAO_", "Task": "Visual_Object_Tracking", "score": "0.380"}]}
{"doc_id": "02e85d62fbd8249a046d00ac10e39546511b2a51", "arxiv_id": "1603.05959", "title": "Efficient multi\u2010scale 3D CNN with fully connected CRF for accurate brain lesion segmentation", "n_ary_relations": [{"Material": "BRATS-2015", "Method": "Multi-Scale_3D___FC-CRF", "Metric": "Dice_Score", "Task": "Brain_Tumor_Segmentation", "score": "84%"}]}
{"doc_id": "03184ac97ebf0724c45a29ab49f2a8ce59ac2de3", "arxiv_id": "1409.8403", "title": "Evaluation of output embeddings for fine-grained image classification", "n_ary_relations": [{"Material": "CUB-200_-_0-Shot_Learning", "Method": "SJE", "Metric": "Accuracy", "Task": "Few-Shot_Image_Classification", "score": " 50.1%"}]}
{"doc_id": "0373b97580cdfd0b69f165e1a946bae62da95dce", "arxiv_id": "1604.04112", "title": "Deep Residual Networks with Exponential Linear Unit", "n_ary_relations": [{"Material": "CIFAR-10", "Method": "ResNet_ELU", "Metric": "Percentage_correct", "Task": "Image_Classification", "score": "94.4"}, {"Material": "CIFAR-100", "Method": "ResNet_ELU", "Metric": "Percentage_correct", "Task": "Image_Classification", "score": "73.5"}]}
{"doc_id": "03a5b2aac53443e6078f0f63b35d4f95d6d54c5d", "arxiv_id": "1609.05158", "title": "Real-Time Single Image and Video Super-Resolution Using an Efficient Sub-Pixel Convolutional Neural Network", "n_ary_relations": [{"Material": "BSD100_-_4x_upscaling", "Method": "ESPCN", "Metric": "MOS", "Task": "Image_Super-Resolution", "score": "2.01"}, {"Material": "BSD100_-_4x_upscaling", "Method": "ESPCN", "Metric": "PSNR", "Task": "Image_Super-Resolution", "score": "27.02"}, {"Material": "BSD100_-_4x_upscaling", "Method": "ESPCN", "Metric": "SSIM", "Task": "Image_Super-Resolution", "score": "0.7442"}, {"Material": "Set14_-_4x_upscaling", "Method": "ESPCN", "Metric": "MOS", "Task": "Image_Super-Resolution", "score": "2.52"}, {"Material": "Set14_-_4x_upscaling", "Method": "ESPCN", "Metric": "PSNR", "Task": "Image_Super-Resolution", "score": "27.66"}, {"Material": "Set14_-_4x_upscaling", "Method": "ESPCN", "Metric": "SSIM", "Task": "Image_Super-Resolution", "score": "0.8004"}, {"Material": "Set5_-_4x_upscaling", "Method": "ESPCN", "Metric": "MOS", "Task": "Image_Super-Resolution", "score": "2.89"}, {"Material": "Set5_-_4x_upscaling", "Method": "ESPCN", "Metric": "PSNR", "Task": "Image_Super-Resolution", "score": "30.76"}, {"Material": "Set5_-_4x_upscaling", "Method": "ESPCN", "Metric": "SSIM", "Task": "Image_Super-Resolution", "score": " 0.8784"}, {"Material": "Ultra_Video_Group_HD_-_4x_upscaling", "Method": "ESPCN", "Metric": "Average_PSNR", "Task": "Video_Super-Resolution", "score": "37.91"}, {"Material": "Ultra_Video_Group_HD_-_4x_upscaling", "Method": "bicubic", "Metric": "Average_PSNR", "Task": "Video_Super-Resolution", "score": "36.20"}, {"Material": "Vid4_-_4x_upscaling", "Method": "ESPCN", "Metric": "MOVIE", "Task": "Video_Super-Resolution", "score": "6.54"}, {"Material": "Vid4_-_4x_upscaling", "Method": "ESPCN", "Metric": "PSNR", "Task": "Video_Super-Resolution", "score": "25.06"}, {"Material": "Vid4_-_4x_upscaling", "Method": "ESPCN", "Metric": "SSIM", "Task": "Video_Super-Resolution", "score": "0.7394"}, {"Material": "Xiph_HD_-_4x_upscaling", "Method": "ESPCN", "Metric": "Average_PSNR", "Task": "Video_Super-Resolution", "score": "31.67"}, {"Material": "Xiph_HD_-_4x_upscaling", "Method": "bicubic", "Metric": "Average_PSNR", "Task": "Video_Super-Resolution", "score": "30.30"}]}
{"doc_id": "04320b6d3e6e50a5faf0e54ae2b8b8739445a026", "arxiv_id": "1904.07418", "title": "Positional Encoding to Control Output Sequence Length", "n_ary_relations": [{"Material": "DUC_2004_Task_1", "Method": "Transformer_LRPE_PE_Re-ranking_Ensemble", "Metric": "ROUGE-1", "Task": "Text_Summarization", "score": "32.85"}, {"Material": "DUC_2004_Task_1", "Method": "Transformer_LRPE_PE_Re-ranking_Ensemble", "Metric": "ROUGE-2", "Task": "Text_Summarization", "score": "11.78"}, {"Material": "DUC_2004_Task_1", "Method": "Transformer_LRPE_PE_Re-ranking_Ensemble", "Metric": "ROUGE-L", "Task": "Text_Summarization", "score": "28.52"}]}
{"doc_id": "04640006606ddfb9d6aa4ce8f55855b1f23ec7ed", "arxiv_id": "1605.07146", "title": "Wide Residual Networks", "n_ary_relations": [{"Material": "CIFAR-10", "Method": "Wide_ResNet", "Metric": "Percentage_correct", "Task": "Image_Classification", "score": "96.11"}, {"Material": "CIFAR-10", "Method": "Wide_ResNet", "Metric": "Percentage_error", "Task": "Image_Classification", "score": "3.89"}, {"Material": "CIFAR-100", "Method": "Wide_ResNet", "Metric": "Percentage_correct", "Task": "Image_Classification", "score": "81.15"}, {"Material": "CIFAR-100", "Method": "Wide_ResNet", "Metric": "Percentage_error", "Task": "Image_Classification", "score": "18.85"}, {"Material": "SVHN", "Method": "Wide_ResNet", "Metric": "Percentage_error", "Task": "Image_Classification", "score": "1.7"}]}
{"doc_id": "04957e40d47ca89d38653e97f728883c0ad26e5d", "arxiv_id": "1712.00726", "title": "Cascade R-CNN: Delving Into High Quality Object Detection", "n_ary_relations": [{"Material": "COCO", "Method": "Cascade_R-CNN", "Metric": "Bounding_Box_AP", "Task": "Object_Detection", "score": "42.8"}]}
{"doc_id": "051b3763c2ad4e4271db712b0e9a4cfe298d05db", "arxiv_id": "", "title": "Supplementary Material for LiteFlowNet: A Lightweight Convolutional Neural Network for Optical Flow Estimation", "n_ary_relations": [{"Material": "Sintel-clean", "Method": "LiteFlowNet", "Metric": "Average_End-Point_Error", "Task": "Optical_Flow_Estimation", "score": "4.54"}, {"Material": "Sintel-final", "Method": "LiteFlowNet", "Metric": "Average_End-Point_Error", "Task": "Optical_Flow_Estimation", "score": "5.38"}]}
{"doc_id": "052282998bc24db695891f755a00e3cebd3fd796", "arxiv_id": "1704.04651", "title": "The Reactor: A Sample-Efficient Actor-Critic Architecture", "n_ary_relations": [{"Material": "Atari-57", "Method": "Reactor", "Metric": "Medium_Human-Normalized_Score", "Task": "Atari_Games", "score": "187.0%"}]}
{"doc_id": "0523e14247d74c4505cd5e32e1f0495f291ec432", "arxiv_id": "", "title": "Factoring Variations in Natural Images with Deep Gaussian Mixture Models", "n_ary_relations": [{"Material": "CIFAR-10", "Method": "Deep_GMM", "Metric": "NLL_Test", "Task": "Image_Generation", "score": "4.00"}]}
{"doc_id": "052443e1709c0f7d3432cca7c451534eea76b7ca", "arxiv_id": "1511.02228", "title": "Seven Ways to Improve Example-Based Single Image Super Resolution", "n_ary_relations": [{"Material": "BSD100_-_4x_upscaling", "Method": "IA", "Metric": "PSNR", "Task": "Image_Super-Resolution", "score": "27.16"}, {"Material": "Set14_-_4x_upscaling", "Method": "IA", "Metric": "PSNR", "Task": "Image_Super-Resolution", "score": "27.88"}, {"Material": "Set5_-_4x_upscaling", "Method": "IA", "Metric": "PSNR", "Task": "Image_Super-Resolution", "score": "31.10"}]}
{"doc_id": "05357b8c05b5bc020e871fc330a88910c3177e4d", "arxiv_id": "1704.00138", "title": "Multiple Instance Detection Network with Online Instance Classifier Refinement", "n_ary_relations": [{"Material": "ImageNet", "Method": "Online_Instance_Classifier_Refinement", "Metric": "MAP", "Task": "Weakly_Supervised_Object_Detection", "score": "6"}, {"Material": "PASCAL_VOC_2007", "Method": "OICR-Ens___FRCNN", "Metric": "MAP", "Task": "Weakly_Supervised_Object_Detection", "score": "47.0"}, {"Material": "PASCAL_VOC_2012", "Method": "OICR-Ens___FRCNN", "Metric": "MAP", "Task": "Weakly_Supervised_Object_Detection", "score": "42.5"}]}
{"doc_id": "05ee231749c9ce97f036c71c1d2d599d660a8c81", "arxiv_id": "1810.09951", "title": "GhostVLAD for set-based face recognition", "n_ary_relations": [{"Material": "IJB-A", "Method": "SE-GV-3", "Metric": "TAR___FAR_0_01", "Task": "Face_Recognition", "score": "0.972"}, {"Material": "IJB-B", "Method": "GhostVLAD__SE-GV-3", "Metric": "TAR___FAR_0_01", "Task": "Face_Recognition", "score": "0.963"}]}
{"doc_id": "060ff1aad5619a7d6d6cdfaf8be5da29bff3808c", "arxiv_id": "1804.08199", "title": "Linguistically-Informed Self-Attention for Semantic Role Labeling", "n_ary_relations": [{"Material": "CoNLL_2005", "Method": "LISA", "Metric": "F1", "Task": "Predicate_Detection", "score": "98.4"}, {"Material": "CoNLL_2005", "Method": "LISA", "Metric": "F1", "Task": "Semantic_Role_Labeling", "score": "86.04"}, {"Material": "CoNLL_2005", "Method": "LISA", "Metric": "F1", "Task": "Semantic_Role_Labeling__predicted_predicates_", "score": "84.99"}, {"Material": "CoNLL_2005", "Method": "LISA___ELMo", "Metric": "F1", "Task": "Semantic_Role_Labeling__predicted_predicates_", "score": "86.90"}, {"Material": "CoNLL_2012", "Method": "LISA", "Metric": "F1", "Task": "Predicate_Detection", "score": "97.2"}, {"Material": "CoNLL_2012", "Method": "LISA", "Metric": "F1", "Task": "Semantic_Role_Labeling__predicted_predicates_", "score": "82.33"}, {"Material": "CoNLL_2012", "Method": "LISA___ELMo", "Metric": "F1", "Task": "Semantic_Role_Labeling__predicted_predicates_", "score": "83.38"}]}
{"doc_id": "06150e6e69a379c27e1d0100fcd7660f073cbacf", "arxiv_id": "", "title": "Local Decorrelation For Improved Pedestrian Detection", "n_ary_relations": [{"Material": "Caltech", "Method": "LDCF", "Metric": "Reasonable_Miss_Rate", "Task": "Pedestrian_Detection", "score": "24.8"}]}
{"doc_id": "061c05faf3d68a7bdade9d4debeab369e2f9746c", "arxiv_id": "1701.06264", "title": "Loss-Sensitive Generative Adversarial Networks on Lipschitz Densities", "n_ary_relations": [{"Material": "CIFAR-10", "Method": "CLS-GAN", "Metric": "Percentage_correct", "Task": "Image_Classification", "score": "91.7"}, {"Material": "SVHN", "Method": "CLS-GAN", "Metric": "Percentage_error", "Task": "Image_Classification", "score": "5.98"}]}
{"doc_id": "063ad0349f05c8aacbbb653ffcf01047a293fa30", "arxiv_id": "1610.03771", "title": "SentiHood: Targeted Aspect Based Sentiment Analysis Dataset for Urban Neighbourhoods", "n_ary_relations": [{"Material": "Sentihood", "Method": "LSTM-LOC", "Metric": "Aspect", "Task": "Aspect-Based_Sentiment_Analysis", "score": "69.3"}, {"Material": "Sentihood", "Method": "LSTM-LOC", "Metric": "Sentiment", "Task": "Aspect-Based_Sentiment_Analysis", "score": "81.9"}]}
{"doc_id": "06b4d8409837dce9d6eb919efd1debdaecc40d01", "arxiv_id": "1409.5185", "title": "Deeply-Supervised Nets", "n_ary_relations": [{"Material": "CIFAR-10", "Method": "DSN", "Metric": "Percentage_correct", "Task": "Image_Classification", "score": "91.8"}, {"Material": "CIFAR-100", "Method": "DSN", "Metric": "Percentage_correct", "Task": "Image_Classification", "score": "65.4"}, {"Material": "MNIST", "Method": "DSN", "Metric": "Percentage_error", "Task": "Image_Classification", "score": "0.4"}, {"Material": "SVHN", "Method": "DSN", "Metric": "Percentage_error", "Task": "Image_Classification", "score": 1.92}]}
{"doc_id": "06c06885fd53b2cbd407704cf14f658842ed48e5", "arxiv_id": "1511.04491", "title": "Deeply-Recursive Convolutional Network for Image Super-Resolution", "n_ary_relations": [{"Material": "BSD100_-_4x_upscaling", "Method": "DRCN", "Metric": "MOS", "Task": "Image_Super-Resolution", "score": "2.12"}, {"Material": "BSD100_-_4x_upscaling", "Method": "DRCN", "Metric": "PSNR", "Task": "Image_Super-Resolution", "score": "27.21"}, {"Material": "BSD100_-_4x_upscaling", "Method": "DRCN", "Metric": "SSIM", "Task": "Image_Super-Resolution", "score": "0.7493"}, {"Material": "Set14_-_4x_upscaling", "Method": "DRCN", "Metric": "MOS", "Task": "Image_Super-Resolution", "score": "2.84"}, {"Material": "Set14_-_4x_upscaling", "Method": "DRCN", "Metric": "PSNR", "Task": "Image_Super-Resolution", "score": "28.02"}, {"Material": "Set14_-_4x_upscaling", "Method": "DRCN", "Metric": "SSIM", "Task": "Image_Super-Resolution", "score": "0.8074"}, {"Material": "Set5_-_4x_upscaling", "Method": "DRCN", "Metric": "MOS", "Task": "Image_Super-Resolution", "score": "3.26"}, {"Material": "Set5_-_4x_upscaling", "Method": "DRCN", "Metric": "PSNR", "Task": "Image_Super-Resolution", "score": "31.52"}, {"Material": "Set5_-_4x_upscaling", "Method": "DRCN", "Metric": "SSIM", "Task": "Image_Super-Resolution", "score": "0.8938"}]}
{"doc_id": "06c5b86b638b2f3572b9cdd9ef0be4740b16781b", "arxiv_id": "1807.04990", "title": "A Multi-sentiment-resource Enhanced Attention Network for Sentiment Classification", "n_ary_relations": [{"Material": "MR", "Method": "MEAN", "Metric": "Accuracy", "Task": "Sentiment_Analysis", "score": "84.5"}, {"Material": "SST-5_Fine-grained_classification", "Method": "MEAN", "Metric": "Accuracy", "Task": "Sentiment_Analysis", "score": "51.4"}]}
{"doc_id": "07045f87709d0b7b998794e9fa912c0aba912281", "arxiv_id": "1505.04597", "title": "U-Net: Convolutional Networks for Biomedical Image Segmentation", "n_ary_relations": [{"Material": "CHASE_DB1", "Method": "U-Net", "Metric": "AUC", "Task": "Retinal_Vessel_Segmentation", "score": "0.9772"}, {"Material": "CHASE_DB1", "Method": "U-Net", "Metric": "F1_score", "Task": "Retinal_Vessel_Segmentation", "score": "0.7783"}, {"Material": "CT-150", "Method": "U-Net", "Metric": "Dice_Score", "Task": "Pancreas_Segmentation", "score": "0.814"}, {"Material": "CT-150", "Method": "U-Net", "Metric": "Precision", "Task": "Pancreas_Segmentation", "score": "0.848"}, {"Material": "CT-150", "Method": "U-Net", "Metric": "Recall", "Task": "Pancreas_Segmentation", "score": "0.806"}, {"Material": "DIC-HeLa", "Method": "U-Net", "Metric": "Mean_IoU", "Task": "Cell_Segmentation", "score": "0.7756"}, {"Material": "DRIVE", "Method": "U-Net", "Metric": "AUC", "Task": "Retinal_Vessel_Segmentation", "score": "0.9755"}, {"Material": "DRIVE", "Method": "U-Net", "Metric": "F1_score", "Task": "Retinal_Vessel_Segmentation", "score": "0.8142"}, {"Material": "ISBI_2012_EM_Segmentation", "Method": "U-Net", "Metric": "Warping_Error", "Task": "Medical_Image_Segmentation", "score": "0.000353"}, {"Material": "Kaggle_Skin_Lesion_Segmentation", "Method": "U-Net", "Metric": "AUC", "Task": "Skin_Cancer_Segmentation", "score": "0.9371"}, {"Material": "Kaggle_Skin_Lesion_Segmentation", "Method": "U-Net", "Metric": "F1_score", "Task": "Skin_Cancer_Segmentation", "score": "0.8682"}, {"Material": "LUNA", "Method": "U-Net", "Metric": "AUC", "Task": "Lung_Nodule_Segmentation", "score": "0.9784"}, {"Material": "LUNA", "Method": "U-Net", "Metric": "F1_score", "Task": "Lung_Nodule_Segmentation", "score": "0.9658"}, {"Material": "PhC-U373", "Method": "U-Net", "Metric": "Mean_IoU", "Task": "Cell_Segmentation", "score": "0.9203"}, {"Material": "STARE", "Method": "U-Net", "Metric": "AUC", "Task": "Retinal_Vessel_Segmentation", "score": "0.9898"}, {"Material": "STARE", "Method": "U-Net", "Metric": "F1_score", "Task": "Retinal_Vessel_Segmentation", "score": "0.8373"}]}
{"doc_id": "071b16f25117fb6133480c6259227d54fc2a5ea0", "arxiv_id": "1409.0473", "title": "Neural Machine Translation by Jointly Learning to Align and Translate", "n_ary_relations": [{"Material": "IWSLT2015_German-English", "Method": "Bi-GRU__MLE_SLE_", "Metric": "BLEU_score", "Task": "Machine_Translation", "score": "28.53"}, {"Material": "WMT2014_English-French", "Method": "RNN-search50_", "Metric": "BLEU_score", "Task": "Machine_Translation", "score": 36.15}]}
{"doc_id": "072fd0b8d471f183da0ca9880379b3bb29031b6a", "arxiv_id": "1611.07004", "title": "Image-to-Image Translation with Conditional Adversarial Networks", "n_ary_relations": [{"Material": "Aerial-to-Map", "Method": "cGAN", "Metric": "Class_IOU", "Task": "Image-to-Image_Translation", "score": "0.26"}, {"Material": "Aerial-to-Map", "Method": "cGAN", "Metric": "Per-class_Accuracy", "Task": "Image-to-Image_Translation", "score": "46%"}, {"Material": "Aerial-to-Map", "Method": "cGAN", "Metric": "Per-pixel_Accuracy", "Task": "Image-to-Image_Translation", "score": "70%"}, {"Material": "Cityscapes_Labels-to-Photo", "Method": "pix2pix", "Metric": "Class_IOU", "Task": "Image-to-Image_Translation", "score": "0.18"}, {"Material": "Cityscapes_Labels-to-Photo", "Method": "pix2pix", "Metric": "Per-class_Accuracy", "Task": "Image-to-Image_Translation", "score": "25%"}, {"Material": "Cityscapes_Labels-to-Photo", "Method": "pix2pix", "Metric": "Per-pixel_Accuracy", "Task": "Image-to-Image_Translation", "score": "71%"}, {"Material": "Cityscapes_Photo-to-Labels", "Method": "pix2pix", "Metric": "Class_IOU", "Task": "Image-to-Image_Translation", "score": "0.32"}, {"Material": "Cityscapes_Photo-to-Labels", "Method": "pix2pix", "Metric": "Per-class_Accuracy", "Task": "Image-to-Image_Translation", "score": "40%"}, {"Material": "Cityscapes_Photo-to-Labels", "Method": "pix2pix", "Metric": "Per-pixel_Accuracy", "Task": "Image-to-Image_Translation", "score": "85%"}]}
{"doc_id": "074b6fe0cc6848fb86a6703d1c52074494177c79", "arxiv_id": "", "title": "CyCADA: Cycle-Consistent Adversarial Domain Adaptation", "n_ary_relations": [{"Material": "GTAV-to-Cityscapes_Labels", "Method": "CyCADA_pixel_feat", "Metric": "Per-pixel_Accuracy", "Task": "Synthetic-to-Real_Translation", "score": "82.3%"}, {"Material": "GTAV-to-Cityscapes_Labels", "Method": "CyCADA_pixel_feat", "Metric": "fwIOU", "Task": "Synthetic-to-Real_Translation", "score": "72.4"}, {"Material": "GTAV-to-Cityscapes_Labels", "Method": "CyCADA_pixel_feat", "Metric": "mIoU", "Task": "Synthetic-to-Real_Translation", "score": "39.5"}, {"Material": "SVNH-to-MNIST", "Method": "CyCADA_pixel_feat", "Metric": "Classification_Accuracy", "Task": "Unsupervised_Image-To-Image_Translation", "score": "90.4%"}, {"Material": "SYNTHIA_Fall-to-Winter", "Method": "CyCADA", "Metric": "Per-pixel_Accuracy", "Task": "Image-to-Image_Translation", "score": "92.1%"}, {"Material": "SYNTHIA_Fall-to-Winter", "Method": "CyCADA", "Metric": "fwIOU", "Task": "Image-to-Image_Translation", "score": "85.7"}, {"Material": "SYNTHIA_Fall-to-Winter", "Method": "CyCADA", "Metric": "mIoU", "Task": "Image-to-Image_Translation", "score": "63.3"}]}
{"doc_id": "07c4fc48ad7b7d1a417b0bb72d0ae2d4efc5aa83", "arxiv_id": "1706.03059", "title": "Depthwise Separable Convolutions for Neural Machine Translation", "n_ary_relations": [{"Material": "WMT2014_English-German", "Method": "SliceNet", "Metric": "BLEU_score", "Task": "Machine_Translation", "score": 26.1}]}
{"doc_id": "07cca2bdd0dc2fee02889e17789748eba9d06ffa", "arxiv_id": "", "title": "Inferring hybrid transportation modes from sparse GPS data using a moving window SVM classification", "n_ary_relations": [{"Material": "GPS", "Method": "Support_Vector_Machines", "Metric": "Accuracy", "Task": "Trajectory_Prediction", "score": "88%"}]}
{"doc_id": "07f3f736d90125cb2b04e7408782af411c67dd5a", "arxiv_id": "1503.03244", "title": "Convolutional Neural Network Architectures for Matching Natural Language Sentences", "n_ary_relations": [{"Material": "SemEvalCQA", "Method": "ARC-II", "Metric": "MAP", "Task": "Question_Answering", "score": "0.780"}, {"Material": "SemEvalCQA", "Method": "ARC-II", "Metric": "P_1", "Task": "Question_Answering", "score": "0.753"}]}
{"doc_id": "0875fc92cce33df5cf7df169590dbf0ca00d2652", "arxiv_id": "1511.02793", "title": "Generating Images from Captions with Attention", "n_ary_relations": [{"Material": "MS-COCO", "Method": "AttnGAN_OP", "Metric": "Inception_score", "Task": "Text-to-Image_Generation", "score": "24.76"}, {"Material": "MS-COCO", "Method": "StackGAN_OP", "Metric": "Inception_score", "Task": "Text-to-Image_Generation", "score": "12.12"}]}
{"doc_id": "0891ed6ed64fb461bc03557b28c686f87d880c9a", "arxiv_id": "1603.01360", "title": "Neural Architectures for Named Entity Recognition", "n_ary_relations": [{"Material": "CoNLL_2003__English_", "Method": "LSTM-CRF", "Metric": "F1", "Task": "Named_Entity_Recognition__NER_", "score": "90.94"}]}
{"doc_id": "0899bb0f3d5425c88b358638bb8556729720c8db", "arxiv_id": "1902.01275", "title": "Implicit 3D Orientation Learning for 6D Object Detection from RGB Images", "n_ary_relations": [{"Material": "T-LESS", "Method": "RetinaNet_Augmented_Autoencoders_ICP", "Metric": "Accuracy", "Task": "6D_Pose_Estimation", "score": "57.14"}]}
{"doc_id": "08d55271589f989d90a7edce3345f78f2468a7e0", "arxiv_id": "1704.03373", "title": "Quality Aware Network for Set to Set Recognition", "n_ary_relations": [{"Material": "YouTube_Faces_DB", "Method": "QAN", "Metric": "Accuracy", "Task": "Face_Verification", "score": "96.17%"}]}
{"doc_id": "0985497d1de3ffd11713e75289cc2ad55836623d", "arxiv_id": "1805.02220", "title": "Multi-Passage Machine Reading Comprehension with Cross-Passage Answer Verification", "n_ary_relations": [{"Material": "MS_MARCO", "Method": "VNET", "Metric": "BLEU-1", "Task": "Question_Answering", "score": "54.37"}, {"Material": "MS_MARCO", "Method": "VNET", "Metric": "Rouge-L", "Task": "Question_Answering", "score": "51.63"}]}
{"doc_id": "09879f7956dddc2a9328f5c1472feeb8402bcbcf", "arxiv_id": "1605.08803", "title": "Density estimation using Real NVP", "n_ary_relations": [{"Material": "CIFAR-10", "Method": "PixelRNN", "Metric": "Model_Entropy", "Task": "Image_Generation", "score": "3"}, {"Material": "CIFAR-10", "Method": "Real_NVP", "Metric": "Model_Entropy", "Task": "Image_Generation", "score": "3.5"}]}
{"doc_id": "09da677bdbba113374d8fe4bb15ecfbdb4c8fe40", "arxiv_id": "1707.01629", "title": "Dual Path Networks", "n_ary_relations": [{"Material": "ImageNet", "Method": "DPN-131", "Metric": "Top_1_Accuracy", "Task": "Image_Classification", "score": "81.5%"}, {"Material": "ImageNet", "Method": "DPN-131", "Metric": "Top_5_Accuracy", "Task": "Image_Classification", "score": "95.8%"}]}
{"doc_id": "09ec60f2eea5d43792b2bc9da63b1c9b7719f666", "arxiv_id": "1804.03786", "title": "Nonlinear 3D Face Morphable Model", "n_ary_relations": [{"Material": "AFLW2000", "Method": "Nonlinear_3D_Face_Morphable_Model", "Metric": "Error_rate", "Task": "Face_Alignment", "score": "4.70"}]}
{"doc_id": "0a053f55804eee01f3c8b4138a1d3364d5bc45ac", "arxiv_id": "1802.04394", "title": "M-Walk: Learning to Walk over Graphs using Monte Carlo Tree Search", "n_ary_relations": [{"Material": "WN18RR", "Method": "M-Walk", "Metric": "Hits_1", "Task": "Link_Prediction", "score": "0.414"}, {"Material": "WN18RR", "Method": "M-Walk", "Metric": "Hits_3", "Task": "Link_Prediction", "score": "0.445"}, {"Material": "WN18RR", "Method": "M-Walk", "Metric": "MRR", "Task": "Link_Prediction", "score": "0.437"}]}
{"doc_id": "0a1dc95e4c884a91bd141df8133d1b4961178123", "arxiv_id": "1501.00092", "title": "Image Super-Resolution Using Deep Convolutional Networks", "n_ary_relations": [{"Material": "BSD100_-_4x_upscaling", "Method": "SRCNN", "Metric": "PSNR", "Task": "Image_Super-Resolution", "score": "26.90"}, {"Material": "BSD100_-_4x_upscaling", "Method": "SRCNN", "Metric": "SSIM", "Task": "Image_Super-Resolution", "score": "0.7101"}, {"Material": "Manga109_-_4x_upscaling", "Method": "SRCNN", "Metric": "PSNR", "Task": "Image_Super-Resolution", "score": "27.58"}, {"Material": "Manga109_-_4x_upscaling", "Method": "SRCNN", "Metric": "SSIM", "Task": "Image_Super-Resolution", "score": "0.8555"}, {"Material": "Set14_-_4x_upscaling", "Method": "SRCNN", "Metric": "PSNR", "Task": "Image_Super-Resolution", "score": "27.50"}, {"Material": "Set14_-_4x_upscaling", "Method": "SRCNN", "Metric": "SSIM", "Task": "Image_Super-Resolution", "score": "0.7513"}, {"Material": "Set5_-_4x_upscaling", "Method": "SRCNN", "Metric": "PSNR", "Task": "Image_Super-Resolution", "score": "30.49"}, {"Material": "Set5_-_4x_upscaling", "Method": "SRCNN", "Metric": "SSIM", "Task": "Image_Super-Resolution", "score": "0.8628"}, {"Material": "Ultra_Video_Group_HD_-_4x_upscaling", "Method": "SRCNN", "Metric": "Average_PSNR", "Task": "Video_Super-Resolution", "score": "37.52"}, {"Material": "Urban100_-_4x_upscaling", "Method": "SRCNN", "Metric": "PSNR", "Task": "Image_Super-Resolution", "score": "24.52"}, {"Material": "Urban100_-_4x_upscaling", "Method": "SRCNN", "Metric": "SSIM", "Task": "Image_Super-Resolution", "score": "0.7221"}, {"Material": "Vid4_-_4x_upscaling", "Method": "SRCNN", "Metric": "MOVIE", "Task": "Video_Super-Resolution", "score": "6.90"}, {"Material": "Vid4_-_4x_upscaling", "Method": "SRCNN", "Metric": "PSNR", "Task": "Video_Super-Resolution", "score": "24.68"}, {"Material": "Vid4_-_4x_upscaling", "Method": "SRCNN", "Metric": "SSIM", "Task": "Video_Super-Resolution", "score": "0.7158"}, {"Material": "Xiph_HD_-_4x_upscaling", "Method": "SRCNN", "Metric": "Average_PSNR", "Task": "Video_Super-Resolution", "score": "31.47"}]}
{"doc_id": "0a34fe39e9938ae8c813a81ae6d2d3a325600e5c", "arxiv_id": "1708.07517", "title": "FacePoseNet: Making a Case for Landmark-Free Face Alignment", "n_ary_relations": [{"Material": "300W", "Method": "FPN", "Metric": "Mean_Error_Rate", "Task": "Facial_Landmark_Detection", "score": "0.1043"}, {"Material": "IJB-A", "Method": "FPN", "Metric": "Accuracy", "Task": "Face_Identification", "score": "91.4%"}, {"Material": "IJB-A", "Method": "FPN", "Metric": "TAR___FAR_0_01", "Task": "Face_Verification", "score": "90.1%"}, {"Material": "IJB-B", "Method": "FPN", "Metric": "Accuracy", "Task": "Face_Identification", "score": "91.1%"}, {"Material": "IJB-B", "Method": "FPN", "Metric": "TAR___FAR_0_01", "Task": "Face_Verification", "score": "96.5%"}]}
{"doc_id": "0a3a003457f5d7758a42a0e4b7278b39a86ed0bd", "arxiv_id": "1812.02391", "title": "Meta-Transfer Learning for Few-Shot Learning", "n_ary_relations": [{"Material": "Mini-ImageNet_-_1-Shot_Learning", "Method": "MTL", "Metric": "Accuracy", "Task": "Few-Shot_Image_Classification", "score": "61.2%"}, {"Material": "Mini-ImageNet_-_1-Shot_Learning", "Method": "MTL", "Metric": "Accuracy", "Task": "Few-Shot_Learning", "score": "61.2%"}, {"Material": "Mini-ImageNet_-_5-Shot_Learning", "Method": "MTL", "Metric": "Accuracy", "Task": "Few-Shot_Image_Classification", "score": "75.5%"}]}
{"doc_id": "0a49b4de21363d86599d4a058aaf4f5aed019495", "arxiv_id": "1603.06147", "title": "A Character-level Decoder without Explicit Segmentation for Neural Machine Translation", "n_ary_relations": [{"Material": "WMT2015_English-German", "Method": "Enc-Dec_Att__BPE_", "Metric": "BLEU_score", "Task": "Machine_Translation", "score": 21.72}, {"Material": "WMT2015_English-German", "Method": "Enc-Dec_Att__char_", "Metric": "BLEU_score", "Task": "Machine_Translation", "score": 23.45}]}
{"doc_id": "0a6d7e8e61c54c796f53120fdb86a25177e00998", "arxiv_id": "1606.06357", "title": "Complex Embeddings for Simple Link Prediction", "n_ary_relations": [{"Material": "WN18", "Method": "ComplEx", "Metric": "Hits_1", "Task": "Link_Prediction", "score": "0.936"}, {"Material": "WN18", "Method": "ComplEx", "Metric": "Hits_10", "Task": "Link_Prediction", "score": "0.947"}, {"Material": "WN18", "Method": "ComplEx", "Metric": "Hits_3", "Task": "Link_Prediction", "score": "0.936"}, {"Material": "WN18", "Method": "ComplEx", "Metric": "MRR", "Task": "Link_Prediction", "score": "0.941"}]}
{"doc_id": "0a78873e41615798d09391d9f40d41666b8c9beb", "arxiv_id": "1806.04185", "title": "A Corpus with Multi-Level Annotations of Patients, Interventions and Outcomes to Support Language Processing for Medical Literature", "n_ary_relations": [{"Material": "EBM-NLP", "Method": "bi-LSTM", "Metric": "F1", "Task": "Participant_Intervention_Comparison_Outcome_Extraction", "score": "66.30"}]}
{"doc_id": "0abb49fe138e8fb7332c26b148a48d0db39724fc", "arxiv_id": "1301.3557", "title": "Stochastic Pooling for Regularization of Deep Convolutional Neural Networks", "n_ary_relations": [{"Material": "CIFAR-10", "Method": "Stochastic_Pooling", "Metric": "Percentage_correct", "Task": "Image_Classification", "score": "84.9"}, {"Material": "CIFAR-100", "Method": "Stochastic_Pooling", "Metric": "Percentage_correct", "Task": "Image_Classification", "score": "57.5"}, {"Material": "SVHN", "Method": "Stochastic_Pooling", "Metric": "Percentage_error", "Task": "Image_Classification", "score": 2.8}]}
{"doc_id": "0b0cf7e00e7532e38238a9164f0a8db2574be2ea", "arxiv_id": "1706.03762", "title": "Attention is All you Need", "n_ary_relations": [{"Material": "IWSLT2015_English-German", "Method": "Transformer", "Metric": "BLEU_score", "Task": "Machine_Translation", "score": "28.23"}, {"Material": "IWSLT2015_German-English", "Method": "Transformer", "Metric": "BLEU_score", "Task": "Machine_Translation", "score": "34.44"}, {"Material": "Penn_Treebank", "Method": "Transformer", "Metric": "F1_score", "Task": "Constituency_Parsing", "score": "92.7"}, {"Material": "WMT2014_English-French", "Method": "Transformer_Base", "Metric": "BLEU_score", "Task": "Machine_Translation", "score": "38.1"}, {"Material": "WMT2014_English-French", "Method": "Transformer_Big", "Metric": "BLEU_score", "Task": "Machine_Translation", "score": "41.0"}, {"Material": "WMT2014_English-German", "Method": "Transformer_Base", "Metric": "BLEU_score", "Task": "Machine_Translation", "score": "27.3"}, {"Material": "WMT2014_English-German", "Method": "Transformer_Big", "Metric": "BLEU_score", "Task": "Machine_Translation", "score": "28.4"}]}
{"doc_id": "0b544dfe355a5070b60986319a3f51fb45d1348e", "arxiv_id": "1406.1078", "title": "Learning Phrase Representations using RNN Encoder\u2013Decoder for Statistical Machine Translation", "n_ary_relations": [{"Material": "WMT2014_English-French", "Method": "CSLM___RNN___WP", "Metric": "BLEU_score", "Task": "Machine_Translation", "score": "34.54"}]}
{"doc_id": "0b5519f76fc8e31ecf9931f00184aee86694e3a4", "arxiv_id": "1811.11482", "title": "Image Reconstruction with Predictive Filter Flow", "n_ary_relations": [{"Material": "Set14_-_4x_upscaling", "Method": "PFF", "Metric": "PSNR", "Task": "Image_Super-Resolution", "score": "28.98"}, {"Material": "Set14_-_4x_upscaling", "Method": "PFF", "Metric": "SSIM", "Task": "Image_Super-Resolution", "score": "0.7904"}, {"Material": "Set5_-_4x_upscaling", "Method": "PFF", "Metric": "PSNR", "Task": "Image_Super-Resolution", "score": "32.74"}, {"Material": "Set5_-_4x_upscaling", "Method": "PFF", "Metric": "SSIM", "Task": "Image_Super-Resolution", "score": "0.9021"}]}
{"doc_id": "0b5aef2894d3248fb5ecc955d50501f0aa276036", "arxiv_id": "1806.06228", "title": "Multimodal Sentiment Analysis using Hierarchical Fusion with Context Modeling", "n_ary_relations": [{"Material": "IEMOCAP", "Method": "CHFusion", "Metric": "F1", "Task": "Multimodal_Emotion_Recognition", "score": "55.3%"}, {"Material": "MOSI", "Method": "CHFusion", "Metric": "Accuracy", "Task": "Multimodal_Sentiment_Analysis", "score": "76.5%"}]}
{"doc_id": "0b8759d61e93b809df16d9fe9010d2a2d7241c74", "arxiv_id": "1511.07289", "title": "Fast and Accurate Deep Network Learning by Exponential Linear Units (ELUs)", "n_ary_relations": [{"Material": "CIFAR-10", "Method": "Exponential_Linear_Units", "Metric": "Percentage_correct", "Task": "Image_Classification", "score": "93.5"}, {"Material": "CIFAR-100", "Method": "Exponential_Linear_Units", "Metric": "Percentage_correct", "Task": "Image_Classification", "score": "75.7"}]}
{"doc_id": "0be9ca65ad318ee3729928882ef2c403d4b6d24e", "arxiv_id": "1808.10143", "title": "Direct Output Connection for a High-Rank Language Model", "n_ary_relations": [{"Material": "Penn_Treebank", "Method": "LSTM_Encoder-Decoder___LSTM-LM", "Metric": "F1_score", "Task": "Constituency_Parsing", "score": "94.47"}, {"Material": "Penn_Treebank__Word_Level_", "Method": "AWD-LSTM-DOC", "Metric": "Params", "Task": "Language_Modelling", "score": "23M"}, {"Material": "Penn_Treebank__Word_Level_", "Method": "AWD-LSTM-DOC_x5", "Metric": "Params", "Task": "Language_Modelling", "score": "185M"}, {"Material": "Penn_Treebank__Word_Level_", "Method": "AWD-LSTM-DOC", "Metric": "Test_perplexity", "Task": "Language_Modelling", "score": "52.38"}, {"Material": "Penn_Treebank__Word_Level_", "Method": "AWD-LSTM-DOC_x5", "Metric": "Test_perplexity", "Task": "Language_Modelling", "score": "47.17"}, {"Material": "Penn_Treebank__Word_Level_", "Method": "AWD-LSTM-DOC", "Metric": "Validation_perplexity", "Task": "Language_Modelling", "score": "54.12"}, {"Material": "Penn_Treebank__Word_Level_", "Method": "AWD-LSTM-DOC_x5", "Metric": "Validation_perplexity", "Task": "Language_Modelling", "score": "48.63"}, {"Material": "WikiText-2", "Method": "AWD-LSTM-DOC", "Metric": "Number_of_params", "Task": "Language_Modelling", "score": "37M"}, {"Material": "WikiText-2", "Method": "AWD-LSTM-DOC_x5", "Metric": "Number_of_params", "Task": "Language_Modelling", "score": "185M"}, {"Material": "WikiText-2", "Method": "AWD-LSTM-DOC", "Metric": "Test_perplexity", "Task": "Language_Modelling", "score": "58.03"}, {"Material": "WikiText-2", "Method": "AWD-LSTM-DOC_x5", "Metric": "Test_perplexity", "Task": "Language_Modelling", "score": "53.09"}, {"Material": "WikiText-2", "Method": "AWD-LSTM-DOC", "Metric": "Validation_perplexity", "Task": "Language_Modelling", "score": "60.29"}, {"Material": "WikiText-2", "Method": "AWD-LSTM-DOC_x5", "Metric": "Validation_perplexity", "Task": "Language_Modelling", "score": "54.19"}]}
{"doc_id": "0c278ecf472f42ec1140ca2f1a0a3dd60cbe5c48", "arxiv_id": "", "title": "", "n_ary_relations": [{"Material": "Atari_2600_Montezuma_s_Revenge", "Method": "DQN_SR", "Metric": "Score", "Task": "Atari_Games", "score": "1778.8"}]}
{"doc_id": "0c36c988acc9ec239953ff1b3931799af388ef70", "arxiv_id": "1802.02142", "title": "Face Detection Using Improved Faster RCNN", "n_ary_relations": [{"Material": "WIDER_Face__Easy_", "Method": "FDNet", "Metric": "AP", "Task": "Face_Detection", "score": "0.950"}, {"Material": "WIDER_Face__Hard_", "Method": "FDNet", "Metric": "AP", "Task": "Face_Detection", "score": "0.878"}, {"Material": "WIDER_Face__Medium_", "Method": "FDNet", "Metric": "AP", "Task": "Face_Detection", "score": "0.939"}]}
{"doc_id": "0c769c19d894e0dbd6eb314781dc1db3c626df57", "arxiv_id": "1604.01850", "title": "Joint Detection and Identification Feature Learning for Person Search", "n_ary_relations": [{"Material": "DukeMTMC-reID", "Method": "OIM", "Metric": "MAP", "Task": "Person_Re-Identification", "score": "47.4"}, {"Material": "DukeMTMC-reID", "Method": "OIM", "Metric": "Rank-1", "Task": "Person_Re-Identification", "score": "68.1"}]}
{"doc_id": "0c9ae806059196007938f24d0327a4237ed6adf5", "arxiv_id": "1807.06653", "title": "Invariant Information Clustering for Unsupervised Image Classification and Segmentation", "n_ary_relations": [{"Material": "MNIST", "Method": "IIC", "Metric": "Accuracy", "Task": "Unsupervised_MNIST", "score": "99.3"}]}
{"doc_id": "0ca2bd0e40a8f0a57665535ae1c31561370ad183", "arxiv_id": "1609.01704", "title": "Hierarchical Multiscale Recurrent Neural Networks", "n_ary_relations": [{"Material": "Text8", "Method": "LayerNorm_HM-LSTM", "Metric": "Bit_per_Character__BPC_", "Task": "Language_Modelling", "score": "1.29"}, {"Material": "Text8", "Method": "LayerNorm_HM-LSTM", "Metric": "Number_of_params", "Task": "Language_Modelling", "score": "35M"}, {"Material": "enwiki8", "Method": "LN_HM-LSTM", "Metric": "Bit_per_Character__BPC_", "Task": "Language_Modelling", "score": "1.32"}, {"Material": "enwiki8", "Method": "LN_HM-LSTM", "Metric": "Number_of_params", "Task": "Language_Modelling", "score": "35M"}]}
{"doc_id": "0cb8f50580cc69191144bd503e268451ce966fa6", "arxiv_id": "1704.01212", "title": "Neural Message Passing for Quantum Chemistry", "n_ary_relations": [{"Material": "QM9", "Method": "MPNNs", "Metric": "Error_ratio", "Task": "Drug_Discovery", "score": "0.68"}]}
{"doc_id": "0cfdcf2a0e345cdf7e680c30d136fdedb0eccb28", "arxiv_id": "1804.09337", "title": "Learning a Discriminative Feature Network for Semantic Segmentation", "n_ary_relations": [{"Material": "Cityscapes", "Method": "Smooth_Network_with_Channel_Attention_Block", "Metric": "Mean_IoU", "Task": "Semantic_Segmentation", "score": "80.3%"}, {"Material": "PASCAL_VOC_2012", "Method": "Smooth_Network_with_Channel_Attention_Block", "Metric": "Mean_IoU", "Task": "Semantic_Segmentation", "score": "86.2%"}]}
{"doc_id": "0d0101e65e52ae0cec38bcd13c6a9d631979c577", "arxiv_id": "1605.07648", "title": "FractalNet: Ultra-Deep Neural Networks without Residuals", "n_ary_relations": [{"Material": "SVHN", "Method": "FractalNet", "Metric": "Percentage_error", "Task": "Image_Classification", "score": "2.01"}]}
{"doc_id": "0d24a0695c9fc669e643bad51d4e14f056329dec", "arxiv_id": "1607.07086", "title": "An Actor-Critic Algorithm for Sequence Prediction", "n_ary_relations": [{"Material": "IWSLT2015_English-German", "Method": "RNNsearch", "Metric": "BLEU_score", "Task": "Machine_Translation", "score": "25.04"}, {"Material": "IWSLT2015_German-English", "Method": "RNNsearch", "Metric": "BLEU_score", "Task": "Machine_Translation", "score": "29.98"}]}
{"doc_id": "0d467adaf936b112f570970c5210bdb3c626a717", "arxiv_id": "1612.01925", "title": "FlowNet 2.0: Evolution of Optical Flow Estimation with Deep Networks", "n_ary_relations": [{"Material": "HPatches", "Method": "FlowNet2", "Metric": "Viewpoint_I_AEPE", "Task": "Dense_Pixel_Correspondence_Estimation", "score": "5.99"}, {"Material": "HPatches", "Method": "FlowNet2", "Metric": "Viewpoint_II_AEPE", "Task": "Dense_Pixel_Correspondence_Estimation", "score": "15.55"}, {"Material": "HPatches", "Method": "FlowNet2", "Metric": "Viewpoint_III_AEPE", "Task": "Dense_Pixel_Correspondence_Estimation", "score": "17.09"}, {"Material": "HPatches", "Method": "FlowNet2", "Metric": "Viewpoint_IV_AEPE", "Task": "Dense_Pixel_Correspondence_Estimation", "score": "22.13"}, {"Material": "HPatches", "Method": "FlowNet2", "Metric": "Viewpoint_V_AEPE", "Task": "Dense_Pixel_Correspondence_Estimation", "score": "30.68"}]}
{"doc_id": "0d5fa5be4bfe085de8f88dbee1c3b2a6e5ab9ee2", "arxiv_id": "1704.08545", "title": "ICNet for Real-Time Semantic Segmentation on High-Resolution Images", "n_ary_relations": [{"Material": "CamVid", "Method": "ICNet", "Metric": "Frame__fps_", "Task": "Real-Time_Semantic_Segmentation", "score": "27.8"}, {"Material": "CamVid", "Method": "ICNet", "Metric": "Time__ms_", "Task": "Real-Time_Semantic_Segmentation", "score": "36"}, {"Material": "CamVid", "Method": "ICNet", "Metric": "mIoU", "Task": "Real-Time_Semantic_Segmentation", "score": "67.1%"}, {"Material": "Cityscapes", "Method": "ICNet", "Metric": "Frame__fps_", "Task": "Real-Time_Semantic_Segmentation", "score": "30.3"}, {"Material": "Cityscapes", "Method": "ICNet", "Metric": "Mean_IoU", "Task": "Semantic_Segmentation", "score": "70.6%"}, {"Material": "Cityscapes", "Method": "ICNet", "Metric": "Time__ms_", "Task": "Real-Time_Semantic_Segmentation", "score": "33"}, {"Material": "Cityscapes", "Method": "ICNet", "Metric": "mIoU", "Task": "Real-Time_Semantic_Segmentation", "score": "70.6%"}]}
{"doc_id": "0dab72129b4458d9e3dbf1f109848c2d6d7af8a8", "arxiv_id": "1508.05326", "title": "A large annotated corpus for learning natural language inference", "n_ary_relations": [{"Material": "SNLI", "Method": "__Unigram_and_bigram_features", "Metric": "__Test_Accuracy", "Task": "Natural_Language_Inference", "score": "78.2"}, {"Material": "SNLI", "Method": "100D_LSTM_encoders", "Metric": "__Test_Accuracy", "Task": "Natural_Language_Inference", "score": "77.6"}, {"Material": "SNLI", "Method": "Unlexicalized_features", "Metric": "__Test_Accuracy", "Task": "Natural_Language_Inference", "score": "50.4"}, {"Material": "SNLI", "Method": "__Unigram_and_bigram_features", "Metric": "__Train_Accuracy", "Task": "Natural_Language_Inference", "score": "99.7"}, {"Material": "SNLI", "Method": "100D_LSTM_encoders", "Metric": "__Train_Accuracy", "Task": "Natural_Language_Inference", "score": "84.8"}, {"Material": "SNLI", "Method": "Unlexicalized_features", "Metric": "__Train_Accuracy", "Task": "Natural_Language_Inference", "score": "49.4"}, {"Material": "SNLI", "Method": "__Unigram_and_bigram_features", "Metric": "Parameters", "Task": "Natural_Language_Inference", "score": ""}, {"Material": "SNLI", "Method": "100D_LSTM_encoders", "Metric": "Parameters", "Task": "Natural_Language_Inference", "score": "220k"}, {"Material": "SNLI", "Method": "Unlexicalized_features", "Metric": "Parameters", "Task": "Natural_Language_Inference", "score": ""}]}
{"doc_id": "0dcde9f2c5149f0e4c806db7b4cc4915bed077da", "arxiv_id": "1503.04596", "title": "Enhanced image classification with a fast-learning shallow convolutional neural network", "n_ary_relations": [{"Material": "CIFAR-10", "Method": "FLSCNN", "Metric": "Percentage_correct", "Task": "Image_Classification", "score": "75.9"}, {"Material": "MNIST", "Method": "FLSCNN", "Metric": "Percentage_error", "Task": "Image_Classification", "score": "0.4"}, {"Material": "SVHN", "Method": "FLSCNN", "Metric": "Percentage_error", "Task": "Image_Classification", "score": 3.96}]}
{"doc_id": "0e37c8f19eefeb0c20d92f5cb4df4153077c116b", "arxiv_id": "1506.03767", "title": "Spectral Representations for Convolutional Neural Networks", "n_ary_relations": [{"Material": "CIFAR-10", "Method": "Spectral_Representations_for_Convolutional_Neural_Networks", "Metric": "Percentage_correct", "Task": "Image_Classification", "score": "91.4"}, {"Material": "CIFAR-100", "Method": "Spectral_Representations_for_Convolutional_Neural_Networks", "Metric": "Percentage_correct", "Task": "Image_Classification", "score": "68.4"}]}
{"doc_id": "0e8753f550350e53824358ca3f0f8cfd2f2dc2f7", "arxiv_id": "1408.1717", "title": "Matrix Completion on Graphs", "n_ary_relations": [{"Material": "MovieLens_100K", "Method": "GMC", "Metric": "RMSE", "Task": "Collaborative_Filtering", "score": "0.996"}]}
{"doc_id": "0ecd4fdce541317b38124967b5c2a259d8f43c91", "arxiv_id": "1207.4708", "title": "The Arcade Learning Environment: An Evaluation Platform for General Agents", "n_ary_relations": [{"Material": "Atari_2600_Alien", "Method": "Best_linear", "Metric": "Score", "Task": "Atari_Games", "score": 939.2}, {"Material": "Atari_2600_Amidar", "Method": "Best_linear", "Metric": "Score", "Task": "Atari_Games", "score": 103.4}, {"Material": "Atari_2600_Assault", "Method": "Best_linear", "Metric": "Score", "Task": "Atari_Games", "score": 628.0}, {"Material": "Atari_2600_Asterix", "Method": "Best_linear", "Metric": "Score", "Task": "Atari_Games", "score": 987.3}, {"Material": "Atari_2600_Asteroids", "Method": "Best_linear", "Metric": "Score", "Task": "Atari_Games", "score": 907.3}, {"Material": "Atari_2600_Atlantis", "Method": "Best_linear", "Metric": "Score", "Task": "Atari_Games", "score": 62687.0}, {"Material": "Atari_2600_Bank_Heist", "Method": "Best_linear", "Metric": "Score", "Task": "Atari_Games", "score": 190.8}, {"Material": "Atari_2600_Battle_Zone", "Method": "Best_linear", "Metric": "Score", "Task": "Atari_Games", "score": 15820.0}, {"Material": "Atari_2600_Beam_Rider", "Method": "Best_linear", "Metric": "Score", "Task": "Atari_Games", "score": 929.4}, {"Material": "Atari_2600_Bowling", "Method": "Best_linear", "Metric": "Score", "Task": "Atari_Games", "score": 43.9}, {"Material": "Atari_2600_Boxing", "Method": "Best_linear", "Metric": "Score", "Task": "Atari_Games", "score": 44.0}, {"Material": "Atari_2600_Breakout", "Method": "Best_linear", "Metric": "Score", "Task": "Atari_Games", "score": 5.2}, {"Material": "Atari_2600_Centipede", "Method": "Best_linear", "Metric": "Score", "Task": "Atari_Games", "score": 8803.0}, {"Material": "Atari_2600_Chopper_Command", "Method": "Best_linear", "Metric": "Score", "Task": "Atari_Games", "score": 1582.0}, {"Material": "Atari_2600_Crazy_Climber", "Method": "Best_linear", "Metric": "Score", "Task": "Atari_Games", "score": 23411.0}, {"Material": "Atari_2600_Demon_Attack", "Method": "Best_linear", "Metric": "Score", "Task": "Atari_Games", "score": 520.5}, {"Material": "Atari_2600_Double_Dunk", "Method": "Best_linear", "Metric": "Score", "Task": "Atari_Games", "score": -13.1}, {"Material": "Atari_2600_Enduro", "Method": "Best_linear", "Metric": "Score", "Task": "Atari_Games", "score": 129.1}, {"Material": "Atari_2600_Fishing_Derby", "Method": "Best_linear", "Metric": "Score", "Task": "Atari_Games", "score": -89.5}, {"Material": "Atari_2600_Freeway", "Method": "Best_linear", "Metric": "Score", "Task": "Atari_Games", "score": 19.1}, {"Material": "Atari_2600_Frostbite", "Method": "Best_linear", "Metric": "Score", "Task": "Atari_Games", "score": 216.9}, {"Material": "Atari_2600_Gopher", "Method": "Best_linear", "Metric": "Score", "Task": "Atari_Games", "score": 1288.0}, {"Material": "Atari_2600_Gravitar", "Method": "Best_linear", "Metric": "Score", "Task": "Atari_Games", "score": 387.7}, {"Material": "Atari_2600_HERO", "Method": "Best_linear", "Metric": "Score", "Task": "Atari_Games", "score": 6459.0}, {"Material": "Atari_2600_Ice_Hockey", "Method": "Best_linear", "Metric": "Score", "Task": "Atari_Games", "score": -9.5}, {"Material": "Atari_2600_James_Bond", "Method": "Best_linear", "Metric": "Score", "Task": "Atari_Games", "score": 202.8}, {"Material": "Atari_2600_Kangaroo", "Method": "Best_linear", "Metric": "Score", "Task": "Atari_Games", "score": 1622.0}, {"Material": "Atari_2600_Krull", "Method": "Best_linear", "Metric": "Score", "Task": "Atari_Games", "score": 3372.0}, {"Material": "Atari_2600_Kung-Fu_Master", "Method": "Best_linear", "Metric": "Score", "Task": "Atari_Games", "score": 19544.0}, {"Material": "Atari_2600_Montezuma_s_Revenge", "Method": "Best_linear", "Metric": "Score", "Task": "Atari_Games", "score": 10.7}, {"Material": "Atari_2600_Ms__Pacman", "Method": "Best_linear", "Metric": "Score", "Task": "Atari_Games", "score": 1692.0}, {"Material": "Atari_2600_Name_This_Game", "Method": "Best_linear", "Metric": "Score", "Task": "Atari_Games", "score": 2500.0}, {"Material": "Atari_2600_Pong", "Method": "Best_linear", "Metric": "Score", "Task": "Atari_Games", "score": -19.0}, {"Material": "Atari_2600_Private_Eye", "Method": "Best_linear", "Metric": "Score", "Task": "Atari_Games", "score": 684.3}, {"Material": "Atari_2600_Q_Bert", "Method": "Best_linear", "Metric": "Score", "Task": "Atari_Games", "score": 613.5}, {"Material": "Atari_2600_River_Raid", "Method": "Best_linear", "Metric": "Score", "Task": "Atari_Games", "score": 1904.0}, {"Material": "Atari_2600_Road_Runner", "Method": "Best_linear", "Metric": "Score", "Task": "Atari_Games", "score": 67.7}, {"Material": "Atari_2600_Robotank", "Method": "Best_linear", "Metric": "Score", "Task": "Atari_Games", "score": 28.7}, {"Material": "Atari_2600_Seaquest", "Method": "Best_linear", "Metric": "Score", "Task": "Atari_Games", "score": 664.8}, {"Material": "Atari_2600_Space_Invaders", "Method": "Best_linear", "Metric": "Score", "Task": "Atari_Games", "score": 250.1}, {"Material": "Atari_2600_Star_Gunner", "Method": "Best_linear", "Metric": "Score", "Task": "Atari_Games", "score": 1070.0}, {"Material": "Atari_2600_Tennis", "Method": "Best_linear", "Metric": "Score", "Task": "Atari_Games", "score": -0.1}, {"Material": "Atari_2600_Time_Pilot", "Method": "Best_linear", "Metric": "Score", "Task": "Atari_Games", "score": 3741.0}, {"Material": "Atari_2600_Tutankham", "Method": "Best_linear", "Metric": "Score", "Task": "Atari_Games", "score": 114.3}, {"Material": "Atari_2600_Up_and_Down", "Method": "Best_linear", "Metric": "Score", "Task": "Atari_Games", "score": 3533.0}, {"Material": "Atari_2600_Venture", "Method": "Best_linear", "Metric": "Score", "Task": "Atari_Games", "score": 66.0}, {"Material": "Atari_2600_Video_Pinball", "Method": "Best_linear", "Metric": "Score", "Task": "Atari_Games", "score": 16871.0}, {"Material": "Atari_2600_Wizard_of_Wor", "Method": "Best_linear", "Metric": "Score", "Task": "Atari_Games", "score": 1981.0}, {"Material": "Atari_2600_Zaxxon", "Method": "Best_linear", "Metric": "Score", "Task": "Atari_Games", "score": 3365.0}]}
{"doc_id": "0ee850dd6640a96531ac5ad21da5438db04d8b3c", "arxiv_id": "", "title": "Neural Ranking Models with Weak Supervision", "n_ary_relations": [{"Material": "TREC_Robust04", "Method": "FNRM-RankProb_Embed", "Metric": "MAP", "Task": "Ad-Hoc_Information_Retrieval", "score": "0.2837"}, {"Material": "TREC_Robust04", "Method": "FNRM-Rank_Embed", "Metric": "MAP", "Task": "Ad-Hoc_Information_Retrieval", "score": "0.2811"}]}
{"doc_id": "0f0a25d3be0d50a134f6f68e6a82bd8a2f668882", "arxiv_id": "1607.08764", "title": "SwiDeN: Convolutional Neural Networks For Depiction Invariant Object Recognition", "n_ary_relations": [{"Material": "Photo-Art-50", "Method": "SwiDeN", "Metric": "Overall_Accuracy", "Task": "Depiction_Invariant_Object_Recognition", "score": "93.02%"}]}
{"doc_id": "0f0cab9235bbf185acdd4f9713fd111ca50effca", "arxiv_id": "1805.04855", "title": "Covariance Pooling for Facial Expression Recognition", "n_ary_relations": [{"Material": "_Static_Facial_Expressions_in_the_Wild", "Method": "Covariance_Pooling", "Metric": "Accuracy", "Task": "Facial_Expression_Recognition", "score": "58.14%"}, {"Material": "Real-World_Affective_Faces", "Method": "Covariance_Pooling", "Metric": "Accuracy", "Task": "Facial_Expression_Recognition", "score": "87.0%"}]}
{"doc_id": "0f2f4edb7599de34c97f680cf356943e57088345", "arxiv_id": "1603.06937", "title": "Stacked Hourglass Networks for Human Pose Estimation", "n_ary_relations": [{"Material": "FLIC_Elbows", "Method": "Stacked_Hourglass_Networks", "Metric": "PCK_0_2", "Task": "Pose_Estimation", "score": "99.0%"}, {"Material": "FLIC_Wrists", "Method": "Stacked_Hourglass_Networks", "Metric": "PCK_0_2", "Task": "Pose_Estimation", "score": "97.0%"}, {"Material": "MPII_Human_Pose", "Method": "Stacked_Hourglass_Networks", "Metric": "PCKh-0_5", "Task": "Pose_Estimation", "score": "90.9%"}]}
{"doc_id": "0f810eb4777fd05317951ebaa7a3f5835ee84cf4", "arxiv_id": "1706.08090", "title": "Count-Based Exploration in Feature Space for Reinforcement Learning", "n_ary_relations": [{"Material": "Atari_2600_Freeway", "Method": "Sarsa-\u03b5", "Metric": "Score", "Task": "Atari_Games", "score": 29.9}, {"Material": "Atari_2600_Freeway", "Method": "Sarsa-\u03c6-EB", "Metric": "Score", "Task": "Atari_Games", "score": 0.0}, {"Material": "Atari_2600_Frostbite", "Method": "Sarsa-\u03b5", "Metric": "Score", "Task": "Atari_Games", "score": 1394.3}, {"Material": "Atari_2600_Frostbite", "Method": "Sarsa-\u03c6-EB", "Metric": "Score", "Task": "Atari_Games", "score": 2770.1}, {"Material": "Atari_2600_Montezuma_s_Revenge", "Method": "Sarsa-\u03b5", "Metric": "Score", "Task": "Atari_Games", "score": 399.5}, {"Material": "Atari_2600_Montezuma_s_Revenge", "Method": "Sarsa-\u03c6-EB", "Metric": "Score", "Task": "Atari_Games", "score": 2745.4}, {"Material": "Atari_2600_Q_Bert", "Method": "Sarsa-\u03b5", "Metric": "Score", "Task": "Atari_Games", "score": 3895.3}, {"Material": "Atari_2600_Q_Bert", "Method": "Sarsa-\u03c6-EB", "Metric": "Score", "Task": "Atari_Games", "score": 4111.8}, {"Material": "Atari_2600_Venture", "Method": "Sarsa-\u03b5", "Metric": "Score", "Task": "Atari_Games", "score": 0.0}, {"Material": "Atari_2600_Venture", "Method": "Sarsa-\u03c6-EB", "Metric": "Score", "Task": "Atari_Games", "score": 1169.2}]}
{"doc_id": "0f84a81f431b18a78bd97f59ed4b9d8eda390970", "arxiv_id": "1412.6806", "title": "Striving for Simplicity: The All Convolutional Net", "n_ary_relations": [{"Material": "CIFAR-10", "Method": "ACN", "Metric": "Percentage_correct", "Task": "Image_Classification", "score": "95.6"}, {"Material": "CIFAR-100", "Method": "ACN", "Metric": "Percentage_correct", "Task": "Image_Classification", "score": "66.3"}]}
{"doc_id": "0fa88943665de1176b0fc6de4ed7469b40cdb08c", "arxiv_id": "1611.01722", "title": "Learning to Draw Samples: With Application to Amortized MLE for Generative Adversarial Learning", "n_ary_relations": [{"Material": "CIFAR-10", "Method": "SteinGAN", "Metric": "Inception_score", "Task": "Conditional_Image_Generation", "score": "6.35"}]}
{"doc_id": "0fbd17a4f791e04bbf8f240f7c48c178900e30a6", "arxiv_id": "1807.04067", "title": "MultiPoseNet: Fast Multi-Person Pose Estimation using Pose Residual Network", "n_ary_relations": [{"Material": "COCO", "Method": "Pose_Residual_Network", "Metric": "AP", "Task": "Multi-Person_Pose_Estimation", "score": "0.697"}, {"Material": "COCO", "Method": "Pose_Residual_Network", "Metric": "Validation_AP", "Task": "Keypoint_Detection", "score": "69.6"}]}
{"doc_id": "0ff9ea8409c932baf3c0302c89ede79add1431aa", "arxiv_id": "1603.06042", "title": "Globally Normalized Transition-Based Neural Networks", "n_ary_relations": [{"Material": "Penn_Treebank", "Method": "Andor_et_al_", "Metric": "LAS", "Task": "Dependency_Parsing", "score": "92.79"}, {"Material": "Penn_Treebank", "Method": "Andor_et_al_", "Metric": "POS", "Task": "Dependency_Parsing", "score": "97.44"}, {"Material": "Penn_Treebank", "Method": "Andor_et_al_", "Metric": "UAS", "Task": "Dependency_Parsing", "score": "94.61"}]}
{"doc_id": "1001c09821f6910b5b8038a3c5993456ba966946", "arxiv_id": "1206.2944", "title": "Practical Bayesian Optimization of Machine Learning Algorithms", "n_ary_relations": [{"Material": "CIFAR-10", "Method": "GP_EI", "Metric": "Percentage_correct", "Task": "Image_Classification", "score": "90.5"}]}
{"doc_id": "100c730003033151c0f78ed1aab23df3e9bd5283", "arxiv_id": "1511.06038", "title": "Neural Variational Inference for Text Processing", "n_ary_relations": [{"Material": "QASent", "Method": "Attentive_LSTM", "Metric": "MAP", "Task": "Question_Answering", "score": "0.7339"}, {"Material": "QASent", "Method": "LSTM", "Metric": "MAP", "Task": "Question_Answering", "score": "0.6436"}, {"Material": "QASent", "Method": "LSTM__lexical_overlap___dist_output_", "Metric": "MAP", "Task": "Question_Answering", "score": "0.7228"}, {"Material": "QASent", "Method": "Attentive_LSTM", "Metric": "MRR", "Task": "Question_Answering", "score": "0.8117"}, {"Material": "QASent", "Method": "LSTM", "Metric": "MRR", "Task": "Question_Answering", "score": " 0.7235"}, {"Material": "QASent", "Method": "LSTM__lexical_overlap___dist_output_", "Metric": "MRR", "Task": "Question_Answering", "score": "0.7986"}, {"Material": "WikiQA", "Method": "Attentive_LSTM", "Metric": "MAP", "Task": "Question_Answering", "score": "0.6886"}, {"Material": "WikiQA", "Method": "LSTM", "Metric": "MAP", "Task": "Question_Answering", "score": "0.6552"}, {"Material": "WikiQA", "Method": "LSTM__lexical_overlap___dist_output_", "Metric": "MAP", "Task": "Question_Answering", "score": " 0.6820"}, {"Material": "WikiQA", "Method": "Attentive_LSTM", "Metric": "MRR", "Task": "Question_Answering", "score": "0.7069"}, {"Material": "WikiQA", "Method": "LSTM", "Metric": "MRR", "Task": "Question_Answering", "score": " 0.6747"}, {"Material": "WikiQA", "Method": "LSTM__lexical_overlap___dist_output_", "Metric": "MRR", "Task": "Question_Answering", "score": "0.6988"}]}
{"doc_id": "10203151008a20b32ce089f7f9d580005c2426cf", "arxiv_id": "1604.02426", "title": "CNN Image Retrieval Learns from BoW: Unsupervised Fine-Tuning with Hard Examples", "n_ary_relations": [{"Material": "Oxf105k", "Method": "siaMAC_QE_", "Metric": "MAP", "Task": "Image_Retrieval", "score": "77.9%"}, {"Material": "Oxf5k", "Method": "siaMAC_QE_", "Metric": "MAP", "Task": "Image_Retrieval", "score": "82.9%"}, {"Material": "Par106k", "Method": "siaMAC_QE_", "Metric": "Accuracy", "Task": "Image_Retrieval", "score": "78.3%"}, {"Material": "Par6k", "Method": "siaMAC_QE_", "Metric": "Accuracy", "Task": "Image_Retrieval", "score": "85.6%"}]}
{"doc_id": "10232946dd5fe3cdcbce72fe40e75d852561518b", "arxiv_id": "1704.03976", "title": "Virtual Adversarial Training: A Regularization Method for Supervised and Semi-Supervised Learning", "n_ary_relations": [{"Material": "CIFAR-10__4000_Labels", "Method": "VAT", "Metric": "Accuracy", "Task": "Semi-Supervised_Image_Classification", "score": "88.64"}, {"Material": "CIFAR-10__4000_Labels", "Method": "VAT_EntMin", "Metric": "Accuracy", "Task": "Semi-Supervised_Image_Classification", "score": "89.45"}, {"Material": "SVHN__1000_labels", "Method": "VAT", "Metric": "Accuracy", "Task": "Semi-Supervised_Image_Classification", "score": "94.58"}, {"Material": "SVHN__1000_labels", "Method": "VAT_EntMin", "Metric": "Accuracy", "Task": "Semi-Supervised_Image_Classification", "score": "96.14"}]}
{"doc_id": "1023b20d226bd0af9fdf0fd1847accefbfa5ec84", "arxiv_id": "1603.01547", "title": "Text Understanding with the Attention Sum Reader Network", "n_ary_relations": [{"Material": "CNN___Daily_Mail", "Method": "AS_Reader__ensemble_model_", "Metric": "CNN", "Task": "Question_Answering", "score": "75.4"}, {"Material": "CNN___Daily_Mail", "Method": "AS_Reader__single_model_", "Metric": "CNN", "Task": "Question_Answering", "score": " 69.5"}, {"Material": "CNN___Daily_Mail", "Method": "AS_Reader__ensemble_model_", "Metric": "Daily_Mail", "Task": "Question_Answering", "score": "77.7"}, {"Material": "CNN___Daily_Mail", "Method": "AS_Reader__single_model_", "Metric": "Daily_Mail", "Task": "Question_Answering", "score": "73.9"}, {"Material": "Children_s_Book_Test", "Method": "AS_reader__avg_", "Metric": "Accuracy-CN", "Task": "Question_Answering", "score": "68.9%"}, {"Material": "Children_s_Book_Test", "Method": "AS_reader__greedy_", "Metric": "Accuracy-CN", "Task": "Question_Answering", "score": "67.5%"}, {"Material": "Children_s_Book_Test", "Method": "AS_reader__avg_", "Metric": "Accuracy-NE", "Task": "Question_Answering", "score": "70.6%"}, {"Material": "Children_s_Book_Test", "Method": "AS_reader__greedy_", "Metric": "Accuracy-NE", "Task": "Question_Answering", "score": "71%"}, {"Material": "SearchQA", "Method": "ASR", "Metric": "N-gram_F1", "Task": "Open-Domain_Question_Answering", "score": "22.8"}, {"Material": "SearchQA", "Method": "ASR", "Metric": "Unigram_Acc", "Task": "Open-Domain_Question_Answering", "score": "41.3"}]}
{"doc_id": "10a36dea0167511b66deca65fdca978aa9afdb11", "arxiv_id": "1512.02167", "title": "Simple Baseline for Visual Question Answering", "n_ary_relations": [{"Material": "COCO_Visual_Question_Answering__VQA__real_images_1_0_multiple_choice", "Method": "iBOWIMG_baseline", "Metric": "Percentage_correct", "Task": "Visual_Question_Answering", "score": 61.97}, {"Material": "COCO_Visual_Question_Answering__VQA__real_images_1_0_open_ended", "Method": "iBOWIMG_baseline", "Metric": "Percentage_correct", "Task": "Visual_Question_Answering", "score": 55.89}]}
{"doc_id": "10ebd5c40277ecba4ed45d3dc12f9f1226720523", "arxiv_id": "", "title": "End-To-End Memory Networks", "n_ary_relations": [{"Material": "bAbi", "Method": "End-To-End_Memory_Networks", "Metric": "Accuracy__trained_on_10k_", "Task": "Question_Answering", "score": "93.4%"}, {"Material": "bAbi", "Method": "End-To-End_Memory_Networks", "Metric": "Accuracy__trained_on_1k_", "Task": "Question_Answering", "score": "86.1%"}, {"Material": "bAbi", "Method": "End-To-End_Memory_Networks", "Metric": "Mean_Error_Rate", "Task": "Question_Answering", "score": " 7.5%"}]}
{"doc_id": "10f62af29c3fc5e2572baddca559ffbfd6be8787", "arxiv_id": "1511.08630", "title": "A C-LSTM Neural Network for Text Classification", "n_ary_relations": [{"Material": "SST-2_Binary_classification", "Method": "C-LSTM", "Metric": "Accuracy", "Task": "Sentiment_Analysis", "score": "87.8"}, {"Material": "SST-5_Fine-grained_classification", "Method": "C-LSTM", "Metric": "Accuracy", "Task": "Sentiment_Analysis", "score": "49.2"}, {"Material": "TREC-6", "Method": "C-LSTM", "Metric": "Error", "Task": "Text_Classification", "score": "5.4"}]}
{"doc_id": "10fd174fefd5e36a523805e4c2d2fbf1d12a3ae8", "arxiv_id": "1606.04080", "title": "Matching Networks for One Shot Learning", "n_ary_relations": [{"Material": "Mini-ImageNet_-_1-Shot_Learning", "Method": "Matching_Nets___C64F_feature_extractor", "Metric": "Accuracy", "Task": "Few-Shot_Image_Classification", "score": "43.60%"}, {"Material": "Mini-ImageNet_-_5-Shot_Learning", "Method": "Matching_Nets___C64F_feature_extractor", "Metric": "Accuracy", "Task": "Few-Shot_Image_Classification", "score": "55.30%"}, {"Material": "OMNIGLOT_-_1-Shot_Learning", "Method": "Matching_Nets", "Metric": "Accuracy", "Task": "Few-Shot_Image_Classification", "score": "98.1%"}, {"Material": "OMNIGLOT_-_5-Shot_Learning", "Method": "Matching_Nets", "Metric": "Accuracy", "Task": "Few-Shot_Image_Classification", "score": "98.9%"}]}
{"doc_id": "1109b663453e78a59e4f66446d71720ac58cec25", "arxiv_id": "1312.6229", "title": "OverFeat: Integrated Recognition, Localization and Detection using Convolutional Networks", "n_ary_relations": [{"Material": "ImageNet_Detection", "Method": "OverFeat", "Metric": "MAP", "Task": "Object_Detection", "score": "24.3%"}]}
{"doc_id": "121e30c48546e671dc5e16c694c5e69b392cf8fb", "arxiv_id": "1903.04167", "title": "Partially Shuffling the Training Data to Improve Language Models", "n_ary_relations": [{"Material": "Penn_Treebank__Word_Level_", "Method": "AWD-LSTM-MoS___Partial_Shuffle", "Metric": "Params", "Task": "Language_Modelling", "score": "22M"}, {"Material": "Penn_Treebank__Word_Level_", "Method": "AWD-LSTM-MoS___Partial_Shuffle", "Metric": "Test_perplexity", "Task": "Language_Modelling", "score": "53.92"}, {"Material": "Penn_Treebank__Word_Level_", "Method": "AWD-LSTM-MoS___Partial_Shuffle", "Metric": "Validation_perplexity", "Task": "Language_Modelling", "score": "55.89"}, {"Material": "WikiText-2", "Method": "AWD-LSTM-MoS___Partial_Shuffle", "Metric": "Number_of_params", "Task": "Language_Modelling", "score": "35M"}, {"Material": "WikiText-2", "Method": "AWD-LSTM-MoS___Partial_Shuffle", "Metric": "Test_perplexity", "Task": "Language_Modelling", "score": "59.98"}, {"Material": "WikiText-2", "Method": "AWD-LSTM-MoS___Partial_Shuffle", "Metric": "Validation_perplexity", "Task": "Language_Modelling", "score": "62.38"}]}
{"doc_id": "128c727ac06fcc50f1735cb222a441eee6adcab6", "arxiv_id": "1901.09590", "title": "TuckER: Tensor Factorization for Knowledge Graph Completion", "n_ary_relations": [{"Material": "_FB15k", "Method": "TuckER", "Metric": "Hits_1", "Task": "Link_Prediction", "score": "0.741"}, {"Material": "_FB15k", "Method": "TuckER", "Metric": "Hits_10", "Task": "Link_Prediction", "score": "0.892"}, {"Material": "_FB15k", "Method": "TuckER", "Metric": "Hits_3", "Task": "Link_Prediction", "score": "0.833"}, {"Material": "_FB15k", "Method": "TuckER", "Metric": "MRR", "Task": "Link_Prediction", "score": "0.795"}, {"Material": "FB15k-237", "Method": "TuckER", "Metric": "Hits_1", "Task": "Link_Prediction", "score": "0.266"}, {"Material": "FB15k-237", "Method": "TuckER", "Metric": "Hits_10", "Task": "Link_Prediction", "score": "0.544"}, {"Material": "FB15k-237", "Method": "TuckER", "Metric": "Hits_3", "Task": "Link_Prediction", "score": "0.394"}, {"Material": "FB15k-237", "Method": "TuckER", "Metric": "MRR", "Task": "Link_Prediction", "score": "0.358"}, {"Material": "WN18", "Method": "TuckER", "Metric": "Hits_1", "Task": "Link_Prediction", "score": "0.949"}, {"Material": "WN18", "Method": "TuckER", "Metric": "Hits_10", "Task": "Link_Prediction", "score": "0.958"}, {"Material": "WN18", "Method": "TuckER", "Metric": "Hits_3", "Task": "Link_Prediction", "score": "0.955"}, {"Material": "WN18", "Method": "TuckER", "Metric": "MRR", "Task": "Link_Prediction", "score": "0.953"}, {"Material": "WN18RR", "Method": "TuckER", "Metric": "Hits_1", "Task": "Link_Prediction", "score": "0.443"}, {"Material": "WN18RR", "Method": "TuckER", "Metric": "Hits_10", "Task": "Link_Prediction", "score": "0.526"}, {"Material": "WN18RR", "Method": "TuckER", "Metric": "Hits_3", "Task": "Link_Prediction", "score": "0.482"}, {"Material": "WN18RR", "Method": "TuckER", "Metric": "MRR", "Task": "Link_Prediction", "score": "0.470"}]}
{"doc_id": "12db83e66e50152e170d5009c425c925ad2e2c2a", "arxiv_id": "1509.06664", "title": "Reasoning about Entailment with Neural Attention", "n_ary_relations": [{"Material": "SNLI", "Method": "100D_LSTMs_w__word-by-word_attention", "Metric": "__Test_Accuracy", "Task": "Natural_Language_Inference", "score": "83.5"}, {"Material": "SNLI", "Method": "100D_LSTMs_w__word-by-word_attention", "Metric": "__Train_Accuracy", "Task": "Natural_Language_Inference", "score": "85.3"}, {"Material": "SNLI", "Method": "100D_LSTMs_w__word-by-word_attention", "Metric": "Parameters", "Task": "Natural_Language_Inference", "score": "250k"}]}
{"doc_id": "12e20e4ea572dbe476fd894c5c9a9930cf250dd2", "arxiv_id": "1707.09098", "title": "MEMEN: Multi-layer Embedding with Memory Networks for Machine Comprehension", "n_ary_relations": [{"Material": "SQuAD1_1", "Method": "MEMEN___single_model_", "Metric": "EM", "Task": "Question_Answering", "score": "78.234"}, {"Material": "SQuAD1_1", "Method": "MEMEN__ensemble_", "Metric": "EM", "Task": "Question_Answering", "score": "75.370"}, {"Material": "SQuAD1_1", "Method": "MEMEN___single_model_", "Metric": "F1", "Task": "Question_Answering", "score": "85.344"}, {"Material": "SQuAD1_1", "Method": "MEMEN__ensemble_", "Metric": "F1", "Task": "Question_Answering", "score": "82.658"}, {"Material": "TriviaQA", "Method": "MEMEN", "Metric": "EM", "Task": "Question_Answering", "score": "43.16"}, {"Material": "TriviaQA", "Method": "MEMEN", "Metric": "F1", "Task": "Question_Answering", "score": "46.90"}]}
{"doc_id": "12f008bea798a05ebfa2864ec026999cb375bcd9", "arxiv_id": "1606.01549", "title": "Gated-Attention Readers for Text Comprehension", "n_ary_relations": [{"Material": "CNN___Daily_Mail", "Method": "GA_Reader", "Metric": "CNN", "Task": "Question_Answering", "score": "77.9"}, {"Material": "CNN___Daily_Mail", "Method": "GA_Reader", "Metric": "Daily_Mail", "Task": "Question_Answering", "score": "80.9"}, {"Material": "Children_s_Book_Test", "Method": "GA___feature___fix_L_w_", "Metric": "Accuracy-CN", "Task": "Question_Answering", "score": "70.7%"}, {"Material": "Children_s_Book_Test", "Method": "GA_reader", "Metric": "Accuracy-CN", "Task": "Question_Answering", "score": "69.4%"}, {"Material": "Children_s_Book_Test", "Method": "NSE", "Metric": "Accuracy-CN", "Task": "Question_Answering", "score": "71.9%"}, {"Material": "Children_s_Book_Test", "Method": "GA___feature___fix_L_w_", "Metric": "Accuracy-NE", "Task": "Question_Answering", "score": "74.9%"}, {"Material": "Children_s_Book_Test", "Method": "GA_reader", "Metric": "Accuracy-NE", "Task": "Question_Answering", "score": "71.9%"}, {"Material": "Children_s_Book_Test", "Method": "NSE", "Metric": "Accuracy-NE", "Task": "Question_Answering", "score": "73.2%"}, {"Material": "Quasar", "Method": "GA", "Metric": "EM__Quasar-T_", "Task": "Open-Domain_Question_Answering", "score": "26.4"}, {"Material": "Quasar", "Method": "GA", "Metric": "F1__Quasar-T_", "Task": "Open-Domain_Question_Answering", "score": "26.4"}]}
{"doc_id": "1329206dbdb0a2b9e23102e1340c17bd2b2adcf5", "arxiv_id": "1407.3867", "title": "Part-Based R-CNNs for Fine-Grained Category Detection", "n_ary_relations": [{"Material": "_CUB-200-2011", "Method": "Part_RCNN", "Metric": "Accuracy", "Task": "Fine-Grained_Image_Classification", "score": "76.4%"}]}
{"doc_id": "139768cf7714beb9309efba734460f8562c60c78", "arxiv_id": "1707.05236", "title": "Artificial Error Generation with Machine Translation and Syntactic Patterns", "n_ary_relations": [{"Material": "CoNLL-2014_A1", "Method": "Ann_PAT_MT", "Metric": "F0_5", "Task": "Grammatical_Error_Detection", "score": "21.87"}, {"Material": "CoNLL-2014_A2", "Method": "Ann_PAT_MT", "Metric": "F0_5", "Task": "Grammatical_Error_Detection", "score": "30.13"}, {"Material": "FCE", "Method": "Ann_PAT_MT", "Metric": "F0_5", "Task": "Grammatical_Error_Detection", "score": "49.11"}]}
{"doc_id": "13b58f3108709dbbed5588759bc0496f82a261c4", "arxiv_id": "1511.06581", "title": "Dueling Network Architectures for Deep Reinforcement Learning", "n_ary_relations": [{"Material": "Atari_2600_Alien", "Method": "DDQN__tuned__noop", "Metric": "Score", "Task": "Atari_Games", "score": 3747.7}, {"Material": "Atari_2600_Alien", "Method": "Duel_hs", "Metric": "Score", "Task": "Atari_Games", "score": 1486.5}, {"Material": "Atari_2600_Alien", "Method": "Duel_noop", "Metric": "Score", "Task": "Atari_Games", "score": 4461.4}, {"Material": "Atari_2600_Alien", "Method": "Prior_Duel_hs", "Metric": "Score", "Task": "Atari_Games", "score": "823.7"}, {"Material": "Atari_2600_Alien", "Method": "Prior_Duel_noop", "Metric": "Score", "Task": "Atari_Games", "score": 3941.0}, {"Material": "Atari_2600_Amidar", "Method": "DDQN__tuned__noop", "Metric": "Score", "Task": "Atari_Games", "score": 1793.3}, {"Material": "Atari_2600_Amidar", "Method": "Duel_hs", "Metric": "Score", "Task": "Atari_Games", "score": 172.7}, {"Material": "Atari_2600_Amidar", "Method": "Duel_noop", "Metric": "Score", "Task": "Atari_Games", "score": 2354.5}, {"Material": "Atari_2600_Amidar", "Method": "Prior_Duel_hs", "Metric": "Score", "Task": "Atari_Games", "score": "238.4"}, {"Material": "Atari_2600_Amidar", "Method": "Prior_Duel_noop", "Metric": "Score", "Task": "Atari_Games", "score": 2296.8}, {"Material": "Atari_2600_Assault", "Method": "DDQN__tuned__noop", "Metric": "Score", "Task": "Atari_Games", "score": 5393.2}, {"Material": "Atari_2600_Assault", "Method": "Duel_hs", "Metric": "Score", "Task": "Atari_Games", "score": 3994.8}, {"Material": "Atari_2600_Assault", "Method": "Duel_noop", "Metric": "Score", "Task": "Atari_Games", "score": 4621.0}, {"Material": "Atari_2600_Assault", "Method": "Prior_Duel_hs", "Metric": "Score", "Task": "Atari_Games", "score": "10950.6"}, {"Material": "Atari_2600_Assault", "Method": "Prior_Duel_noop", "Metric": "Score", "Task": "Atari_Games", "score": 11477.0}, {"Material": "Atari_2600_Asterix", "Method": "DDQN__tuned__noop", "Metric": "Score", "Task": "Atari_Games", "score": 17356.5}, {"Material": "Atari_2600_Asterix", "Method": "Duel_hs", "Metric": "Score", "Task": "Atari_Games", "score": 15840.0}, {"Material": "Atari_2600_Asterix", "Method": "Duel_noop", "Metric": "Score", "Task": "Atari_Games", "score": 28188.0}, {"Material": "Atari_2600_Asterix", "Method": "Prior_Duel_hs", "Metric": "Score", "Task": "Atari_Games", "score": "364200.0"}, {"Material": "Atari_2600_Asterix", "Method": "Prior_Duel_noop", "Metric": "Score", "Task": "Atari_Games", "score": 375080.0}, {"Material": "Atari_2600_Asteroids", "Method": "DDQN__tuned__noop", "Metric": "Score", "Task": "Atari_Games", "score": 734.7}, {"Material": "Atari_2600_Asteroids", "Method": "Duel_hs", "Metric": "Score", "Task": "Atari_Games", "score": 2035.4}, {"Material": "Atari_2600_Asteroids", "Method": "Duel_noop", "Metric": "Score", "Task": "Atari_Games", "score": 2837.7}, {"Material": "Atari_2600_Asteroids", "Method": "Prior_Duel_noop", "Metric": "Score", "Task": "Atari_Games", "score": 1192.7}, {"Material": "Atari_2600_Atlantis", "Method": "DDQN__tuned__noop", "Metric": "Score", "Task": "Atari_Games", "score": 106056.0}, {"Material": "Atari_2600_Atlantis", "Method": "Duel_hs", "Metric": "Score", "Task": "Atari_Games", "score": 445360.0}, {"Material": "Atari_2600_Atlantis", "Method": "Duel_noop", "Metric": "Score", "Task": "Atari_Games", "score": 382572.0}, {"Material": "Atari_2600_Atlantis", "Method": "Prior_Duel_noop", "Metric": "Score", "Task": "Atari_Games", "score": 395762.0}, {"Material": "Atari_2600_Bank_Heist", "Method": "DDQN__tuned__noop", "Metric": "Score", "Task": "Atari_Games", "score": 1030.6}, {"Material": "Atari_2600_Bank_Heist", "Method": "Duel_hs", "Metric": "Score", "Task": "Atari_Games", "score": 1129.3}, {"Material": "Atari_2600_Bank_Heist", "Method": "Duel_noop", "Metric": "Score", "Task": "Atari_Games", "score": 1611.9}, {"Material": "Atari_2600_Bank_Heist", "Method": "Prior_Duel_noop", "Metric": "Score", "Task": "Atari_Games", "score": 1503.1}, {"Material": "Atari_2600_Battle_Zone", "Method": "DDQN__tuned__noop", "Metric": "Score", "Task": "Atari_Games", "score": 31700.0}, {"Material": "Atari_2600_Battle_Zone", "Method": "Duel_hs", "Metric": "Score", "Task": "Atari_Games", "score": 31320.0}, {"Material": "Atari_2600_Battle_Zone", "Method": "Duel_noop", "Metric": "Score", "Task": "Atari_Games", "score": 37150.0}, {"Material": "Atari_2600_Battle_Zone", "Method": "Prior_Duel_noop", "Metric": "Score", "Task": "Atari_Games", "score": 35520.0}, {"Material": "Atari_2600_Beam_Rider", "Method": "DDQN__tuned__noop", "Metric": "Score", "Task": "Atari_Games", "score": 13772.8}, {"Material": "Atari_2600_Beam_Rider", "Method": "Duel_hs", "Metric": "Score", "Task": "Atari_Games", "score": 14591.3}, {"Material": "Atari_2600_Beam_Rider", "Method": "Duel_noop", "Metric": "Score", "Task": "Atari_Games", "score": 12164.0}, {"Material": "Atari_2600_Beam_Rider", "Method": "Prior_Duel_noop", "Metric": "Score", "Task": "Atari_Games", "score": 30276.5}, {"Material": "Atari_2600_Berzerk", "Method": "DDQN__tuned__noop", "Metric": "Score", "Task": "Atari_Games", "score": 1225.4}, {"Material": "Atari_2600_Berzerk", "Method": "Duel_hs", "Metric": "Score", "Task": "Atari_Games", "score": 910.6}, {"Material": "Atari_2600_Berzerk", "Method": "Duel_noop", "Metric": "Score", "Task": "Atari_Games", "score": 1472.6}, {"Material": "Atari_2600_Berzerk", "Method": "Prior_Duel_noop", "Metric": "Score", "Task": "Atari_Games", "score": 3409.0}, {"Material": "Atari_2600_Bowling", "Method": "DDQN__tuned__noop", "Metric": "Score", "Task": "Atari_Games", "score": 68.1}, {"Material": "Atari_2600_Bowling", "Method": "Duel_hs", "Metric": "Score", "Task": "Atari_Games", "score": 65.7}, {"Material": "Atari_2600_Bowling", "Method": "Duel_noop", "Metric": "Score", "Task": "Atari_Games", "score": 65.5}, {"Material": "Atari_2600_Bowling", "Method": "Prior_Duel_noop", "Metric": "Score", "Task": "Atari_Games", "score": 46.7}, {"Material": "Atari_2600_Boxing", "Method": "DDQN__tuned__noop", "Metric": "Score", "Task": "Atari_Games", "score": 91.6}, {"Material": "Atari_2600_Boxing", "Method": "Duel_hs", "Metric": "Score", "Task": "Atari_Games", "score": 77.3}, {"Material": "Atari_2600_Boxing", "Method": "Duel_noop", "Metric": "Score", "Task": "Atari_Games", "score": 99.4}, {"Material": "Atari_2600_Boxing", "Method": "Prior_Duel_noop", "Metric": "Score", "Task": "Atari_Games", "score": 98.9}, {"Material": "Atari_2600_Breakout", "Method": "DDQN__tuned__noop", "Metric": "Score", "Task": "Atari_Games", "score": 418.5}, {"Material": "Atari_2600_Breakout", "Method": "Duel_hs", "Metric": "Score", "Task": "Atari_Games", "score": 411.6}, {"Material": "Atari_2600_Breakout", "Method": "Duel_noop", "Metric": "Score", "Task": "Atari_Games", "score": 345.3}, {"Material": "Atari_2600_Breakout", "Method": "Prior_Duel_noop", "Metric": "Score", "Task": "Atari_Games", "score": 366.0}, {"Material": "Atari_2600_Centipede", "Method": "DDQN__tuned__noop", "Metric": "Score", "Task": "Atari_Games", "score": 5409.4}, {"Material": "Atari_2600_Centipede", "Method": "Duel_hs", "Metric": "Score", "Task": "Atari_Games", "score": 4881.0}, {"Material": "Atari_2600_Centipede", "Method": "Duel_noop", "Metric": "Score", "Task": "Atari_Games", "score": 7561.4}, {"Material": "Atari_2600_Centipede", "Method": "Prior_Duel_noop", "Metric": "Score", "Task": "Atari_Games", "score": 7687.5}, {"Material": "Atari_2600_Chopper_Command", "Method": "DDQN__tuned__noop", "Metric": "Score", "Task": "Atari_Games", "score": 5809.0}, {"Material": "Atari_2600_Chopper_Command", "Method": "Duel_hs", "Metric": "Score", "Task": "Atari_Games", "score": 3784.0}, {"Material": "Atari_2600_Chopper_Command", "Method": "Duel_noop", "Metric": "Score", "Task": "Atari_Games", "score": 11215.0}, {"Material": "Atari_2600_Chopper_Command", "Method": "Prior_Duel_noop", "Metric": "Score", "Task": "Atari_Games", "score": 13185.0}, {"Material": "Atari_2600_Crazy_Climber", "Method": "DDQN__tuned__noop", "Metric": "Score", "Task": "Atari_Games", "score": 117282.0}, {"Material": "Atari_2600_Crazy_Climber", "Method": "Duel_hs", "Metric": "Score", "Task": "Atari_Games", "score": 124566.0}, {"Material": "Atari_2600_Crazy_Climber", "Method": "Duel_noop", "Metric": "Score", "Task": "Atari_Games", "score": 143570.0}, {"Material": "Atari_2600_Crazy_Climber", "Method": "Prior_Duel_noop", "Metric": "Score", "Task": "Atari_Games", "score": 162224.0}, {"Material": "Atari_2600_Defender", "Method": "Duel_noop", "Metric": "Score", "Task": "Atari_Games", "score": "42214.0"}, {"Material": "Atari_2600_Defender", "Method": "Prior_Duel_hs", "Metric": "Score", "Task": "Atari_Games", "score": "34415.0"}, {"Material": "Atari_2600_Defender", "Method": "Prior_Duel_noop", "Metric": "Score", "Task": "Atari_Games", "score": "41324.5"}, {"Material": "Atari_2600_Demon_Attack", "Method": "DDQN__tuned__noop", "Metric": "Score", "Task": "Atari_Games", "score": 58044.2}, {"Material": "Atari_2600_Demon_Attack", "Method": "Duel_hs", "Metric": "Score", "Task": "Atari_Games", "score": 56322.8}, {"Material": "Atari_2600_Demon_Attack", "Method": "Duel_noop", "Metric": "Score", "Task": "Atari_Games", "score": 60813.3}, {"Material": "Atari_2600_Demon_Attack", "Method": "Prior_Duel_noop", "Metric": "Score", "Task": "Atari_Games", "score": 72878.6}, {"Material": "Atari_2600_Double_Dunk", "Method": "DDQN__tuned__noop", "Metric": "Score", "Task": "Atari_Games", "score": -5.5}, {"Material": "Atari_2600_Double_Dunk", "Method": "Duel_hs", "Metric": "Score", "Task": "Atari_Games", "score": -0.8}, {"Material": "Atari_2600_Double_Dunk", "Method": "Duel_noop", "Metric": "Score", "Task": "Atari_Games", "score": 0.1}, {"Material": "Atari_2600_Double_Dunk", "Method": "Prior_Duel_noop", "Metric": "Score", "Task": "Atari_Games", "score": -12.5}, {"Material": "Atari_2600_Enduro", "Method": "DDQN__tuned__noop", "Metric": "Score", "Task": "Atari_Games", "score": 1211.8}, {"Material": "Atari_2600_Enduro", "Method": "Duel_hs", "Metric": "Score", "Task": "Atari_Games", "score": 2077.4}, {"Material": "Atari_2600_Enduro", "Method": "Duel_noop", "Metric": "Score", "Task": "Atari_Games", "score": 2258.2}, {"Material": "Atari_2600_Enduro", "Method": "Prior_Duel_noop", "Metric": "Score", "Task": "Atari_Games", "score": 2306.4}, {"Material": "Atari_2600_Fishing_Derby", "Method": "DDQN__tuned__noop", "Metric": "Score", "Task": "Atari_Games", "score": 15.5}, {"Material": "Atari_2600_Fishing_Derby", "Method": "Duel_hs", "Metric": "Score", "Task": "Atari_Games", "score": -4.1}, {"Material": "Atari_2600_Fishing_Derby", "Method": "Duel_noop", "Metric": "Score", "Task": "Atari_Games", "score": 46.4}, {"Material": "Atari_2600_Fishing_Derby", "Method": "Prior_Duel_noop", "Metric": "Score", "Task": "Atari_Games", "score": 41.3}, {"Material": "Atari_2600_Freeway", "Method": "DDQN__tuned__noop", "Metric": "Score", "Task": "Atari_Games", "score": 33.3}, {"Material": "Atari_2600_Freeway", "Method": "Duel_hs", "Metric": "Score", "Task": "Atari_Games", "score": 0.2}, {"Material": "Atari_2600_Freeway", "Method": "Duel_noop", "Metric": "Score", "Task": "Atari_Games", "score": 0.0}, {"Material": "Atari_2600_Freeway", "Method": "Prior_Duel_noop", "Metric": "Score", "Task": "Atari_Games", "score": 33.0}, {"Material": "Atari_2600_Frostbite", "Method": "DDQN__tuned__noop", "Metric": "Score", "Task": "Atari_Games", "score": 1683.3}, {"Material": "Atari_2600_Frostbite", "Method": "Duel_hs", "Metric": "Score", "Task": "Atari_Games", "score": 2332.4}, {"Material": "Atari_2600_Frostbite", "Method": "Duel_noop", "Metric": "Score", "Task": "Atari_Games", "score": 4672.8}, {"Material": "Atari_2600_Frostbite", "Method": "Prior_Duel_noop", "Metric": "Score", "Task": "Atari_Games", "score": 7413.0}, {"Material": "Atari_2600_Gopher", "Method": "DDQN__tuned__noop", "Metric": "Score", "Task": "Atari_Games", "score": 14840.8}, {"Material": "Atari_2600_Gopher", "Method": "Duel_hs", "Metric": "Score", "Task": "Atari_Games", "score": 20051.4}, {"Material": "Atari_2600_Gopher", "Method": "Duel_noop", "Metric": "Score", "Task": "Atari_Games", "score": 15718.4}, {"Material": "Atari_2600_Gopher", "Method": "Prior_Duel_noop", "Metric": "Score", "Task": "Atari_Games", "score": 104368.2}, {"Material": "Atari_2600_Gravitar", "Method": "DDQN__tuned__noop", "Metric": "Score", "Task": "Atari_Games", "score": 412.0}, {"Material": "Atari_2600_Gravitar", "Method": "Duel_hs", "Metric": "Score", "Task": "Atari_Games", "score": 297.0}, {"Material": "Atari_2600_Gravitar", "Method": "Duel_noop", "Metric": "Score", "Task": "Atari_Games", "score": 588.0}, {"Material": "Atari_2600_Gravitar", "Method": "Prior_Duel_noop", "Metric": "Score", "Task": "Atari_Games", "score": 238.0}, {"Material": "Atari_2600_HERO", "Method": "DDQN__tuned__noop", "Metric": "Score", "Task": "Atari_Games", "score": 20130.2}, {"Material": "Atari_2600_HERO", "Method": "Duel_hs", "Metric": "Score", "Task": "Atari_Games", "score": 15207.9}, {"Material": "Atari_2600_HERO", "Method": "Duel_noop", "Metric": "Score", "Task": "Atari_Games", "score": 20818.2}, {"Material": "Atari_2600_HERO", "Method": "Prior_Duel_noop", "Metric": "Score", "Task": "Atari_Games", "score": 21036.5}, {"Material": "Atari_2600_Ice_Hockey", "Method": "DDQN__tuned__noop", "Metric": "Score", "Task": "Atari_Games", "score": -2.7}, {"Material": "Atari_2600_Ice_Hockey", "Method": "Duel_hs", "Metric": "Score", "Task": "Atari_Games", "score": -1.3}, {"Material": "Atari_2600_Ice_Hockey", "Method": "Duel_noop", "Metric": "Score", "Task": "Atari_Games", "score": 0.5}, {"Material": "Atari_2600_Ice_Hockey", "Method": "Prior_Duel_noop", "Metric": "Score", "Task": "Atari_Games", "score": -0.4}, {"Material": "Atari_2600_James_Bond", "Method": "DDQN__tuned__noop", "Metric": "Score", "Task": "Atari_Games", "score": 1358.0}, {"Material": "Atari_2600_James_Bond", "Method": "Duel_hs", "Metric": "Score", "Task": "Atari_Games", "score": 835.5}, {"Material": "Atari_2600_James_Bond", "Method": "Duel_noop", "Metric": "Score", "Task": "Atari_Games", "score": 1312.5}, {"Material": "Atari_2600_James_Bond", "Method": "Prior_Duel_noop", "Metric": "Score", "Task": "Atari_Games", "score": 812.0}, {"Material": "Atari_2600_Kangaroo", "Method": "DDQN__tuned__noop", "Metric": "Score", "Task": "Atari_Games", "score": 12992.0}, {"Material": "Atari_2600_Kangaroo", "Method": "Duel_hs", "Metric": "Score", "Task": "Atari_Games", "score": 10334.0}, {"Material": "Atari_2600_Kangaroo", "Method": "Duel_noop", "Metric": "Score", "Task": "Atari_Games", "score": 14854.0}, {"Material": "Atari_2600_Kangaroo", "Method": "Prior_Duel_noop", "Metric": "Score", "Task": "Atari_Games", "score": 1792.0}, {"Material": "Atari_2600_Krull", "Method": "DDQN__tuned__noop", "Metric": "Score", "Task": "Atari_Games", "score": 7920.5}, {"Material": "Atari_2600_Krull", "Method": "Duel_hs", "Metric": "Score", "Task": "Atari_Games", "score": 8051.6}, {"Material": "Atari_2600_Krull", "Method": "Duel_noop", "Metric": "Score", "Task": "Atari_Games", "score": 11451.9}, {"Material": "Atari_2600_Krull", "Method": "Prior_Duel_noop", "Metric": "Score", "Task": "Atari_Games", "score": 10374.4}, {"Material": "Atari_2600_Kung-Fu_Master", "Method": "DDQN__tuned__noop", "Metric": "Score", "Task": "Atari_Games", "score": 29710.0}, {"Material": "Atari_2600_Kung-Fu_Master", "Method": "Duel_hs", "Metric": "Score", "Task": "Atari_Games", "score": 24288.0}, {"Material": "Atari_2600_Kung-Fu_Master", "Method": "Duel_noop", "Metric": "Score", "Task": "Atari_Games", "score": 34294.0}, {"Material": "Atari_2600_Kung-Fu_Master", "Method": "Prior_Duel_noop", "Metric": "Score", "Task": "Atari_Games", "score": 48375.0}, {"Material": "Atari_2600_Montezuma_s_Revenge", "Method": "DDQN__tuned__noop", "Metric": "Score", "Task": "Atari_Games", "score": 0.0}, {"Material": "Atari_2600_Montezuma_s_Revenge", "Method": "Duel_hs", "Metric": "Score", "Task": "Atari_Games", "score": 22.0}, {"Material": "Atari_2600_Montezuma_s_Revenge", "Method": "Duel_noop", "Metric": "Score", "Task": "Atari_Games", "score": 0.0}, {"Material": "Atari_2600_Montezuma_s_Revenge", "Method": "Prior_Duel_noop", "Metric": "Score", "Task": "Atari_Games", "score": 0.0}, {"Material": "Atari_2600_Ms__Pacman", "Method": "DDQN__tuned__noop", "Metric": "Score", "Task": "Atari_Games", "score": 2711.4}, {"Material": "Atari_2600_Ms__Pacman", "Method": "Duel_hs", "Metric": "Score", "Task": "Atari_Games", "score": 2250.6}, {"Material": "Atari_2600_Ms__Pacman", "Method": "Duel_noop", "Metric": "Score", "Task": "Atari_Games", "score": 6283.5}, {"Material": "Atari_2600_Ms__Pacman", "Method": "Prior_Duel_noop", "Metric": "Score", "Task": "Atari_Games", "score": 3327.3}, {"Material": "Atari_2600_Name_This_Game", "Method": "DDQN__tuned__noop", "Metric": "Score", "Task": "Atari_Games", "score": 10616.0}, {"Material": "Atari_2600_Name_This_Game", "Method": "Duel_hs", "Metric": "Score", "Task": "Atari_Games", "score": 11185.1}, {"Material": "Atari_2600_Name_This_Game", "Method": "Duel_noop", "Metric": "Score", "Task": "Atari_Games", "score": 11971.1}, {"Material": "Atari_2600_Name_This_Game", "Method": "Prior_Duel_noop", "Metric": "Score", "Task": "Atari_Games", "score": 15572.5}, {"Material": "Atari_2600_Phoenix", "Method": "Prior_Duel_hs", "Metric": "Score", "Task": "Atari_Games", "score": "63597.0"}, {"Material": "Atari_2600_Pong", "Method": "DDQN__tuned__noop", "Metric": "Score", "Task": "Atari_Games", "score": 20.9}, {"Material": "Atari_2600_Pong", "Method": "Duel_hs", "Metric": "Score", "Task": "Atari_Games", "score": 18.8}, {"Material": "Atari_2600_Pong", "Method": "Duel_noop", "Metric": "Score", "Task": "Atari_Games", "score": 21.0}, {"Material": "Atari_2600_Pong", "Method": "Prior_Duel_noop", "Metric": "Score", "Task": "Atari_Games", "score": 20.9}, {"Material": "Atari_2600_Private_Eye", "Method": "DDQN__tuned__noop", "Metric": "Score", "Task": "Atari_Games", "score": 129.7}, {"Material": "Atari_2600_Private_Eye", "Method": "Duel_hs", "Metric": "Score", "Task": "Atari_Games", "score": 292.6}, {"Material": "Atari_2600_Private_Eye", "Method": "Duel_noop", "Metric": "Score", "Task": "Atari_Games", "score": 103.0}, {"Material": "Atari_2600_Private_Eye", "Method": "Prior_Duel_noop", "Metric": "Score", "Task": "Atari_Games", "score": 206.0}, {"Material": "Atari_2600_Q_Bert", "Method": "DDQN__tuned__noop", "Metric": "Score", "Task": "Atari_Games", "score": 15088.5}, {"Material": "Atari_2600_Q_Bert", "Method": "Duel_hs", "Metric": "Score", "Task": "Atari_Games", "score": 14175.8}, {"Material": "Atari_2600_Q_Bert", "Method": "Duel_noop", "Metric": "Score", "Task": "Atari_Games", "score": 19220.3}, {"Material": "Atari_2600_Q_Bert", "Method": "Prior_Duel_noop", "Metric": "Score", "Task": "Atari_Games", "score": 18760.3}, {"Material": "Atari_2600_River_Raid", "Method": "DDQN__tuned__noop", "Metric": "Score", "Task": "Atari_Games", "score": 14884.5}, {"Material": "Atari_2600_River_Raid", "Method": "Duel_hs", "Metric": "Score", "Task": "Atari_Games", "score": 16569.4}, {"Material": "Atari_2600_River_Raid", "Method": "Duel_noop", "Metric": "Score", "Task": "Atari_Games", "score": 21162.6}, {"Material": "Atari_2600_River_Raid", "Method": "Prior_Duel_noop", "Metric": "Score", "Task": "Atari_Games", "score": 20607.6}, {"Material": "Atari_2600_Road_Runner", "Method": "DDQN__tuned__noop", "Metric": "Score", "Task": "Atari_Games", "score": 44127.0}, {"Material": "Atari_2600_Road_Runner", "Method": "Duel_hs", "Metric": "Score", "Task": "Atari_Games", "score": 58549.0}, {"Material": "Atari_2600_Road_Runner", "Method": "Duel_noop", "Metric": "Score", "Task": "Atari_Games", "score": 69524.0}, {"Material": "Atari_2600_Road_Runner", "Method": "Prior_Duel_noop", "Metric": "Score", "Task": "Atari_Games", "score": 62151.0}, {"Material": "Atari_2600_Robotank", "Method": "DDQN__tuned__noop", "Metric": "Score", "Task": "Atari_Games", "score": 65.1}, {"Material": "Atari_2600_Robotank", "Method": "Duel_hs", "Metric": "Score", "Task": "Atari_Games", "score": 62.0}, {"Material": "Atari_2600_Robotank", "Method": "Duel_noop", "Metric": "Score", "Task": "Atari_Games", "score": 65.3}, {"Material": "Atari_2600_Robotank", "Method": "Prior_Duel_noop", "Metric": "Score", "Task": "Atari_Games", "score": 27.5}, {"Material": "Atari_2600_Seaquest", "Method": "DDQN__tuned__noop", "Metric": "Score", "Task": "Atari_Games", "score": 16452.7}, {"Material": "Atari_2600_Seaquest", "Method": "Duel_hs", "Metric": "Score", "Task": "Atari_Games", "score": 37361.6}, {"Material": "Atari_2600_Seaquest", "Method": "Duel_noop", "Metric": "Score", "Task": "Atari_Games", "score": 50254.2}, {"Material": "Atari_2600_Seaquest", "Method": "Prior_Duel_noop", "Metric": "Score", "Task": "Atari_Games", "score": 931.6}, {"Material": "Atari_2600_Space_Invaders", "Method": "DDQN__tuned__noop", "Metric": "Score", "Task": "Atari_Games", "score": 2525.5}, {"Material": "Atari_2600_Space_Invaders", "Method": "Duel_hs", "Metric": "Score", "Task": "Atari_Games", "score": 5993.1}, {"Material": "Atari_2600_Space_Invaders", "Method": "Duel_noop", "Metric": "Score", "Task": "Atari_Games", "score": 6427.3}, {"Material": "Atari_2600_Space_Invaders", "Method": "Prior_Duel_noop", "Metric": "Score", "Task": "Atari_Games", "score": 15311.5}, {"Material": "Atari_2600_Star_Gunner", "Method": "DDQN__tuned__noop", "Metric": "Score", "Task": "Atari_Games", "score": 60142.0}, {"Material": "Atari_2600_Star_Gunner", "Method": "Duel_hs", "Metric": "Score", "Task": "Atari_Games", "score": 90804.0}, {"Material": "Atari_2600_Star_Gunner", "Method": "Duel_noop", "Metric": "Score", "Task": "Atari_Games", "score": 89238.0}, {"Material": "Atari_2600_Star_Gunner", "Method": "Prior_Duel_noop", "Metric": "Score", "Task": "Atari_Games", "score": 125117.0}, {"Material": "Atari_2600_Tennis", "Method": "DDQN__tuned__noop", "Metric": "Score", "Task": "Atari_Games", "score": -22.8}, {"Material": "Atari_2600_Tennis", "Method": "Duel_hs", "Metric": "Score", "Task": "Atari_Games", "score": 4.4}, {"Material": "Atari_2600_Tennis", "Method": "Duel_noop", "Metric": "Score", "Task": "Atari_Games", "score": 5.1}, {"Material": "Atari_2600_Tennis", "Method": "Prior_Duel_noop", "Metric": "Score", "Task": "Atari_Games", "score": 0.0}, {"Material": "Atari_2600_Time_Pilot", "Method": "DDQN__tuned__noop", "Metric": "Score", "Task": "Atari_Games", "score": 8339.0}, {"Material": "Atari_2600_Time_Pilot", "Method": "Duel_hs", "Metric": "Score", "Task": "Atari_Games", "score": 6601.0}, {"Material": "Atari_2600_Time_Pilot", "Method": "Duel_noop", "Metric": "Score", "Task": "Atari_Games", "score": 11666.0}, {"Material": "Atari_2600_Time_Pilot", "Method": "Prior_Duel_noop", "Metric": "Score", "Task": "Atari_Games", "score": 7553.0}, {"Material": "Atari_2600_Tutankham", "Method": "DDQN__tuned__noop", "Metric": "Score", "Task": "Atari_Games", "score": 218.4}, {"Material": "Atari_2600_Tutankham", "Method": "Duel_hs", "Metric": "Score", "Task": "Atari_Games", "score": 48.0}, {"Material": "Atari_2600_Tutankham", "Method": "Duel_noop", "Metric": "Score", "Task": "Atari_Games", "score": 211.4}, {"Material": "Atari_2600_Tutankham", "Method": "Prior_Duel_noop", "Metric": "Score", "Task": "Atari_Games", "score": 245.9}, {"Material": "Atari_2600_Up_and_Down", "Method": "DDQN__tuned__noop", "Metric": "Score", "Task": "Atari_Games", "score": 22972.2}, {"Material": "Atari_2600_Up_and_Down", "Method": "Duel_hs", "Metric": "Score", "Task": "Atari_Games", "score": 24759.2}, {"Material": "Atari_2600_Up_and_Down", "Method": "Duel_noop", "Metric": "Score", "Task": "Atari_Games", "score": 44939.6}, {"Material": "Atari_2600_Up_and_Down", "Method": "Prior_Duel_noop", "Metric": "Score", "Task": "Atari_Games", "score": 33879.1}, {"Material": "Atari_2600_Venture", "Method": "DDQN__tuned__noop", "Metric": "Score", "Task": "Atari_Games", "score": 98.0}, {"Material": "Atari_2600_Venture", "Method": "Duel_hs", "Metric": "Score", "Task": "Atari_Games", "score": 200.0}, {"Material": "Atari_2600_Venture", "Method": "Duel_noop", "Metric": "Score", "Task": "Atari_Games", "score": 497.0}, {"Material": "Atari_2600_Venture", "Method": "Prior_Duel_noop", "Metric": "Score", "Task": "Atari_Games", "score": 48.0}, {"Material": "Atari_2600_Video_Pinball", "Method": "DDQN__tuned__noop", "Metric": "Score", "Task": "Atari_Games", "score": 309941.9}, {"Material": "Atari_2600_Video_Pinball", "Method": "Duel_hs", "Metric": "Score", "Task": "Atari_Games", "score": 110976.2}, {"Material": "Atari_2600_Video_Pinball", "Method": "Duel_noop", "Metric": "Score", "Task": "Atari_Games", "score": 98209.5}, {"Material": "Atari_2600_Video_Pinball", "Method": "Prior_Duel_noop", "Metric": "Score", "Task": "Atari_Games", "score": 479197.0}, {"Material": "Atari_2600_Wizard_of_Wor", "Method": "DDQN__tuned__noop", "Metric": "Score", "Task": "Atari_Games", "score": 7492.0}, {"Material": "Atari_2600_Wizard_of_Wor", "Method": "Duel_hs", "Metric": "Score", "Task": "Atari_Games", "score": 7054.0}, {"Material": "Atari_2600_Wizard_of_Wor", "Method": "Duel_noop", "Metric": "Score", "Task": "Atari_Games", "score": 7855.0}, {"Material": "Atari_2600_Wizard_of_Wor", "Method": "Prior_Duel_noop", "Metric": "Score", "Task": "Atari_Games", "score": 12352.0}, {"Material": "Atari_2600_Zaxxon", "Method": "DDQN__tuned__noop", "Metric": "Score", "Task": "Atari_Games", "score": 10163.0}, {"Material": "Atari_2600_Zaxxon", "Method": "Duel_hs", "Metric": "Score", "Task": "Atari_Games", "score": 10164.0}, {"Material": "Atari_2600_Zaxxon", "Method": "Duel_noop", "Metric": "Score", "Task": "Atari_Games", "score": 12944.0}, {"Material": "Atari_2600_Zaxxon", "Method": "Prior_Duel_noop", "Metric": "Score", "Task": "Atari_Games", "score": 13886.0}]}
{"doc_id": "13ea9a2ed134a9e238d33024fba34d3dd6a010e0", "arxiv_id": "1703.05693", "title": "SVDNet for Pedestrian Retrieval", "n_ary_relations": [{"Material": "DukeMTMC-reID", "Method": "SVDNet", "Metric": "MAP", "Task": "Person_Re-Identification", "score": "56.8"}, {"Material": "DukeMTMC-reID", "Method": "SVDNet", "Metric": "Rank-1", "Task": "Person_Re-Identification", "score": "76.7"}, {"Material": "Market-1501", "Method": "SVDNet", "Metric": "MAP", "Task": "Person_Re-Identification", "score": "62.1"}, {"Material": "Market-1501", "Method": "SVDNet", "Metric": "Rank-1", "Task": "Person_Re-Identification", "score": "82.3"}]}
{"doc_id": "143a3186c368544ded00a444be33153420baa254", "arxiv_id": "1703.03400", "title": "Model-Agnostic Meta-Learning for Fast Adaptation of Deep Networks", "n_ary_relations": [{"Material": "Mini-ImageNet_-_1-Shot_Learning", "Method": "MAML", "Metric": "Accuracy", "Task": "Few-Shot_Image_Classification", "score": "48.70%"}, {"Material": "Mini-ImageNet_-_5-Shot_Learning", "Method": "MAML", "Metric": "Accuracy", "Task": "Few-Shot_Image_Classification", "score": "63.10%"}, {"Material": "OMNIGLOT_-_1-Shot_Learning", "Method": "MAML", "Metric": "Accuracy", "Task": "Few-Shot_Image_Classification", "score": "98.7%"}, {"Material": "OMNIGLOT_-_5-Shot_Learning", "Method": "MAML", "Metric": "Accuracy", "Task": "Few-Shot_Image_Classification", "score": "99.9%"}]}
{"doc_id": "14908a18ff831005b6b4fc953ce61e1b4e7b54ee", "arxiv_id": "1812.01207", "title": "Practical Text Classification With Large Pre-Trained Language Models", "n_ary_relations": [{"Material": "SST-2_Binary_classification", "Method": "Transformer__finetune_", "Metric": "Accuracy", "Task": "Sentiment_Analysis", "score": "90.9"}, {"Material": "SemEval_2018_Task_1E-c", "Method": "Transformer__finetune_", "Metric": "Macro-F1", "Task": "Emotion_Classification", "score": "56.1"}]}
{"doc_id": "14ad9d060c1e8f0449e697ee189ac346353fbfbc", "arxiv_id": "1809.07950", "title": "CollaboNet: collaboration of deep neural networks for biomedical named entity recognition", "n_ary_relations": [{"Material": "BC5CDR", "Method": "CollaboNet", "Metric": "F1", "Task": "Named_Entity_Recognition__NER_", "score": "87.12"}, {"Material": "JNLPBA", "Method": "CollaboNet", "Metric": "F1", "Task": "Named_Entity_Recognition__NER_", "score": "78.58"}]}
{"doc_id": "151313065d71b49dbf07289c002c887d7b5a0a6b", "arxiv_id": "1703.04247", "title": "DeepFM: A Factorization-Machine based Neural Network for CTR Prediction", "n_ary_relations": [{"Material": "Amazon", "Method": "DeepFM", "Metric": "AUC", "Task": "Click-Through_Rate_Prediction", "score": "0.8683"}, {"Material": "Bing_News", "Method": "DeepFM", "Metric": "AUC", "Task": "Click-Through_Rate_Prediction", "score": "0.8376"}, {"Material": "Bing_News", "Method": "DeepFM", "Metric": "Log_Loss", "Task": "Click-Through_Rate_Prediction", "score": "0.2671"}, {"Material": "Company_", "Method": "DeepFM", "Metric": "AUC", "Task": "Click-Through_Rate_Prediction", "score": "0.8715"}, {"Material": "Company_", "Method": "DeepFM", "Metric": "Log_Loss", "Task": "Click-Through_Rate_Prediction", "score": "0.02618"}, {"Material": "Criteo", "Method": "DeepFM", "Metric": "AUC", "Task": "Click-Through_Rate_Prediction", "score": "0.8007"}, {"Material": "Criteo", "Method": "DeepFM", "Metric": "Log_Loss", "Task": "Click-Through_Rate_Prediction", "score": "0.45083"}, {"Material": "Dianping", "Method": "DeepFM", "Metric": "AUC", "Task": "Click-Through_Rate_Prediction", "score": "0.8481"}, {"Material": "Dianping", "Method": "DeepFM", "Metric": "Log_Loss", "Task": "Click-Through_Rate_Prediction", "score": "0.3333"}, {"Material": "MovieLens_20M", "Method": "DeepFM", "Metric": "AUC", "Task": "Click-Through_Rate_Prediction", "score": "0.7324"}]}
{"doc_id": "1518039b5001f1836565215eb047526b3ac7f462", "arxiv_id": "1508.07909", "title": "Neural Machine Translation of Rare Words with Subword Units", "n_ary_relations": [{"Material": "WMT2015_English-German", "Method": "BPE_word_segmentation", "Metric": "BLEU_score", "Task": "Machine_Translation", "score": "22.8"}, {"Material": "WMT2015_English-Russian", "Method": "C2-50k_Segmentation", "Metric": "BLEU_score", "Task": "Machine_Translation", "score": "20.9"}]}
{"doc_id": "15212fa4d30863ea1f9bd9591eee03848278242d", "arxiv_id": "1810.09311", "title": "Revisiting Distributional Correspondence Indexing: A Python Reimplementation and New Experiments", "n_ary_relations": [{"Material": "Multi-Domain_Sentiment_Dataset", "Method": "Distributional_Correspondence_Indexing", "Metric": "Average", "Task": "Sentiment_Analysis", "score": "83.30"}, {"Material": "Multi-Domain_Sentiment_Dataset", "Method": "Distributional_Correspondence_Indexing", "Metric": "Books", "Task": "Sentiment_Analysis", "score": "81.4"}, {"Material": "Multi-Domain_Sentiment_Dataset", "Method": "Distributional_Correspondence_Indexing", "Metric": "DVD", "Task": "Sentiment_Analysis", "score": "81.00"}, {"Material": "Multi-Domain_Sentiment_Dataset", "Method": "Distributional_Correspondence_Indexing", "Metric": "Electronics", "Task": "Sentiment_Analysis", "score": "85,06"}, {"Material": "Multi-Domain_Sentiment_Dataset", "Method": "Distributional_Correspondence_Indexing", "Metric": "Kitchen", "Task": "Sentiment_Analysis", "score": "85.9"}]}
{"doc_id": "15ca7adccf5cd4dc309cdcaa6328f4c429ead337", "arxiv_id": "1605.06240", "title": "FPNN: Field Probing Neural Networks for 3D Data", "n_ary_relations": [{"Material": "ModelNet40", "Method": "FPNN__4-FCs___NF_", "Metric": "Accuracy", "Task": "3D_Object_Recognition", "score": "88.4%"}]}
{"doc_id": "15cc54ed7b1582b2efd71bedf28b23634d82991b", "arxiv_id": "1812.09916", "title": "Improving MMD-GAN Training with Repulsive Loss Function", "n_ary_relations": [{"Material": "CIFAR-10", "Method": "MMD-GAN-rep", "Metric": "FID", "Task": "Image_Generation", "score": "16.21"}, {"Material": "CIFAR-10", "Method": "MMD-GAN-rep", "Metric": "Inception_score", "Task": "Image_Generation", "score": "8.29"}]}
{"doc_id": "15e07c1344e97e46ade2ee0a57017371fa05fe12", "arxiv_id": "1811.01136", "title": "Margin-based Parallel Corpus Mining with Multilingual Sentence Embeddings", "n_ary_relations": [{"Material": "BUCC_French-to-English", "Method": "Multilingual_Sentence_Embeddings", "Metric": "F1_score", "Task": "Cross-Lingual_Bitext_Mining", "score": "92.89"}, {"Material": "BUCC_German-to-English", "Method": "Multilingual_Sentence_Embeddings", "Metric": "F1_score", "Task": "Cross-Lingual_Bitext_Mining", "score": "95.58"}]}
{"doc_id": "15e1af79939dbf90790b03d8aa02477783fb1d0f", "arxiv_id": "1701.07717", "title": "Unlabeled Samples Generated by GAN Improve the Person Re-identification Baseline in Vitro", "n_ary_relations": [{"Material": "DukeMTMC-reID", "Method": "GAN", "Metric": "MAP", "Task": "Person_Re-Identification", "score": "47.13"}, {"Material": "DukeMTMC-reID", "Method": "GAN", "Metric": "Rank-1", "Task": "Person_Re-Identification", "score": "67.68"}, {"Material": "Market-1501", "Method": "GAN", "Metric": "MAP", "Task": "Person_Re-Identification", "score": "66.07"}, {"Material": "Market-1501", "Method": "GAN", "Metric": "Rank-1", "Task": "Person_Re-Identification", "score": "83.97"}]}
{"doc_id": "15e81c8d1c21f9e928c72721ac46d458f3341454", "arxiv_id": "1711.02281", "title": "Non-Autoregressive Neural Machine Translation", "n_ary_relations": [{"Material": "IWSLT2015_English-German", "Method": "NAT__FT___NPD", "Metric": "BLEU_score", "Task": "Machine_Translation", "score": "28.16"}, {"Material": "WMT2014_English-German", "Method": "NAT__FT___NPD", "Metric": "BLEU_score", "Task": "Machine_Translation", "score": "19.17"}, {"Material": "WMT2014_German-English", "Method": "NAT__FT___NPD", "Metric": "BLEU_score", "Task": "Machine_Translation", "score": "23.20"}, {"Material": "WMT2016_English-Romanian", "Method": "NAT__FT___NPD", "Metric": "BLEU_score", "Task": "Machine_Translation", "score": "29.79"}, {"Material": "WMT2016_Romanian-English", "Method": "NAT__FT___NPD", "Metric": "BLEU_score", "Task": "Machine_Translation", "score": "31.44"}]}
{"doc_id": "165ef2b5f86b9b2c68b652391db5ece8c5a0bc7e", "arxiv_id": "1504.01013", "title": "Efficient Piecewise Training of Deep Structured Models for Semantic Segmentation", "n_ary_relations": [{"Material": "PASCAL_Context", "Method": "Piecewise", "Metric": "mIoU", "Task": "Semantic_Segmentation", "score": "43.3"}]}
{"doc_id": "1672ffebacadf849188668f24bcd377a19ae4051", "arxiv_id": "1706.06978", "title": "Deep Interest Network for Click-Through Rate Prediction", "n_ary_relations": [{"Material": "Amazon", "Method": "DIN", "Metric": "AUC", "Task": "Click-Through_Rate_Prediction", "score": "0.8818"}, {"Material": "Amazon", "Method": "DIN___Dice_Activation", "Metric": "AUC", "Task": "Click-Through_Rate_Prediction", "score": "0.8871"}, {"Material": "MovieLens_20M", "Method": "DIN", "Metric": "AUC", "Task": "Click-Through_Rate_Prediction", "score": "0.7337"}, {"Material": "MovieLens_20M", "Method": "DIN___Dice_Activation", "Metric": "AUC", "Task": "Click-Through_Rate_Prediction", "score": "0.7348"}]}
{"doc_id": "16cd50316e41cbb1d9dfeafeb524b31654cef37a", "arxiv_id": "1610.05256", "title": "Achieving Human Parity in Conversational Speech Recognition", "n_ary_relations": [{"Material": "Switchboard___Hub500", "Method": "CNN-LSTM", "Metric": "Percentage_error", "Task": "Speech_Recognition", "score": 6.6}, {"Material": "Switchboard___Hub500", "Method": "Microsoft_2016b", "Metric": "Percentage_error", "Task": "Speech_Recognition", "score": 5.8}]}
{"doc_id": "16da4d6503e17f8597602437358461c252244bf7", "arxiv_id": "1706.09579", "title": "R2CNN: Rotational Region CNN for Orientation Robust Scene Text Detection", "n_ary_relations": [{"Material": "IC15", "Method": "R2CNN", "Metric": "F-Measure", "Task": "Scene_Text_Detection", "score": "82.54%"}]}
{"doc_id": "1713d05f9d5861cac4d5ec73151667cb03a42bfc", "arxiv_id": "1711.01068", "title": "Compressing Word Embeddings via Deep Compositional Code Learning", "n_ary_relations": [{"Material": "IWSLT2015_German-English", "Method": "DCCL", "Metric": "BLEU_score", "Task": "Machine_Translation", "score": "29.56"}]}
{"doc_id": "1751668492bac56f0ae2b6410417515ab3215945", "arxiv_id": "1711.04903", "title": "Robust Multilingual Part-of-Speech Tagging via Adversarial Training", "n_ary_relations": [{"Material": "Penn_Treebank", "Method": "Adversarial_Bi-LSTM", "Metric": "Accuracy", "Task": "Part-Of-Speech_Tagging", "score": "97.59"}, {"Material": "UD", "Method": "Adversarial_Bi-LSTM", "Metric": "Avg_accuracy", "Task": "Part-Of-Speech_Tagging", "score": "96.73"}]}
{"doc_id": "1768909f779869c0e83d53f6c91764f41c338ab5", "arxiv_id": "1506.08959", "title": "A large-scale car dataset for fine-grained categorization and verification", "n_ary_relations": [{"Material": "CompCars", "Method": "AlexNet", "Metric": "Accuracy", "Task": "Fine-Grained_Image_Classification", "score": "81.9%"}, {"Material": "CompCars", "Method": "GoogLeNet", "Metric": "Accuracy", "Task": "Fine-Grained_Image_Classification", "score": "91.2%"}]}
{"doc_id": "1822ca8db58b0382b0c64f310840f0f875ea02c0", "arxiv_id": "1711.10295", "title": "Camera Style Adaptation for Person Re-identification", "n_ary_relations": [{"Material": "DukeMTMC-reID", "Method": "IDE_", "Metric": "MAP", "Task": "Person_Re-Identification", "score": "51.83"}, {"Material": "DukeMTMC-reID", "Method": "IDE____CamStyle", "Metric": "MAP", "Task": "Person_Re-Identification", "score": "53.48"}, {"Material": "DukeMTMC-reID", "Method": "IDE____CamStyle___Random_Erasing", "Metric": "MAP", "Task": "Person_Re-Identification", "score": "57.61"}, {"Material": "DukeMTMC-reID", "Method": "IDE_", "Metric": "Rank-1", "Task": "Person_Re-Identification", "score": "72.31"}, {"Material": "DukeMTMC-reID", "Method": "IDE____CamStyle", "Metric": "Rank-1", "Task": "Person_Re-Identification", "score": "75.27"}, {"Material": "DukeMTMC-reID", "Method": "IDE____CamStyle___Random_Erasing", "Metric": "Rank-1", "Task": "Person_Re-Identification", "score": "78.32"}, {"Material": "Market-1501", "Method": "IDE_", "Metric": "MAP", "Task": "Person_Re-Identification", "score": "65.87"}, {"Material": "Market-1501", "Method": "IDE____CamStyle", "Metric": "MAP", "Task": "Person_Re-Identification", "score": "68.72"}, {"Material": "Market-1501", "Method": "IDE____CamStyle___Random_Erasing", "Metric": "MAP", "Task": "Person_Re-Identification", "score": "71.55"}, {"Material": "Market-1501", "Method": "IDE_", "Metric": "Rank-1", "Task": "Person_Re-Identification", "score": "85.66"}, {"Material": "Market-1501", "Method": "IDE____CamStyle", "Metric": "Rank-1", "Task": "Person_Re-Identification", "score": "88.12"}, {"Material": "Market-1501", "Method": "IDE____CamStyle___Random_Erasing", "Metric": "Rank-1", "Task": "Person_Re-Identification", "score": "89.49"}]}
{"doc_id": "18d62040534012818abb90e37eade5dab6dca716", "arxiv_id": "1808.09419", "title": "Identifying Well-formed Natural Language Questions", "n_ary_relations": [{"Material": "Query_Wellformedness", "Method": "word-1__2_POS-1__2__3", "Metric": "Accuracy", "Task": "Query_Wellformedness", "score": "70.7"}]}
{"doc_id": "19839ffab4c30db1556d7fd9275d1344a6e3fa46", "arxiv_id": "1901.05280", "title": "Dependency or Span, End-to-End Uniform Semantic Role Labeling", "n_ary_relations": [{"Material": "CoNLL_2005", "Method": "Li_et_al_", "Metric": "F1", "Task": "Semantic_Role_Labeling", "score": "87.7"}, {"Material": "OntoNotes", "Method": "Li_et_al_", "Metric": "F1", "Task": "Semantic_Role_Labeling", "score": "86.0"}]}
{"doc_id": "19fd2c2c9d4eecb3cf1befa8ac845a860083e8e7", "arxiv_id": "1507.04296", "title": "Massively Parallel Methods for Deep Reinforcement Learning", "n_ary_relations": [{"Material": "Atari_2600_Alien", "Method": "Gorila", "Metric": "Score", "Task": "Atari_Games", "score": 813.5}, {"Material": "Atari_2600_Amidar", "Method": "Gorila", "Metric": "Score", "Task": "Atari_Games", "score": 189.2}, {"Material": "Atari_2600_Assault", "Method": "Gorila", "Metric": "Score", "Task": "Atari_Games", "score": 1195.8}, {"Material": "Atari_2600_Asterix", "Method": "Gorila", "Metric": "Score", "Task": "Atari_Games", "score": 3324.7}, {"Material": "Atari_2600_Asteroids", "Method": "Gorila", "Metric": "Score", "Task": "Atari_Games", "score": 933.6}, {"Material": "Atari_2600_Atlantis", "Method": "Gorila", "Metric": "Score", "Task": "Atari_Games", "score": 629166.5}, {"Material": "Atari_2600_Bank_Heist", "Method": "Gorila", "Metric": "Score", "Task": "Atari_Games", "score": 399.4}, {"Material": "Atari_2600_Battle_Zone", "Method": "Gorila", "Metric": "Score", "Task": "Atari_Games", "score": 19938.0}, {"Material": "Atari_2600_Beam_Rider", "Method": "Gorila", "Metric": "Score", "Task": "Atari_Games", "score": 3822.1}, {"Material": "Atari_2600_Bowling", "Method": "Gorila", "Metric": "Score", "Task": "Atari_Games", "score": 54.0}, {"Material": "Atari_2600_Boxing", "Method": "Gorila", "Metric": "Score", "Task": "Atari_Games", "score": 74.2}, {"Material": "Atari_2600_Breakout", "Method": "Gorila", "Metric": "Score", "Task": "Atari_Games", "score": 313.0}, {"Material": "Atari_2600_Centipede", "Method": "Gorila", "Metric": "Score", "Task": "Atari_Games", "score": 6296.9}, {"Material": "Atari_2600_Chopper_Command", "Method": "Gorila", "Metric": "Score", "Task": "Atari_Games", "score": 3191.8}, {"Material": "Atari_2600_Crazy_Climber", "Method": "Gorila", "Metric": "Score", "Task": "Atari_Games", "score": 65451.0}, {"Material": "Atari_2600_Demon_Attack", "Method": "Gorila", "Metric": "Score", "Task": "Atari_Games", "score": 14880.1}, {"Material": "Atari_2600_Double_Dunk", "Method": "Gorila", "Metric": "Score", "Task": "Atari_Games", "score": -11.3}, {"Material": "Atari_2600_Enduro", "Method": "Gorila", "Metric": "Score", "Task": "Atari_Games", "score": 71.0}, {"Material": "Atari_2600_Fishing_Derby", "Method": "Gorila", "Metric": "Score", "Task": "Atari_Games", "score": 4.6}, {"Material": "Atari_2600_Freeway", "Method": "Gorila", "Metric": "Score", "Task": "Atari_Games", "score": 10.2}, {"Material": "Atari_2600_Frostbite", "Method": "Gorila", "Metric": "Score", "Task": "Atari_Games", "score": 426.6}, {"Material": "Atari_2600_Gopher", "Method": "Gorila", "Metric": "Score", "Task": "Atari_Games", "score": 4373.0}, {"Material": "Atari_2600_Gravitar", "Method": "Gorila", "Metric": "Score", "Task": "Atari_Games", "score": 538.4}, {"Material": "Atari_2600_HERO", "Method": "Gorila", "Metric": "Score", "Task": "Atari_Games", "score": 8963.4}, {"Material": "Atari_2600_Ice_Hockey", "Method": "Gorila", "Metric": "Score", "Task": "Atari_Games", "score": -1.7000000000000002}, {"Material": "Atari_2600_James_Bond", "Method": "Gorila", "Metric": "Score", "Task": "Atari_Games", "score": 444.0}, {"Material": "Atari_2600_Kangaroo", "Method": "Gorila", "Metric": "Score", "Task": "Atari_Games", "score": 1431.0}, {"Material": "Atari_2600_Krull", "Method": "Gorila", "Metric": "Score", "Task": "Atari_Games", "score": 6363.1}, {"Material": "Atari_2600_Kung-Fu_Master", "Method": "Gorila", "Metric": "Score", "Task": "Atari_Games", "score": 20620.0}, {"Material": "Atari_2600_Montezuma_s_Revenge", "Method": "Gorila", "Metric": "Score", "Task": "Atari_Games", "score": 84.0}, {"Material": "Atari_2600_Ms__Pacman", "Method": "Gorila", "Metric": "Score", "Task": "Atari_Games", "score": 1263.0}, {"Material": "Atari_2600_Name_This_Game", "Method": "Gorila", "Metric": "Score", "Task": "Atari_Games", "score": 9238.5}, {"Material": "Atari_2600_Pong", "Method": "Gorila", "Metric": "Score", "Task": "Atari_Games", "score": 16.7}, {"Material": "Atari_2600_Private_Eye", "Method": "Gorila", "Metric": "Score", "Task": "Atari_Games", "score": 2598.6}, {"Material": "Atari_2600_Q_Bert", "Method": "Gorila", "Metric": "Score", "Task": "Atari_Games", "score": 7089.8}, {"Material": "Atari_2600_River_Raid", "Method": "Gorila", "Metric": "Score", "Task": "Atari_Games", "score": 5310.3}, {"Material": "Atari_2600_Road_Runner", "Method": "Gorila", "Metric": "Score", "Task": "Atari_Games", "score": 43079.8}, {"Material": "Atari_2600_Robotank", "Method": "Gorila", "Metric": "Score", "Task": "Atari_Games", "score": 61.8}, {"Material": "Atari_2600_Seaquest", "Method": "Gorila", "Metric": "Score", "Task": "Atari_Games", "score": 10145.9}, {"Material": "Atari_2600_Space_Invaders", "Method": "Gorila", "Metric": "Score", "Task": "Atari_Games", "score": 1183.3}, {"Material": "Atari_2600_Star_Gunner", "Method": "Gorila", "Metric": "Score", "Task": "Atari_Games", "score": 14919.2}, {"Material": "Atari_2600_Tennis", "Method": "Gorila", "Metric": "Score", "Task": "Atari_Games", "score": -0.7000000000000001}, {"Material": "Atari_2600_Time_Pilot", "Method": "Gorila", "Metric": "Score", "Task": "Atari_Games", "score": 8267.8}, {"Material": "Atari_2600_Tutankham", "Method": "Gorila", "Metric": "Score", "Task": "Atari_Games", "score": 118.5}, {"Material": "Atari_2600_Up_and_Down", "Method": "Gorila", "Metric": "Score", "Task": "Atari_Games", "score": 8747.7}, {"Material": "Atari_2600_Venture", "Method": "Gorila", "Metric": "Score", "Task": "Atari_Games", "score": 523.4}, {"Material": "Atari_2600_Video_Pinball", "Method": "Gorila", "Metric": "Score", "Task": "Atari_Games", "score": 112093.4}, {"Material": "Atari_2600_Wizard_of_Wor", "Method": "Gorila", "Metric": "Score", "Task": "Atari_Games", "score": 10431.0}, {"Material": "Atari_2600_Zaxxon", "Method": "Gorila", "Metric": "Score", "Task": "Atari_Games", "score": 6159.4}]}
{"doc_id": "1a0912bb76777469295bb2c059faee907e7f3258", "arxiv_id": "1703.06870", "title": "Mask R-CNN", "n_ary_relations": [{"Material": "COCO", "Method": "Mask_R-CNN", "Metric": "Average_Precision", "Task": "Instance_Segmentation", "score": "37.1%"}, {"Material": "COCO", "Method": "Mask_R-CNN", "Metric": "Bounding_Box_AP", "Task": "Object_Detection", "score": "39.8"}, {"Material": "COCO", "Method": "Mask_R-CNN", "Metric": "Test_AP", "Task": "Keypoint_Detection", "score": "63.1"}, {"Material": "COCO", "Method": "Mask_R-CNN", "Metric": "Validation_AP", "Task": "Keypoint_Detection", "score": "69.2"}, {"Material": "MHP_v1_0", "Method": "Mask_R-CNN", "Metric": "AP_0_5", "Task": "Multi-Human_Parsing", "score": "52.68%"}, {"Material": "MHP_v2_0", "Method": "Mask_R-CNN", "Metric": "AP_0_5", "Task": "Multi-Human_Parsing", "score": "14.90%"}]}
{"doc_id": "1a2599e467e855f845dcbf9282f8bdbd97b85708", "arxiv_id": "1712.05884", "title": "Natural TTS Synthesis by Conditioning Wavenet on MEL Spectrogram Predictions", "n_ary_relations": [{"Material": "North_American_English", "Method": "Tacotron_2", "Metric": "Mean_Opinion_Score", "Task": "Speech_Synthesis", "score": "4.526"}, {"Material": "North_American_English", "Method": "WaveNet__Linguistic__", "Metric": "Mean_Opinion_Score", "Task": "Speech_Synthesis", "score": "4.341"}]}
{"doc_id": "1a5ea605111eb3403868d4b679315e944beee8c6", "arxiv_id": "1606.02891", "title": "Edinburgh Neural Machine Translation Systems for WMT 16", "n_ary_relations": [{"Material": "WMT2016_Czech-English", "Method": "Attentional_encoder-decoder___BPE", "Metric": "BLEU_score", "Task": "Machine_Translation", "score": "31.4"}, {"Material": "WMT2016_English-Czech", "Method": "Attentional_encoder-decoder___BPE", "Metric": "BLEU_score", "Task": "Machine_Translation", "score": "25.8"}, {"Material": "WMT2016_English-German", "Method": "Attentional_encoder-decoder___BPE", "Metric": "BLEU_score", "Task": "Machine_Translation", "score": "34.2"}, {"Material": "WMT2016_English-Romanian", "Method": "BiGRU", "Metric": "BLEU_score", "Task": "Machine_Translation", "score": "28.1"}, {"Material": "WMT2016_English-Russian", "Method": "Attentional_encoder-decoder___BPE", "Metric": "BLEU_score", "Task": "Machine_Translation", "score": "26.0"}, {"Material": "WMT2016_German-English", "Method": "Attentional_encoder-decoder___BPE", "Metric": "BLEU_score", "Task": "Machine_Translation", "score": "38.6"}, {"Material": "WMT2016_Romanian-English", "Method": "Attentional_encoder-decoder___BPE", "Metric": "BLEU_score", "Task": "Machine_Translation", "score": "33.3"}, {"Material": "WMT2016_Russian-English", "Method": "Attentional_encoder-decoder___BPE", "Metric": "BLEU_score", "Task": "Machine_Translation", "score": "28.0"}]}
{"doc_id": "1a67622ca58aa851afe36ad6c6e78f9fb9d691d2", "arxiv_id": "1403.6652", "title": "DeepWalk: online learning of social representations", "n_ary_relations": [{"Material": "BlogCatalog", "Method": "DeepWalk", "Metric": "Accuracy", "Task": "Node_Classification", "score": "22.50%"}, {"Material": "BlogCatalog", "Method": "DeepWalk", "Metric": "Macro-F1", "Task": "Node_Classification", "score": "0.214"}, {"Material": "Citeseer", "Method": "DeepWalk", "Metric": "Accuracy", "Task": "Node_Classification", "score": "43.2%"}, {"Material": "Cora", "Method": "DeepWalk", "Metric": "Accuracy", "Task": "Document_Classification", "score": "67.2%"}, {"Material": "Cora", "Method": "DeepWalk", "Metric": "Accuracy", "Task": "Node_Classification", "score": "67.2%"}, {"Material": "NELL", "Method": "DeepWalk", "Metric": "Accuracy", "Task": "Node_Classification", "score": "58.1%"}, {"Material": "Pubmed", "Method": "DeepWalk", "Metric": "Accuracy", "Task": "Node_Classification", "score": "65.3%"}, {"Material": "Wikipedia", "Method": "DeepWalk", "Metric": "Accuracy", "Task": "Node_Classification", "score": "19.40%"}, {"Material": "Wikipedia", "Method": "DeepWalk", "Metric": "Macro-F1", "Task": "Node_Classification", "score": "0.183"}]}
{"doc_id": "1a6b67622d04df8e245575bf8fb2066fb6729720", "arxiv_id": "", "title": "", "n_ary_relations": [{"Material": "Penn_Treebank__Character_Level_", "Method": "Past_Decode_Reg____AWD-LSTM-MoS___dyn__eval_", "Metric": "Bit_per_Character__BPC_", "Task": "Language_Modelling", "score": "1.169"}, {"Material": "Penn_Treebank__Character_Level_", "Method": "Past_Decode_Reg____AWD-LSTM-MoS___dyn__eval_", "Metric": "Number_of_params", "Task": "Language_Modelling", "score": "13.8M"}, {"Material": "Penn_Treebank__Word_Level_", "Method": "Past_Decode_Reg____AWD-LSTM-MoS___dyn__eval_", "Metric": "Params", "Task": "Language_Modelling", "score": "22M"}, {"Material": "Penn_Treebank__Word_Level_", "Method": "Past_Decode_Reg____AWD-LSTM-MoS___dyn__eval_", "Metric": "Test_perplexity", "Task": "Language_Modelling", "score": "47.3"}, {"Material": "Penn_Treebank__Word_Level_", "Method": "Past_Decode_Reg____AWD-LSTM-MoS___dyn__eval_", "Metric": "Validation_perplexity", "Task": "Language_Modelling", "score": "48.0"}, {"Material": "WikiText-2", "Method": "Past_Decode_Reg____AWD-LSTM-MoS___dyn__eval_", "Metric": "Number_of_params", "Task": "Language_Modelling", "score": "35M"}, {"Material": "WikiText-2", "Method": "Past_Decode_Reg____AWD-LSTM-MoS___dyn__eval_", "Metric": "Test_perplexity", "Task": "Language_Modelling", "score": "40.3"}, {"Material": "WikiText-2", "Method": "Past_Decode_Reg____AWD-LSTM-MoS___dyn__eval_", "Metric": "Validation_perplexity", "Task": "Language_Modelling", "score": "42.0"}]}
{"doc_id": "1abf6491d1b0f6e8af137869a01843931996a562", "arxiv_id": "1506.04579", "title": "ParseNet: Looking Wider to See Better", "n_ary_relations": [{"Material": "PASCAL_Context", "Method": "ParseNet_", "Metric": "mIoU", "Task": "Semantic_Segmentation", "score": "40.4"}, {"Material": "PASCAL_VOC_2012", "Method": "ParseNet", "Metric": "Mean_IoU", "Task": "Semantic_Segmentation", "score": "69.8%"}]}
{"doc_id": "1b29786b7e43dda1a4d6ee93f520a2960b1e3126", "arxiv_id": "1606.03126", "title": "Key-Value Memory Networks for Directly Reading Documents", "n_ary_relations": [{"Material": "WikiQA", "Method": "Key-Value_Memory_Network", "Metric": "MAP", "Task": "Question_Answering", "score": "0.7069"}, {"Material": "WikiQA", "Method": "Key-Value_Memory_Network", "Metric": "MRR", "Task": "Question_Answering", "score": "0.7265"}]}
{"doc_id": "1b9472907f5b7a1815c98b4562dce6c46dd2cf34", "arxiv_id": "", "title": "Consistent Rank Logits for Ordinal Regression with Convolutional Neural Networks", "n_ary_relations": [{"Material": "AFAD", "Method": "CORAL", "Metric": "MAE", "Task": "Age_Estimation", "score": "3.48"}, {"Material": "CACD", "Method": "CORAL", "Metric": "MAE", "Task": "Age_Estimation", "score": "5.35"}, {"Material": "MORPH_Album2", "Method": "CORAL", "Metric": "MAE", "Task": "Age_Estimation", "score": "2.59"}, {"Material": "UTKFace", "Method": "CORAL", "Metric": "MAE", "Task": "Age_Estimation", "score": "5.39"}]}
{"doc_id": "1bb5520bbc168e54c553758a76c6d953933bd8eb", "arxiv_id": "1407.3068", "title": "Deep Networks with Internal Selective Attention through Feedback Connections", "n_ary_relations": [{"Material": "CIFAR-10", "Method": "Deep_Networks_with_Internal_Selective_Attention_through_Feedback_Connections", "Metric": "Percentage_correct", "Task": "Image_Classification", "score": "90.8"}, {"Material": "CIFAR-100", "Method": "Deep_Networks_with_Internal_Selective_Attention_through_Feedback_Connections", "Metric": "Percentage_correct", "Task": "Image_Classification", "score": "66.2"}]}
{"doc_id": "1bc072002d97808340b312b69427baf2dc9fcb8e", "arxiv_id": "1601.02376", "title": "Deep Learning over Multi-field Categorical Data - - A Case Study on User Response Prediction", "n_ary_relations": [{"Material": "Company_", "Method": "FNN", "Metric": "AUC", "Task": "Click-Through_Rate_Prediction", "score": "0.8683"}, {"Material": "Company_", "Method": "FNN", "Metric": "Log_Loss", "Task": "Click-Through_Rate_Prediction", "score": "0.02629"}, {"Material": "Criteo", "Method": "FNN", "Metric": "AUC", "Task": "Click-Through_Rate_Prediction", "score": "0.7963"}, {"Material": "Criteo", "Method": "FNN", "Metric": "Log_Loss", "Task": "Click-Through_Rate_Prediction", "score": "0.45738"}, {"Material": "iPinYou", "Method": "FNN", "Metric": "AUC", "Task": "Click-Through_Rate_Prediction", "score": "0.7619"}]}
{"doc_id": "1bea6bbdb4aed87fff5390d42934a1d9b0a7bec4", "arxiv_id": "1606.02858", "title": "A Thorough Examination of the CNN/Daily Mail Reading Comprehension Task", "n_ary_relations": [{"Material": "CNN___Daily_Mail", "Method": "Attentive___relabling___ensemble", "Metric": "CNN", "Task": "Question_Answering", "score": "77.6"}, {"Material": "CNN___Daily_Mail", "Method": "AttentiveReader___bilinear_attention", "Metric": "CNN", "Task": "Question_Answering", "score": "72.4"}, {"Material": "CNN___Daily_Mail", "Method": "Classifier", "Metric": "CNN", "Task": "Question_Answering", "score": "67.9"}, {"Material": "CNN___Daily_Mail", "Method": "Attentive___relabling___ensemble", "Metric": "Daily_Mail", "Task": "Question_Answering", "score": "79.2"}, {"Material": "CNN___Daily_Mail", "Method": "AttentiveReader___bilinear_attention", "Metric": "Daily_Mail", "Task": "Question_Answering", "score": "75.8"}, {"Material": "CNN___Daily_Mail", "Method": "Classifier", "Metric": "Daily_Mail", "Task": "Question_Answering", "score": "68.3"}]}
{"doc_id": "1c0e8c3fb143eb5eb5af3026eae7257255fcf814", "arxiv_id": "1511.02853", "title": "Weakly Supervised Deep Detection Networks", "n_ary_relations": [{"Material": "PASCAL_VOC_2007", "Method": "WSDDN-Ens", "Metric": "MAP", "Task": "Weakly_Supervised_Object_Detection", "score": "39.3"}]}
{"doc_id": "1c7e078611c9df412e6eb3a356f31a0da0c1f99c", "arxiv_id": "1711.00199", "title": "PoseCNN: A Convolutional Neural Network for 6D Object Pose Estimation in Cluttered Scenes", "n_ary_relations": [{"Material": "LineMOD", "Method": "PoseCNN", "Metric": "Accuracy", "Task": "6D_Pose_Estimation", "score": "70.2%"}, {"Material": "OccludedLINEMOD", "Method": "PoseCNN___ICP", "Metric": "Accuracy", "Task": "6D_Pose_Estimation", "score": "78.0%"}, {"Material": "YCB-Video", "Method": "PoseCNN___ICP", "Metric": "Mean_AUC", "Task": "6D_Pose_Estimation", "score": "93.0%"}]}
{"doc_id": "1cf6bc0866226c1f8e282463adc8b75d92fba9bb", "arxiv_id": "1511.05234", "title": "Ask, Attend and Answer: Exploring Question-Guided Spatial Attention for Visual Question Answering", "n_ary_relations": [{"Material": "COCO_Visual_Question_Answering__VQA__real_images_1_0_open_ended", "Method": "SMem-VQA", "Metric": "Percentage_correct", "Task": "Visual_Question_Answering", "score": 58.24}]}
{"doc_id": "1d5d0a41b720bc51fd568cf78f8aa4ec5af4f802", "arxiv_id": "1711.10871", "title": "PointFusion: Deep Sensor Fusion for 3D Bounding Box Estimation", "n_ary_relations": [{"Material": "YCB-Video", "Method": "PointFusion", "Metric": "Mean_AUC", "Task": "6D_Pose_Estimation", "score": "83.9%"}]}
{"doc_id": "1d696a1beb42515ab16f3a9f6f72584a41492a03", "arxiv_id": "1412.1265", "title": "Deeply learned face representations are sparse, selective, and robust", "n_ary_relations": [{"Material": "Labeled_Faces_in_the_Wild", "Method": "DeepId2_", "Metric": "Accuracy", "Task": "Face_Verification", "score": "99.47%"}, {"Material": "YouTube_Faces_DB", "Method": "DeepId2_", "Metric": "Accuracy", "Task": "Face_Verification", "score": "93.2%"}]}
{"doc_id": "1d8653d9fca853a8e3727fa7d8f5ec0631cad08f", "arxiv_id": "1610.09027", "title": "Scaling Memory-Augmented Neural Networks with Sparse Reads and Writes", "n_ary_relations": [{"Material": "bAbi", "Method": "LSTM", "Metric": "Accuracy__trained_on_1k_", "Task": "Question_Answering", "score": "49%"}, {"Material": "bAbi", "Method": "LSTM", "Metric": "Mean_Error_Rate", "Task": "Question_Answering", "score": "28.7%"}, {"Material": "bAbi", "Method": "SDNC", "Metric": "Mean_Error_Rate", "Task": "Question_Answering", "score": "6.4%"}]}
{"doc_id": "1db9bd18681b96473f3c82b21edc9240b44dc329", "arxiv_id": "1802.05751", "title": "Image Transformer", "n_ary_relations": [{"Material": "CIFAR-10", "Method": "Image_Transformer", "Metric": "Model_Entropy", "Task": "Image_Generation", "score": "2.89"}]}
{"doc_id": "1e21b925b65303ef0299af65e018ec1e1b9b8d60", "arxiv_id": "1611.02200", "title": "Unsupervised Cross-Domain Image Generation", "n_ary_relations": [{"Material": "SVNH-to-MNIST", "Method": "DTN", "Metric": "Classification_Accuracy", "Task": "Unsupervised_Image-To-Image_Translation", "score": "84.4%"}]}
{"doc_id": "1e5b9e512c01e244287fe7afb05e03c96d5c1cd0", "arxiv_id": "1805.08237", "title": "Morphosyntactic Tagging with a Meta-BiLSTM Model over Context Sensitive Token Encodings", "n_ary_relations": [{"Material": "Penn_Treebank", "Method": "Meta_BiLSTM", "Metric": "Accuracy", "Task": "Part-Of-Speech_Tagging", "score": "97.96"}]}
{"doc_id": "1e7678467b1807777dcd9be557b79328ce9419a8", "arxiv_id": "1902.05509", "title": "MultiGrain: a unified image embedding for classes and instances", "n_ary_relations": [{"Material": "INRIA_Holidays", "Method": "MultiGrain_R50___500", "Metric": "Mean_mAP", "Task": "Image_Retrieval", "score": "91.8%"}, {"Material": "INRIA_Holidays", "Method": "MultiGrain_R50___800", "Metric": "Mean_mAP", "Task": "Image_Retrieval", "score": "92.5%"}, {"Material": "ImageNet", "Method": "MultiGrain_R50-AA-224", "Metric": "Top_1_Accuracy", "Task": "Image_Classification", "score": "78.2%"}, {"Material": "ImageNet", "Method": "MultiGrain_R50-AA-500", "Metric": "Top_1_Accuracy", "Task": "Image_Classification", "score": "79.4%"}, {"Material": "ImageNet", "Method": "PNASNet-5-Large___MultiGrain_p____500", "Metric": "Top_1_Accuracy", "Task": "Image_Classification", "score": "83.6%"}, {"Material": "ImageNet", "Method": "SENet154___MultiGrain_p____450", "Metric": "Top_1_Accuracy", "Task": "Image_Classification", "score": "83.1%"}, {"Material": "ImageNet", "Method": "MultiGrain_R50-AA-224", "Metric": "Top_5_Accuracy", "Task": "Image_Classification", "score": "93.9%"}, {"Material": "ImageNet", "Method": "MultiGrain_R50-AA-500", "Metric": "Top_5_Accuracy", "Task": "Image_Classification", "score": "94.8%"}, {"Material": "ImageNet", "Method": "PNASNet-5-Large___MultiGrain_p____500", "Metric": "Top_5_Accuracy", "Task": "Image_Classification", "score": "96.7%"}, {"Material": "ImageNet", "Method": "SENet154___MultiGrain_p____450", "Metric": "Top_5_Accuracy", "Task": "Image_Classification", "score": "96.5%"}]}
{"doc_id": "1e7a36c4d4f96b29e3edf51b6eb61f8e16217704", "arxiv_id": "1609.07959", "title": "Multiplicative LSTM for sequence modelling", "n_ary_relations": [{"Material": "Hutter_Prize", "Method": "Large_mLSTM__emb__WN__VD", "Metric": "Bit_per_Character__BPC_", "Task": "Language_Modelling", "score": "1.24"}, {"Material": "Hutter_Prize", "Method": "Large_mLSTM__emb__WN__VD", "Metric": "Number_of_params", "Task": "Language_Modelling", "score": "46M"}, {"Material": "Text8", "Method": "Large_mLSTM__emb__WN__VD", "Metric": "Bit_per_Character__BPC_", "Task": "Language_Modelling", "score": "1.27"}, {"Material": "Text8", "Method": "Unregularised_mLSTM", "Metric": "Bit_per_Character__BPC_", "Task": "Language_Modelling", "score": "1.40"}, {"Material": "Text8", "Method": "Large_mLSTM__emb__WN__VD", "Metric": "Number_of_params", "Task": "Language_Modelling", "score": "45M"}, {"Material": "Text8", "Method": "Unregularised_mLSTM", "Metric": "Number_of_params", "Task": "Language_Modelling", "score": "45M"}, {"Material": "enwiki8", "Method": "Large_mLSTM", "Metric": "Bit_per_Character__BPC_", "Task": "Language_Modelling", "score": "1.24"}, {"Material": "enwiki8", "Method": "Large_mLSTM", "Metric": "Number_of_params", "Task": "Language_Modelling", "score": "46M"}]}
{"doc_id": "1ea6b2f67a3a7f044209aae0d0fd1cb14a1e9e06", "arxiv_id": "1601.06759", "title": "Pixel Recurrent Neural Networks", "n_ary_relations": [{"Material": "CIFAR-10", "Method": "NICE", "Metric": "NLL_Test", "Task": "Image_Generation", "score": "4.48"}, {"Material": "CIFAR-10", "Method": "PixelCNN", "Metric": "NLL_Test", "Task": "Image_Generation", "score": "3.14"}, {"Material": "CIFAR-10", "Method": "PixelRNN", "Metric": "NLL_Test", "Task": "Image_Generation", "score": "3.00"}]}
{"doc_id": "1f76b7b071f3e65c97d09720f88d6b0ad9f07e8f", "arxiv_id": "1603.05027", "title": "Identity Mappings in Deep Residual Networks", "n_ary_relations": [{"Material": "CIFAR-10", "Method": "ResNet-1001", "Metric": "Percentage_correct", "Task": "Image_Classification", "score": "95.4"}, {"Material": "CIFAR-10", "Method": "ResNet-1001", "Metric": "Percentage_error", "Task": "Image_Classification", "score": "4.62"}, {"Material": "CIFAR-100", "Method": "ResNet-1001", "Metric": "Percentage_correct", "Task": "Image_Classification", "score": "77.3"}, {"Material": "CIFAR-100", "Method": "ResNet-1001", "Metric": "Percentage_error", "Task": "Image_Classification", "score": "22.71"}]}
{"doc_id": "2019ede61cc0be14859908312e18458a7c79908f", "arxiv_id": "", "title": "Neural Text Generation from Structured Data with Application to the Biography Domain", "n_ary_relations": [{"Material": "WikiBio", "Method": "Table_NLM", "Metric": "BLEU", "Task": "Table-to-text_Generation", "score": "34.70"}, {"Material": "WikiBio", "Method": "Table_NLM", "Metric": "ROUGE", "Task": "Table-to-text_Generation", "score": "25.80"}]}
{"doc_id": "207e0ac5301a3c79af862951b70632ed650f74f7", "arxiv_id": "1603.02139", "title": "Learning a Discriminative Null Space for Person Re-identification", "n_ary_relations": [{"Material": "Market-1501", "Method": "DNS", "Metric": "MAP", "Task": "Person_Re-Identification", "score": "35.68"}, {"Material": "Market-1501", "Method": "DNS", "Metric": "Rank-1", "Task": "Person_Re-Identification", "score": "61.02"}]}
{"doc_id": "20926884a62778a2bf3f9f3c56f30976749ad763", "arxiv_id": "", "title": "Estimating individual treatment effect: generalization bounds and algorithms", "n_ary_relations": [{"Material": "IDHP", "Method": "BART", "Metric": "Average_Treatment_Effect_Error", "Task": "Causal_Inference", "score": "0.34"}, {"Material": "IDHP", "Method": "Balancing_Linear_Regression", "Metric": "Average_Treatment_Effect_Error", "Task": "Causal_Inference", "score": "0.93"}, {"Material": "IDHP", "Method": "Balancing_Neural_Network", "Metric": "Average_Treatment_Effect_Error", "Task": "Causal_Inference", "score": "0.42"}, {"Material": "IDHP", "Method": "Causal_Forest", "Metric": "Average_Treatment_Effect_Error", "Task": "Causal_Inference", "score": "0.40"}, {"Material": "IDHP", "Method": "Counterfactual_Regression___WASS", "Metric": "Average_Treatment_Effect_Error", "Task": "Causal_Inference", "score": "0.27"}, {"Material": "IDHP", "Method": "OLS_with_separate_regressors_for_each_treatment_", "Metric": "Average_Treatment_Effect_Error", "Task": "Causal_Inference", "score": "0.31"}, {"Material": "IDHP", "Method": "OLS_with_treatments_as_a_feature", "Metric": "Average_Treatment_Effect_Error", "Task": "Causal_Inference", "score": "0.94"}, {"Material": "IDHP", "Method": "Random_Forest", "Metric": "Average_Treatment_Effect_Error", "Task": "Causal_Inference", "score": "0.96"}, {"Material": "IDHP", "Method": "TARNet", "Metric": "Average_Treatment_Effect_Error", "Task": "Causal_Inference", "score": "0.28"}, {"Material": "IDHP", "Method": "k-NN", "Metric": "Average_Treatment_Effect_Error", "Task": "Causal_Inference", "score": "0.79"}]}
{"doc_id": "20cc4bfdb648fd7947c71252589fc867d4d16933", "arxiv_id": "", "title": "Pairwise Confusion for Fine-Grained Visual Classification", "n_ary_relations": [{"Material": "_CUB-200-2011", "Method": "PC-DenseNet-161", "Metric": "Accuracy", "Task": "Fine-Grained_Image_Classification", "score": "86.87%"}, {"Material": "NABirds", "Method": "PC-DenseNet-161", "Metric": "Accuracy", "Task": "Fine-Grained_Image_Classification", "score": "82.79%"}, {"Material": "Oxford_102_Flowers", "Method": "PC_Bilinear_CNN", "Metric": "Accuracy", "Task": "Fine-Grained_Image_Classification", "score": "93.65%"}, {"Material": "Stanford_Cars", "Method": "PC-DenseNet-161", "Metric": "Accuracy", "Task": "Fine-Grained_Image_Classification", "score": "92.86%"}, {"Material": "Stanford_Dogs", "Method": "PC-DenseNet-161", "Metric": "Accuracy", "Task": "Fine-Grained_Image_Classification", "score": "83.75%"}]}
{"doc_id": "2116b2eaaece4af9c28c32af2728f3d49b792cf9", "arxiv_id": "1207.0580", "title": "Improving neural networks by preventing co-adaptation of feature detectors", "n_ary_relations": [{"Material": "CIFAR-10", "Method": "Improving_neural_networks_by_preventing_co-adaptation_of_feature_detectors", "Metric": "Percentage_correct", "Task": "Image_Classification", "score": "84.4"}]}
{"doc_id": "218b80da3eb15ae35267d280dcc4a806d515334a", "arxiv_id": "1807.01270", "title": "Reaching Human-level Performance in Automatic Grammatical Error Correction: An Empirical Study", "n_ary_relations": [{"Material": "Unrestricted", "Method": "CNN_Seq2Seq___Fluency_Boost", "Metric": "F0_5", "Task": "Grammatical_Error_Correction", "score": "61.34"}, {"Material": "Unrestricted", "Method": "CNN_Seq2Seq___Fluency_Boost", "Metric": "F0_5", "Task": "Grammatical_Error_Correction", "score": "76.88"}, {"Material": "Unrestricted", "Method": "CNN_Seq2Seq___Fluency_Boost_and_inference", "Metric": "GLEU", "Task": "Grammatical_Error_Correction", "score": "62.37"}]}
{"doc_id": "220a0b46840a2a1421c62d3d343397ab087a3f17", "arxiv_id": "1611.00850", "title": "Optical Flow Estimation Using a Spatial Pyramid Network", "n_ary_relations": [{"Material": "HPatches", "Method": "SPyNet", "Metric": "Viewpoint_I_AEPE", "Task": "Dense_Pixel_Correspondence_Estimation", "score": "36.94"}, {"Material": "HPatches", "Method": "SPyNet", "Metric": "Viewpoint_II_AEPE", "Task": "Dense_Pixel_Correspondence_Estimation", "score": "50.92"}, {"Material": "HPatches", "Method": "SPyNet", "Metric": "Viewpoint_III_AEPE", "Task": "Dense_Pixel_Correspondence_Estimation", "score": "54.29"}, {"Material": "HPatches", "Method": "SPyNet", "Metric": "Viewpoint_IV_AEPE", "Task": "Dense_Pixel_Correspondence_Estimation", "score": "62.60"}, {"Material": "HPatches", "Method": "SPyNet", "Metric": "Viewpoint_V_AEPE", "Task": "Dense_Pixel_Correspondence_Estimation", "score": "72.57"}, {"Material": "Sintel-clean", "Method": "Spynet", "Metric": "Average_End-Point_Error", "Task": "Optical_Flow_Estimation", "score": "6.64"}, {"Material": "Sintel-final", "Method": "Spynet", "Metric": "Average_End-Point_Error", "Task": "Optical_Flow_Estimation", "score": "8.36"}]}
{"doc_id": "223319a93dcf3912bbc1e5f949e5ab4d53906e62", "arxiv_id": "1409.7495", "title": "Unsupervised Domain Adaptation by Backpropagation", "n_ary_relations": [{"Material": "SVNH-to-MNIST", "Method": "DANN", "Metric": "Classification_Accuracy", "Task": "Unsupervised_Image-To-Image_Translation", "score": "73.6%"}]}
{"doc_id": "228db5326a10cd67605ce103a7948207a65feeb1", "arxiv_id": "1511.02274", "title": "Stacked Attention Networks for Image Question Answering", "n_ary_relations": [{"Material": "COCO_Visual_Question_Answering__VQA__real_images_1_0_open_ended", "Method": "SAN", "Metric": "Percentage_correct", "Task": "Visual_Question_Answering", "score": 58.9}]}
{"doc_id": "2298490e82ff3fd03a3a28bd9c9f307bd897a753", "arxiv_id": "1811.05181", "title": "Gradient Harmonized Single-stage Detector", "n_ary_relations": [{"Material": "COCO", "Method": "GHM-C___GHM-R", "Metric": "Bounding_Box_AP", "Task": "Object_Detection", "score": "41.6"}]}
{"doc_id": "22aab110058ebbd198edb1f1e7b4f69fb13c0613", "arxiv_id": "1809.11096", "title": "Large Scale GAN Training for High Fidelity Natural Image Synthesis", "n_ary_relations": [{"Material": "ImageNet_128x128", "Method": "BigGAN", "Metric": "FID", "Task": "Conditional_Image_Generation", "score": "9.6"}, {"Material": "ImageNet_128x128", "Method": "BigGAN-deep", "Metric": "FID", "Task": "Conditional_Image_Generation", "score": "7.4"}, {"Material": "ImageNet_128x128", "Method": "BigGAN", "Metric": "Inception_score", "Task": "Conditional_Image_Generation", "score": "166.3"}, {"Material": "ImageNet_128x128", "Method": "BigGAN-deep", "Metric": "Inception_score", "Task": "Conditional_Image_Generation", "score": "166.5"}]}
{"doc_id": "231af7dc01a166cac3b5b01ca05778238f796e41", "arxiv_id": "", "title": "GANs Trained by a Two Time-Scale Update Rule Converge to a Local Nash Equilibrium", "n_ary_relations": [{"Material": "CIFAR-10", "Method": "WGAN-GP___TT_Update_Rule", "Metric": "FID", "Task": "Image_Generation", "score": "24.8"}, {"Material": "LSUN_Bedroom_256_x_256", "Method": "WGAN-GP___TT_Update_Rule", "Metric": "FID", "Task": "Image_Generation", "score": "9.5"}]}
{"doc_id": "2329a46590b2036d508097143e65c1b77e571e8c", "arxiv_id": "1412.5567", "title": "Deep Speech: Scaling up end-to-end speech recognition", "n_ary_relations": [{"Material": "CHiME_clean", "Method": "CNN___Bi-RNN___CTC__speech_to_letters_", "Metric": "Percentage_error", "Task": "Noisy_Speech_Recognition", "score": 6.3}, {"Material": "CHiME_real", "Method": "CNN___Bi-RNN___CTC__speech_to_letters_", "Metric": "Percentage_error", "Task": "Noisy_Speech_Recognition", "score": 67.94}, {"Material": "Switchboard___Hub500", "Method": "CNN___Bi-RNN___CTC__speech_to_letters___25_9__WER_if_trainedonlyon_SWB", "Metric": "Percentage_error", "Task": "Speech_Recognition", "score": 12.6}, {"Material": "Switchboard___Hub500", "Method": "Deep_Speech", "Metric": "Percentage_error", "Task": "Speech_Recognition", "score": 20}, {"Material": "Switchboard___Hub500", "Method": "Deep_Speech___FSH", "Metric": "Percentage_error", "Task": "Speech_Recognition", "score": 12.6}, {"Material": "VoxForge_American-Canadian", "Method": "Deep_Speech", "Metric": "Percentage_error", "Task": "Accented_Speech_Recognition", "score": "15.01"}, {"Material": "VoxForge_Commonwealth", "Method": "Deep_Speech", "Metric": "Percentage_error", "Task": "Accented_Speech_Recognition", "score": "28.46"}, {"Material": "VoxForge_European", "Method": "Deep_Speech", "Metric": "Percentage_error", "Task": "Accented_Speech_Recognition", "score": "31.20"}, {"Material": "VoxForge_Indian", "Method": "Deep_Speech", "Metric": "Percentage_error", "Task": "Accented_Speech_Recognition", "score": "45.35"}, {"Material": "swb_hub_500_WER_fullSWBCH", "Method": "CNN___Bi-RNN___CTC__speech_to_letters___25_9__WER_if_trainedonlyon_SWB", "Metric": "Percentage_error", "Task": "Speech_Recognition", "score": 16}]}
{"doc_id": "2393447b8b0b79046afea1c88a8ed3949338949e", "arxiv_id": "1901.02262", "title": "Multi-style Generative Reading Comprehension", "n_ary_relations": [{"Material": "MS_MARCO", "Method": "Masque_Q_A_Style", "Metric": "BLEU-1", "Task": "Question_Answering", "score": "43.77"}, {"Material": "MS_MARCO", "Method": "Masque_Q_A_Style", "Metric": "Rouge-L", "Task": "Question_Answering", "score": "52.20"}]}
{"doc_id": "23ae5fa0e8d581b184a8749d764d2ded128fd87e", "arxiv_id": "1509.08985", "title": "Generalizing Pooling Functions in Convolutional Neural Networks: Mixed, Gated, and Tree", "n_ary_relations": [{"Material": "CIFAR-10", "Method": "Tree_Max-Avg_pooling", "Metric": "Percentage_correct", "Task": "Image_Classification", "score": "94.0"}, {"Material": "CIFAR-100", "Method": "Tree_Max-Avg_pooling", "Metric": "Percentage_correct", "Task": "Image_Classification", "score": "67.6"}, {"Material": "MNIST", "Method": "Tree_Max-Avg_pooling", "Metric": "Percentage_error", "Task": "Image_Classification", "score": "0.3"}, {"Material": "SVHN", "Method": "Tree_Max-Avg_pooling", "Metric": "Percentage_error", "Task": "Image_Classification", "score": 1.69}]}
{"doc_id": "23c141141f4f63c061d3cce14c71893959af5721", "arxiv_id": "1603.06021", "title": "A Fast Unified Model for Parsing and Sentence Understanding", "n_ary_relations": [{"Material": "SNLI", "Method": "300D_LSTM_encoders", "Metric": "__Test_Accuracy", "Task": "Natural_Language_Inference", "score": "80.6"}, {"Material": "SNLI", "Method": "300D_SPINN-PI_encoders", "Metric": "__Test_Accuracy", "Task": "Natural_Language_Inference", "score": "83.2"}, {"Material": "SNLI", "Method": "300D_LSTM_encoders", "Metric": "__Train_Accuracy", "Task": "Natural_Language_Inference", "score": "83.9"}, {"Material": "SNLI", "Method": "300D_SPINN-PI_encoders", "Metric": "__Train_Accuracy", "Task": "Natural_Language_Inference", "score": "89.2"}, {"Material": "SNLI", "Method": "300D_LSTM_encoders", "Metric": "Parameters", "Task": "Natural_Language_Inference", "score": "3.0m"}, {"Material": "SNLI", "Method": "300D_SPINN-PI_encoders", "Metric": "Parameters", "Task": "Natural_Language_Inference", "score": "3.7m"}]}
{"doc_id": "23dcfda130aada27c158c0b5f394cac489c9c795", "arxiv_id": "1710.00925", "title": "Fine-Grained Head Pose Estimation Without Keypoints", "n_ary_relations": [{"Material": "AFLW2000", "Method": "Multi-Loss_ResNet50", "Metric": "MAE", "Task": "Head_Pose_Estimation", "score": "6.155"}, {"Material": "BIWI", "Method": "Multi-Loss_ResNet50", "Metric": "MAE", "Task": "Head_Pose_Estimation", "score": "4.895"}]}
{"doc_id": "23f5854b38a15c2ae201e751311665f7995b5e10", "arxiv_id": "1802.05814", "title": "Variational Autoencoders for Collaborative Filtering", "n_ary_relations": [{"Material": "Million_Song_Dataset", "Method": "Mult-DAE", "Metric": "Recall_20", "Task": "Collaborative_Filtering", "score": "0.266"}, {"Material": "Million_Song_Dataset", "Method": "Mult-VAE_PR", "Metric": "Recall_20", "Task": "Collaborative_Filtering", "score": "0.266"}, {"Material": "Million_Song_Dataset", "Method": "Mult-DAE", "Metric": "Recall_50", "Task": "Collaborative_Filtering", "score": "0.363"}, {"Material": "Million_Song_Dataset", "Method": "Mult-VAE_PR", "Metric": "Recall_50", "Task": "Collaborative_Filtering", "score": "0.364"}, {"Material": "MovieLens_20M", "Method": "Mult-DAE", "Metric": "Recall_20", "Task": "Collaborative_Filtering", "score": "0.387"}, {"Material": "MovieLens_20M", "Method": "Mult-VAE_PR", "Metric": "Recall_20", "Task": "Collaborative_Filtering", "score": "0.395"}, {"Material": "MovieLens_20M", "Method": "Mult-DAE", "Metric": "Recall_50", "Task": "Collaborative_Filtering", "score": "0.524"}, {"Material": "MovieLens_20M", "Method": "Mult-VAE_PR", "Metric": "Recall_50", "Task": "Collaborative_Filtering", "score": "0.537"}, {"Material": "Netflix", "Method": "Mult-DAE", "Metric": "Recall_20", "Task": "Collaborative_Filtering", "score": "0.344"}, {"Material": "Netflix", "Method": "Mult-VAE_PR", "Metric": "Recall_20", "Task": "Collaborative_Filtering", "score": "0.351"}, {"Material": "Netflix", "Method": "Mult-DAE", "Metric": "Recall_50", "Task": "Collaborative_Filtering", "score": "0.438"}, {"Material": "Netflix", "Method": "Mult-VAE_PR", "Metric": "Recall_50", "Task": "Collaborative_Filtering", "score": "0.444"}]}
{"doc_id": "2451db113552afb6d9ad15ef4009ec4133d28f74", "arxiv_id": "1712.01034", "title": "Towards Faster Training of Global Covariance Pooling Networks by Iterative Matrix Square Root Normalization", "n_ary_relations": [{"Material": "_CUB-200-2011", "Method": "MPN-COV", "Metric": "Accuracy", "Task": "Fine-Grained_Image_Classification", "score": "88.7%"}, {"Material": "FGVC_Aircraft", "Method": "MPN-COV", "Metric": "Accuracy", "Task": "Fine-Grained_Image_Classification", "score": "91.4%"}, {"Material": "Stanford_Cars", "Method": "MPN-COV", "Metric": "Accuracy", "Task": "Fine-Grained_Image_Classification", "score": "93.3%"}]}
{"doc_id": "258ec208f9c55371a67ebac68aa51bd7f7800a7b", "arxiv_id": "1606.08921", "title": "Image Restoration Using Convolutional Auto-encoders with Symmetric Skip Connections", "n_ary_relations": [{"Material": "BSD200_sigma10", "Method": "RED30", "Metric": "PSNR", "Task": "Image_Denoising", "score": "33.63"}, {"Material": "BSD200_sigma10", "Method": "RED30", "Metric": "SSIM", "Task": "Image_Denoising", "score": "0.9319"}, {"Material": "BSD200_sigma30", "Method": "RED30", "Metric": "PSNR", "Task": "Image_Denoising", "score": "27.95"}, {"Material": "BSD200_sigma30", "Method": "RED30", "Metric": "SSIM", "Task": "Image_Denoising", "score": "0.8019"}, {"Material": "BSD200_sigma50", "Method": "RED30", "Metric": "PSNR", "Task": "Image_Denoising", "score": "25.75"}, {"Material": "BSD200_sigma50", "Method": "RED30", "Metric": "SSIM", "Task": "Image_Denoising", "score": "0.7167"}, {"Material": "BSD200_sigma70", "Method": "RED30", "Metric": "PSNR", "Task": "Image_Denoising", "score": "24.37"}, {"Material": "BSD200_sigma70", "Method": "RED30", "Metric": "SSIM", "Task": "Image_Denoising", "score": "0.6551"}, {"Material": "Urban100_sigma50", "Method": "RED30", "Metric": "PSNR", "Task": "Image_Denoising", "score": "26.32"}, {"Material": "Urban100_sigma70", "Method": "RED30", "Metric": "PSNR", "Task": "Image_Denoising", "score": "24.63"}]}
{"doc_id": "2594a77a3f0dd5073f79ba620e2f287804cec630", "arxiv_id": "", "title": "Regularizing face verification nets for pain intensity regression", "n_ary_relations": [{"Material": "UNBC-McMaster_ShoulderPain_dataset", "Method": "Regularized_Deep_Regressor", "Metric": "MAE", "Task": "Pain_Intensity_Regression", "score": "0.389"}]}
{"doc_id": "25c108a56e4cb757b62911639a40e9caf07f1b4f", "arxiv_id": "1707.09531", "title": "Recurrent Scale Approximation for Object Detection in CNN", "n_ary_relations": [{"Material": "Annotated_Faces_in_the_Wild", "Method": "LRN___RSA", "Metric": "AP", "Task": "Face_Detection", "score": "0.9917"}]}
{"doc_id": "269c7aeca29dae51dca8208815f1c4c81bd471c2", "arxiv_id": "1810.07599", "title": "Orthogonal Deep Features Decomposition for Age-Invariant Face Recognition", "n_ary_relations": [{"Material": "CACDVS", "Method": "OE-CNN", "Metric": "Accuracy", "Task": "Age-Invariant_Face_Recognition", "score": "99.20%"}, {"Material": "MORPH_Album2", "Method": "OE-CNN", "Metric": "Rank-1_Recognition_Rate", "Task": "Age-Invariant_Face_Recognition", "score": "98.55%"}]}
{"doc_id": "26c8d040bef85ad6dde55a8f71af936fb38356ad", "arxiv_id": "1506.07503", "title": "Attention-Based Models for Speech Recognition", "n_ary_relations": [{"Material": "TIMIT", "Method": "Bi-RNN___Attention", "Metric": "Percentage_error", "Task": "Speech_Recognition", "score": 17.6}]}
{"doc_id": "26fe009b958e8728382d9d764bd7153632f0b869", "arxiv_id": "1708.02312", "title": "Shortcut-Stacked Sentence Encoders for Multi-Domain Inference", "n_ary_relations": [{"Material": "SNLI", "Method": "300D_Residual_stacked_encoders", "Metric": "__Test_Accuracy", "Task": "Natural_Language_Inference", "score": "85.7"}, {"Material": "SNLI", "Method": "600D_Residual_stacked_encoders", "Metric": "__Test_Accuracy", "Task": "Natural_Language_Inference", "score": "86.0"}, {"Material": "SNLI", "Method": "300D_Residual_stacked_encoders", "Metric": "__Train_Accuracy", "Task": "Natural_Language_Inference", "score": "89.8"}, {"Material": "SNLI", "Method": "600D_Residual_stacked_encoders", "Metric": "__Train_Accuracy", "Task": "Natural_Language_Inference", "score": "91.0"}, {"Material": "SNLI", "Method": "300D_Residual_stacked_encoders", "Metric": "Parameters", "Task": "Natural_Language_Inference", "score": "9.7m"}, {"Material": "SNLI", "Method": "600D_Residual_stacked_encoders", "Metric": "Parameters", "Task": "Natural_Language_Inference", "score": "29m"}]}
{"doc_id": "2742a33946e20dd33140b8d6e80d5fd04fced1b2", "arxiv_id": "1603.08182", "title": "3DMatch: Learning Local Geometric Descriptors from RGB-D Reconstructions", "n_ary_relations": [{"Material": "Scan2CAD", "Method": "3DMatch", "Metric": "Average_Accuracy", "Task": "3D_Reconstruction", "score": "10.29%"}]}
{"doc_id": "2788a2461ed0067e2f7aaa63c449a24a237ec341", "arxiv_id": "1708.04896", "title": "Random Erasing Data Augmentation", "n_ary_relations": [{"Material": "DukeMTMC-reID", "Method": "SVDNet___Random_Erasing", "Metric": "MAP", "Task": "Person_Re-Identification", "score": "62.4"}, {"Material": "DukeMTMC-reID", "Method": "TriNet___Random_Erasing", "Metric": "MAP", "Task": "Person_Re-Identification", "score": "56.6"}, {"Material": "DukeMTMC-reID", "Method": "SVDNet___Random_Erasing", "Metric": "Rank-1", "Task": "Person_Re-Identification", "score": "79.3"}, {"Material": "DukeMTMC-reID", "Method": "TriNet___Random_Erasing", "Metric": "Rank-1", "Task": "Person_Re-Identification", "score": "73.0"}, {"Material": "Fashion-MNIST", "Method": "Random_Erasing", "Metric": "Percentage_error", "Task": "Image_Classification", "score": "3.65"}, {"Material": "PASCAL_VOC_2007", "Method": "I_ORE", "Metric": "MAP", "Task": "Object_Detection", "score": "76.2%"}]}
{"doc_id": "27c761258329eddb90b64d52679ff190cb4527b5", "arxiv_id": "1802.06955", "title": "Recurrent Residual Convolutional Neural Network based on U-Net (R2U-Net) for Medical Image Segmentation", "n_ary_relations": [{"Material": "CHASE_DB1", "Method": "R2U-Net", "Metric": "AUC", "Task": "Retinal_Vessel_Segmentation", "score": "0.9815"}, {"Material": "CHASE_DB1", "Method": "R2U-Net", "Metric": "F1_score", "Task": "Retinal_Vessel_Segmentation", "score": "0.7928"}, {"Material": "DRIVE", "Method": "R2U-Net", "Metric": "AUC", "Task": "Retinal_Vessel_Segmentation", "score": "0.9784"}, {"Material": "DRIVE", "Method": "R2U-Net", "Metric": "F1_score", "Task": "Retinal_Vessel_Segmentation", "score": "0.8171"}, {"Material": "Kaggle_Skin_Lesion_Segmentation", "Method": "R2U-Net", "Metric": "AUC", "Task": "Skin_Cancer_Segmentation", "score": "0.9419"}, {"Material": "Kaggle_Skin_Lesion_Segmentation", "Method": "R2U-Net", "Metric": "F1_score", "Task": "Skin_Cancer_Segmentation", "score": "0.8920"}, {"Material": "LUNA", "Method": "R2U-Net", "Metric": "AUC", "Task": "Lung_Nodule_Segmentation", "score": "0.9889"}, {"Material": "LUNA", "Method": "R2U-Net", "Metric": "F1_score", "Task": "Lung_Nodule_Segmentation", "score": "0.9823"}, {"Material": "STARE", "Method": "R2U-Net", "Metric": "AUC", "Task": "Retinal_Vessel_Segmentation", "score": "0.9914"}, {"Material": "STARE", "Method": "R2U-Net", "Metric": "F1_score", "Task": "Retinal_Vessel_Segmentation", "score": "0.8475"}]}
{"doc_id": "27e4b65121d3c88643d86dc91a9bdafdf223b988", "arxiv_id": "1602.06023", "title": "Abstractive Text Summarization using Sequence-to-sequence RNNs and Beyond", "n_ary_relations": [{"Material": "DUC_2004_Task_1", "Method": "words-lvt5k-1sent", "Metric": "ROUGE-1", "Task": "Text_Summarization", "score": "28.61"}, {"Material": "DUC_2004_Task_1", "Method": "words-lvt5k-1sent", "Metric": "ROUGE-2", "Task": "Text_Summarization", "score": "9.42"}, {"Material": "DUC_2004_Task_1", "Method": "words-lvt5k-1sent", "Metric": "ROUGE-L", "Task": "Text_Summarization", "score": "25.24"}, {"Material": "GigaWord", "Method": "words-lvt5k-1sent", "Metric": "ROUGE-1", "Task": "Text_Summarization", "score": "36.4"}, {"Material": "GigaWord", "Method": "words-lvt5k-1sent", "Metric": "ROUGE-2", "Task": "Text_Summarization", "score": "17.7"}, {"Material": "GigaWord", "Method": "words-lvt5k-1sent", "Metric": "ROUGE-L", "Task": "Text_Summarization", "score": "33.71"}]}
{"doc_id": "28703eef8fe505e8bd592ced3ce52a597097b031", "arxiv_id": "1606.02960", "title": "Sequence-to-Sequence Learning as Beam-Search Optimization", "n_ary_relations": [{"Material": "IWSLT2015_German-English", "Method": "Word-level_CNN_w_attn__input_feeding", "Metric": "BLEU_score", "Task": "Machine_Translation", "score": "24.0"}]}
{"doc_id": "289e91654f6da968d625481ef21f52892052d4fc", "arxiv_id": "1811.09386", "title": "Explicit Interaction Model towards Text Classification", "n_ary_relations": [{"Material": "AG_News", "Method": "EXAM", "Metric": "Error", "Task": "Text_Classification", "score": "7"}, {"Material": "Amazon_Review_Full", "Method": "EXAM", "Metric": "Accuracy", "Task": "Sentiment_Analysis", "score": "61.9"}, {"Material": "Amazon_Review_Polarity", "Method": "EXAM", "Metric": "Accuracy", "Task": "Sentiment_Analysis", "score": "95.5"}, {"Material": "DBpedia", "Method": "EXAM", "Metric": "Error", "Task": "Text_Classification", "score": "1"}, {"Material": "Yahoo__Answers", "Method": "EXAM", "Metric": "Accuracy", "Task": "Text_Classification", "score": "74.8"}]}
{"doc_id": "28eceb438da0b841bbd3d02684dbfa263838ed60", "arxiv_id": "1707.09405", "title": "Photographic Image Synthesis with Cascaded Refinement Networks", "n_ary_relations": [{"Material": "ADE20K_Labels-to-Photos", "Method": "CRN", "Metric": "Accuracy", "Task": "Image-to-Image_Translation", "score": "68.8%"}, {"Material": "ADE20K_Labels-to-Photos", "Method": "CRN", "Metric": "FID", "Task": "Image-to-Image_Translation", "score": "73.3"}, {"Material": "ADE20K_Labels-to-Photos", "Method": "CRN", "Metric": "mIoU", "Task": "Image-to-Image_Translation", "score": "22.4"}, {"Material": "ADE20K-Outdoor_Labels-to-Photos", "Method": "CRN", "Metric": "Accuracy", "Task": "Image-to-Image_Translation", "score": "68.6%"}, {"Material": "ADE20K-Outdoor_Labels-to-Photos", "Method": "CRN", "Metric": "FID", "Task": "Image-to-Image_Translation", "score": "99.0"}, {"Material": "ADE20K-Outdoor_Labels-to-Photos", "Method": "CRN", "Metric": "mIoU", "Task": "Image-to-Image_Translation", "score": "16.5"}, {"Material": "COCO-Stuff_Labels-to-Photos", "Method": "CRN", "Metric": "Accuracy", "Task": "Image-to-Image_Translation", "score": "40.4%"}, {"Material": "COCO-Stuff_Labels-to-Photos", "Method": "CRN", "Metric": "FID", "Task": "Image-to-Image_Translation", "score": "70.4"}, {"Material": "COCO-Stuff_Labels-to-Photos", "Method": "CRN", "Metric": "mIoU", "Task": "Image-to-Image_Translation", "score": "23.7"}, {"Material": "Cityscapes_Labels-to-Photo", "Method": "CRN", "Metric": "Class_IOU", "Task": "Image-to-Image_Translation", "score": ""}, {"Material": "Cityscapes_Labels-to-Photo", "Method": "CRN", "Metric": "FID", "Task": "Image-to-Image_Translation", "score": "104.7"}, {"Material": "Cityscapes_Labels-to-Photo", "Method": "CRN", "Metric": "Per-class_Accuracy", "Task": "Image-to-Image_Translation", "score": ""}, {"Material": "Cityscapes_Labels-to-Photo", "Method": "CRN", "Metric": "Per-pixel_Accuracy", "Task": "Image-to-Image_Translation", "score": "77.1%"}, {"Material": "Cityscapes_Labels-to-Photo", "Method": "CRN", "Metric": "mIoU", "Task": "Image-to-Image_Translation", "score": "52.4"}]}
{"doc_id": "29c19276b8fff231717c3e342cb24144d2b77726", "arxiv_id": "1604.05529", "title": "Multilingual Part-of-Speech Tagging with Bidirectional Long Short-Term Memory Models and Auxiliary Loss", "n_ary_relations": [{"Material": "Penn_Treebank", "Method": "Bi-LSTM", "Metric": "Accuracy", "Task": "Part-Of-Speech_Tagging", "score": "97.22"}, {"Material": "UD", "Method": "Bi-LSTM", "Metric": "Avg_accuracy", "Task": "Part-Of-Speech_Tagging", "score": "96.40"}]}
{"doc_id": "2a69ddbafb23c63e5e22401664bea229daaeb7d6", "arxiv_id": "1904.01169", "title": "Res2Net: A New Multi-Scale Backbone Architecture", "n_ary_relations": [{"Material": "CIFAR-100", "Method": "Res2NeXt-29", "Metric": "Percentage_correct", "Task": "Image_Classification", "score": "83.44"}, {"Material": "CIFAR-100", "Method": "Res2NeXt-29", "Metric": "Percentage_error", "Task": "Image_Classification", "score": "16.56"}, {"Material": "ImageNet", "Method": "Res2Net-DLA-60", "Metric": "Top_1_Accuracy", "Task": "Image_Classification", "score": "79.47%"}]}
{"doc_id": "2a94c84383ee3de5e6211d43d16e7de387f68878", "arxiv_id": "1612.03144", "title": "Feature Pyramid Networks for Object Detection", "n_ary_relations": [{"Material": "COCO", "Method": "Faster_R-CNN___FPN", "Metric": "Bounding_Box_AP", "Task": "Object_Detection", "score": "36.2"}]}
{"doc_id": "2ad7cef781f98fd66101fa4a78e012369d064830", "arxiv_id": "1603.05474", "title": "Neural Aggregation Network for Video Face Recognition", "n_ary_relations": [{"Material": "IJB-A", "Method": "NAN", "Metric": "TAR___FAR_0_01", "Task": "Face_Verification", "score": "94.10%"}]}
{"doc_id": "2aec8d465e9a74c27f956ed1136f3e8a3ba0a833", "arxiv_id": "1710.04026", "title": "FFDNet: Toward a Fast and Flexible Solution for CNN-Based Image Denoising", "n_ary_relations": [{"Material": "BSD68_sigma15", "Method": "FFDNet", "Metric": "PSNR", "Task": "Image_Denoising", "score": "31.63"}, {"Material": "BSD68_sigma25", "Method": "FFDNet", "Metric": "PSNR", "Task": "Image_Denoising", "score": "29.19"}, {"Material": "BSD68_sigma50", "Method": "FFDNet", "Metric": "PSNR", "Task": "Image_Denoising", "score": "26.29"}]}
{"doc_id": "2b0d7e51efd004fe3847f54863540c79312f3546", "arxiv_id": "1810.04650", "title": "Multi-Task Learning as Multi-Objective Optimization", "n_ary_relations": [{"Material": "CelebA", "Method": "MGDA-UB", "Metric": "Error", "Task": "Multi-Task_Learning", "score": "8.25"}, {"Material": "Cityscapes", "Method": "MultiObjectiveOptimization", "Metric": "mIoU", "Task": "Multi-Task_Learning", "score": "66.63"}]}
{"doc_id": "2bb9f0768fac9622a0be446df69daf75a954d5ac", "arxiv_id": "1810.03541", "title": "An AMR Aligner Tuned by Transition-based Parser", "n_ary_relations": [{"Material": "LDC2014T12_", "Method": "Transition-based_improved_aligner_ensemble", "Metric": "F1_Full", "Task": "Amr_Parsing", "score": "0.68"}, {"Material": "LDC2014T12_", "Method": "Transition-based_improved_aligner_ensemble", "Metric": "F1_Newswire", "Task": "Amr_Parsing", "score": "0.73"}]}
{"doc_id": "2c03df8b48bf3fa39054345bafabfeff15bfd11d", "arxiv_id": "1512.03385", "title": "Deep Residual Learning for Image Recognition", "n_ary_relations": [{"Material": "CIFAR-10", "Method": "ResNet", "Metric": "Percentage_correct", "Task": "Image_Classification", "score": "93.57"}, {"Material": "CIFAR-10", "Method": "ResNet", "Metric": "Percentage_error", "Task": "Image_Classification", "score": "6.43"}, {"Material": "COCO", "Method": "Faster_R-CNN___box_refinement___context___multi-scale_testing", "Metric": "Bounding_Box_AP", "Task": "Object_Detection", "score": "34.9"}, {"Material": "PASCAL_VOC_2007", "Method": "ResNet-101", "Metric": "MAP", "Task": "Object_Detection", "score": "76.4%"}]}
{"doc_id": "2c761495cf3dd320e229586f80f868be12360d4e", "arxiv_id": "1707.02968", "title": "Revisiting Unreasonable Effectiveness of Data in Deep Learning Era", "n_ary_relations": [{"Material": "ImageNet", "Method": "JFT-300M_Finetuning", "Metric": "Top_1_Accuracy", "Task": "Image_Classification", "score": "79.2%"}, {"Material": "ImageNet", "Method": "JFT-300M_Finetuning", "Metric": "Top_5_Accuracy", "Task": "Image_Classification", "score": "94.7%"}, {"Material": "PASCAL_VOC_2012", "Method": "ImageNet_JFT-300M_Initialization", "Metric": "Mean_IoU", "Task": "Semantic_Segmentation", "score": "76.5%"}]}
{"doc_id": "2cb8497f9214735ffd1bd57db645794459b8ff41", "arxiv_id": "1506.03340", "title": "Teaching Machines to Read and Comprehend", "n_ary_relations": [{"Material": "CNN___Daily_Mail", "Method": "Attentive_Reader", "Metric": "CNN", "Task": "Question_Answering", "score": "63"}, {"Material": "CNN___Daily_Mail", "Method": "Impatient_Reader", "Metric": "CNN", "Task": "Question_Answering", "score": "63.8"}, {"Material": "CNN___Daily_Mail", "Method": "MemNNs__ensemble_", "Metric": "CNN", "Task": "Question_Answering", "score": "69.4"}, {"Material": "CNN___Daily_Mail", "Method": "Attentive_Reader", "Metric": "Daily_Mail", "Task": "Question_Answering", "score": "69"}, {"Material": "CNN___Daily_Mail", "Method": "Impatient_Reader", "Metric": "Daily_Mail", "Task": "Question_Answering", "score": "68.0"}]}
{"doc_id": "2cf6a8389135f682b0cb727a07f4e77c097d5434", "arxiv_id": "1409.3660", "title": "10, 000+ Times Accelerated Robust Subset Selection", "n_ary_relations": [{"Material": "CIFAR-10", "Method": "Deep_Diffusion", "Metric": "NLL_Test", "Task": "Image_Generation", "score": "4.20"}]}
{"doc_id": "2d294bde112b892068636f3a48300b3c033d98da", "arxiv_id": "1808.01558", "title": "Deep Multi-Center Learning for Face Alignment", "n_ary_relations": [{"Material": "AFLW2000", "Method": "MCL", "Metric": "Error_rate", "Task": "Face_Alignment", "score": "5.38"}]}
{"doc_id": "2d2a22f1f9eae9188f3d43254daa2d5b7f3a2470", "arxiv_id": "1511.05493", "title": "Gated Graph Sequence Neural Networks", "n_ary_relations": [{"Material": "QM9", "Method": "Gated_Graph_Sequence_NN", "Metric": "Error_ratio", "Task": "Drug_Discovery", "score": "1.36"}, {"Material": "WikiSQL", "Method": "GGS-NN", "Metric": "BLEU-4", "Task": "SQL-to-Text", "score": "35.53"}]}
{"doc_id": "2d5dba33c706d907733f15e7b57fde9909894e29", "arxiv_id": "1703.06520", "title": "Detecting Oriented Text in Natural Images by Linking Segments", "n_ary_relations": [{"Material": "IC15", "Method": "SegLink", "Metric": "F-Measure", "Task": "Scene_Text_Detection", "score": "75.61%"}, {"Material": "SCUT-CTW1500", "Method": "SegLink", "Metric": "F-Measure", "Task": "Curved_Text_Detection", "score": "40.8%"}]}
{"doc_id": "2d83dbf4c8eabc6bdef3326c4a30d5f33ffc944e", "arxiv_id": "1606.01455", "title": "Multimodal Residual Learning for Visual QA", "n_ary_relations": [{"Material": "COCO_Visual_Question_Answering__VQA__real_images_1_0_multiple_choice", "Method": "MRN", "Metric": "Percentage_correct", "Task": "Visual_Question_Answering", "score": 66.33}, {"Material": "COCO_Visual_Question_Answering__VQA__real_images_1_0_open_ended", "Method": "MRN___global_features", "Metric": "Percentage_correct", "Task": "Visual_Question_Answering", "score": 61.84}]}
{"doc_id": "2d876ed1dd2c58058d7197b734a8e4d349b8f231", "arxiv_id": "1611.01576", "title": "Quasi-Recurrent Neural Networks", "n_ary_relations": [{"Material": "IWSLT2015_German-English", "Method": "QRNN", "Metric": "BLEU_score", "Task": "Machine_Translation", "score": "19.41"}]}
{"doc_id": "2dad7e558a1e2982d0d42042021f4cde4af04abf", "arxiv_id": "1710.02224", "title": "Dilated Recurrent Neural Networks", "n_ary_relations": [{"Material": "Sequential_MNIST", "Method": "Dilated_GRU", "Metric": "Permuted_Accuracy", "Task": "Sequential_Image_Classification", "score": "94.6%"}, {"Material": "Sequential_MNIST", "Method": "Dilated_GRU", "Metric": "Unpermuted_Accuracy", "Task": "Sequential_Image_Classification", "score": "99.2%"}]}
{"doc_id": "2dc32f9e0a7870b272a2a51082202a9fa52fb854", "arxiv_id": "1704.03915", "title": "Deep Laplacian Pyramid Networks for Fast and Accurate Super-Resolution", "n_ary_relations": [{"Material": "BSD100_-_4x_upscaling", "Method": "LapSRN", "Metric": "PSNR", "Task": "Image_Super-Resolution", "score": "27.32"}, {"Material": "Set14_-_4x_upscaling", "Method": "_LapSR", "Metric": "PSNR", "Task": "Image_Super-Resolution", "score": "28.19"}, {"Material": "Urban100_-_4x_upscaling", "Method": "LapSRN", "Metric": "PSNR", "Task": "Image_Super-Resolution", "score": "25.21"}]}
{"doc_id": "2e10643c3759f97b673ff8c297778c0b6c20032b", "arxiv_id": "1509.01626", "title": "Character-level Convolutional Networks for Text Classification", "n_ary_relations": [{"Material": "AG_News", "Method": "Char-level_CNN", "Metric": "Error", "Task": "Text_Classification", "score": "9.51"}, {"Material": "DBpedia", "Method": "Char-level_CNN", "Metric": "Error", "Task": "Text_Classification", "score": "1.55"}, {"Material": "Yelp_Binary_classification", "Method": "Char-level_CNN", "Metric": "Error", "Task": "Sentiment_Analysis", "score": "4.88"}, {"Material": "Yelp_Fine-grained_classification", "Method": "Char-level_CNN", "Metric": "Error", "Task": "Sentiment_Analysis", "score": "37.95"}]}
{"doc_id": "2e4c06dd00c4c09ad5ac6be883cc66c19d88ea79", "arxiv_id": "1802.08352", "title": "Learning to Make Predictions on Graphs with Autoencoders", "n_ary_relations": [{"Material": "Citeseer", "Method": "alpha-LoNGAE", "Metric": "Accuracy", "Task": "Node_Classification", "score": "71.60%"}, {"Material": "Cora", "Method": "alpha-LoNGAE", "Metric": "Accuracy", "Task": "Node_Classification", "score": "78.30%"}, {"Material": "Pubmed", "Method": "alpha-LoNGAE", "Metric": "Accuracy", "Task": "Node_Classification", "score": "79.40%"}]}
{"doc_id": "2e57bccb74bcb46cbc5b4225b62679023ed1f9da", "arxiv_id": "1609.05284", "title": "ReasoNet: Learning to Stop Reading in Machine Comprehension", "n_ary_relations": [{"Material": "CNN___Daily_Mail", "Method": "ReasoNet", "Metric": "CNN", "Task": "Question_Answering", "score": "74.7"}, {"Material": "CNN___Daily_Mail", "Method": "ReasoNet", "Metric": "Daily_Mail", "Task": "Question_Answering", "score": "76.6"}, {"Material": "SQuAD1_1", "Method": "ReasoNet__ensemble_", "Metric": "EM", "Task": "Question_Answering", "score": "75.034"}, {"Material": "SQuAD1_1", "Method": "ReasoNet__single_model_", "Metric": "EM", "Task": "Question_Answering", "score": "70.555"}, {"Material": "SQuAD1_1", "Method": "ReasoNet__ensemble_", "Metric": "F1", "Task": "Question_Answering", "score": "82.552"}, {"Material": "SQuAD1_1", "Method": "ReasoNet__single_model_", "Metric": "F1", "Task": "Question_Answering", "score": "79.364"}]}
{"doc_id": "2e942d19333651bf6012374ea9e78d6937fd33ac", "arxiv_id": "", "title": "Detecting Faces Using Region-based Fully Convolutional Networks", "n_ary_relations": [{"Material": "FDDB", "Method": "Face_R-FCN", "Metric": "AP", "Task": "Face_Detection", "score": "0.990"}, {"Material": "WIDER_Face__Easy_", "Method": "Face_R-FCN", "Metric": "AP", "Task": "Face_Detection", "score": "0.943"}, {"Material": "WIDER_Face__Hard_", "Method": "Face_R-FCN", "Metric": "AP", "Task": "Face_Detection", "score": "0.876"}, {"Material": "WIDER_Face__Medium_", "Method": "Face_R-FCN", "Metric": "AP", "Task": "Face_Detection", "score": "0.931"}]}
{"doc_id": "2ebfc12285f5d426e0d0e8d2befa1af27f99a56e", "arxiv_id": "1811.12608", "title": "DeepFlux for Skeletons in the Wild", "n_ary_relations": [{"Material": "SK-LARGE", "Method": "DeepFlux", "Metric": "F-Measure", "Task": "Object_Skeleton_Detection", "score": "0.732"}]}
{"doc_id": "2f0c30d6970da9ee9cf957350d9fa1025a1becb4", "arxiv_id": "1703.06211", "title": "Deformable Convolutional Networks", "n_ary_relations": [{"Material": "COCO", "Method": "D-RFCN___ResNet-101__6_scales_", "Metric": "Bounding_Box_AP", "Task": "Object_Detection", "score": "40.9"}]}
{"doc_id": "2f92b10acf7c405e55c74c1043dabd9ded1b1800", "arxiv_id": "1706.02596", "title": "Dynamic Integration of Background Knowledge in Neural NLU Systems", "n_ary_relations": [{"Material": "TriviaQA", "Method": "Reading_Twice_for_NLU", "Metric": "EM", "Task": "Question_Answering", "score": "50.56"}, {"Material": "TriviaQA", "Method": "Reading_Twice_for_NLU", "Metric": "F1", "Task": "Question_Answering", "score": "56.73"}]}
{"doc_id": "2f95ba08a8f5a97d1a767f3a2490c686ee8f762d", "arxiv_id": "1811.02798", "title": "Multi-Task Graph Autoencoders", "n_ary_relations": [{"Material": "Citeseer", "Method": "MTGAE", "Metric": "Accuracy", "Task": "Link_Prediction", "score": "94.90%"}, {"Material": "Citeseer", "Method": "MTGAE", "Metric": "Accuracy", "Task": "Node_Classification", "score": "71.80%"}, {"Material": "Cora", "Method": "MTGAE", "Metric": "Accuracy", "Task": "Link_Prediction", "score": "94.60%"}, {"Material": "Cora", "Method": "MTGAE", "Metric": "Accuracy", "Task": "Node_Classification", "score": "79.00%"}, {"Material": "Pubmed", "Method": "MTGAE", "Metric": "Accuracy", "Task": "Link_Prediction", "score": "94.40%"}, {"Material": "Pubmed", "Method": "MTGAE", "Metric": "Accuracy", "Task": "Node_Classification", "score": "80.40%"}]}
{"doc_id": "30180f66d5b4b7c0367e4b43e2b55367b72d6d2a", "arxiv_id": "1603.03958", "title": "Template Adaptation for Face Verification and Identification", "n_ary_relations": [{"Material": "IJB-A", "Method": "Template_adaptation", "Metric": "TAR___FAR_0_01", "Task": "Face_Verification", "score": "93.90%"}]}
{"doc_id": "302207c149bdf7beb6e46e4d4afbd2fa9ac02c64", "arxiv_id": "1711.09020", "title": "StarGAN: Unified Generative Adversarial Networks for Multi-domain Image-to-Image Translation", "n_ary_relations": [{"Material": "RaFD", "Method": "StarGAN", "Metric": "Classification_Error", "Task": "Image-to-Image_Translation", "score": "2.12%"}]}
{"doc_id": "303065c44cf847849d04da16b8b1d9a120cef73a", "arxiv_id": "1701.05360", "title": "3D Face Morphable Models \"In-the-Wild\"", "n_ary_relations": [{"Material": "Florence", "Method": "itwmm", "Metric": "Average_3D_Error", "Task": "3D_Face_Reconstruction", "score": "1.82"}]}
{"doc_id": "303fef411f235e6d1125a40af1e93224f498a4d5", "arxiv_id": "1711.03953", "title": "Breaking the Softmax Bottleneck: A High-Rank RNN Language Model", "n_ary_relations": [{"Material": "Penn_Treebank__Word_Level_", "Method": "AWD-LSTM-MoS", "Metric": "Params", "Task": "Language_Modelling", "score": "22M"}, {"Material": "Penn_Treebank__Word_Level_", "Method": "AWD-LSTM-MoS___dynamic_eval", "Metric": "Params", "Task": "Language_Modelling", "score": "22M"}, {"Material": "Penn_Treebank__Word_Level_", "Method": "AWD-LSTM-MoS", "Metric": "Test_perplexity", "Task": "Language_Modelling", "score": "54.44"}, {"Material": "Penn_Treebank__Word_Level_", "Method": "AWD-LSTM-MoS___dynamic_eval", "Metric": "Test_perplexity", "Task": "Language_Modelling", "score": "47.69"}, {"Material": "Penn_Treebank__Word_Level_", "Method": "AWD-LSTM-MoS", "Metric": "Validation_perplexity", "Task": "Language_Modelling", "score": "56.54"}, {"Material": "Penn_Treebank__Word_Level_", "Method": "AWD-LSTM-MoS___dynamic_eval", "Metric": "Validation_perplexity", "Task": "Language_Modelling", "score": "48.33"}, {"Material": "WikiText-2", "Method": "AWD-LSTM-MoS", "Metric": "Number_of_params", "Task": "Language_Modelling", "score": "35M"}, {"Material": "WikiText-2", "Method": "AWD-LSTM-MoS___dynamic_eval", "Metric": "Number_of_params", "Task": "Language_Modelling", "score": "35M"}, {"Material": "WikiText-2", "Method": "AWD-LSTM-MoS", "Metric": "Test_perplexity", "Task": "Language_Modelling", "score": "61.45"}, {"Material": "WikiText-2", "Method": "AWD-LSTM-MoS___dynamic_eval", "Metric": "Test_perplexity", "Task": "Language_Modelling", "score": "40.68"}, {"Material": "WikiText-2", "Method": "AWD-LSTM-MoS", "Metric": "Validation_perplexity", "Task": "Language_Modelling", "score": "63.88"}, {"Material": "WikiText-2", "Method": "AWD-LSTM-MoS___dynamic_eval", "Metric": "Validation_perplexity", "Task": "Language_Modelling", "score": "42.41"}]}
{"doc_id": "309acdd149f5f0ea12acb103b36bb59e6e631671", "arxiv_id": "1701.00295", "title": "Lifting from the Deep: Convolutional 3D Pose Estimation from a Single Image", "n_ary_relations": [{"Material": "Human3_6M", "Method": "Projected-pose_belief_maps___2D_fusion_layers", "Metric": "Average_3D_Error", "Task": "3D_Human_Pose_Estimation", "score": "88.39"}]}
{"doc_id": "3112d2d95d66b3d54a72c55072647aab937e410e", "arxiv_id": "1707.08052", "title": "Challenges in Data-to-Document Generation", "n_ary_relations": [{"Material": "RotoWire", "Method": "Encoder-decoder___conditional_copy", "Metric": "BLEU", "Task": "Data-to-Text_Generation", "score": "14.19"}, {"Material": "RotoWire__Content_Ordering_", "Method": "Encoder-decoder___conditional_copy", "Metric": "DLD", "Task": "Data-to-Text_Generation", "score": "15.42%"}, {"Material": "RotoWire__Relation_Generation_", "Method": "Encoder-decoder___conditional_copy", "Metric": "Precision", "Task": "Data-to-Text_Generation", "score": "74.80%"}, {"Material": "RotoWire__Relation_Generation_", "Method": "Encoder-decoder___conditional_copy", "Metric": "count", "Task": "Data-to-Text_Generation", "score": "23.72"}, {"Material": "Rotowire__Content_Selection_", "Method": "Encoder-decoder___conditional_copy", "Metric": "Precision", "Task": "Data-to-Text_Generation", "score": "29.49%"}, {"Material": "Rotowire__Content_Selection_", "Method": "Encoder-decoder___conditional_copy", "Metric": "Recall", "Task": "Data-to-Text_Generation", "score": "36.18%"}]}
{"doc_id": "31ae4873da19b1e28eca8787a17f49bba08627e5", "arxiv_id": "1704.03414", "title": "A-Fast-RCNN: Hard Positive Generation via Adversary for Object Detection", "n_ary_relations": [{"Material": "PASCAL_VOC_2007", "Method": "FRCN", "Metric": "MAP", "Task": "Object_Detection", "score": "74.2%"}]}
{"doc_id": "31e5dab321066712cdc8b30943f7950066840ee1", "arxiv_id": "1903.11410", "title": "Structural Neural Encoders for AMR-to-text Generation", "n_ary_relations": [{"Material": "LDC2015E86_", "Method": "GCNSEQ", "Metric": "BLEU", "Task": "Graph-to-Sequence", "score": "23.95"}]}
{"doc_id": "325093f2c5b33d7507c10aa422e96aa5b10a33f1", "arxiv_id": "1712.02616", "title": "In-place Activated BatchNorm for Memory-Optimized Training of DNNs", "n_ary_relations": [{"Material": "Cityscapes", "Method": "Mapillary", "Metric": "Mean_IoU", "Task": "Semantic_Segmentation", "score": "82.0%"}]}
{"doc_id": "32a93598e8a338496f04a0ace81b0768c2ef059d", "arxiv_id": "1606.07947", "title": "Sequence-Level Knowledge Distillation", "n_ary_relations": [{"Material": "IWSLT2015_Thai-English", "Method": "Seq-KD___Seq-Inter___Word-KD", "Metric": "BLEU_score", "Task": "Machine_Translation", "score": "14.2"}, {"Material": "WMT2014_English-German", "Method": "Seq-KD___Seq-Inter___Word-KD", "Metric": "BLEU_score", "Task": "Machine_Translation", "score": "18.5"}]}
{"doc_id": "32b36a9837da7eb19fb9e6bd85d48d38a81ff75f", "arxiv_id": "1511.00830", "title": "The Variational Fair Autoencoder", "n_ary_relations": [{"Material": "Multi-Domain_Sentiment_Dataset", "Method": "VFAE", "Metric": "Average", "Task": "Sentiment_Analysis", "score": "78.36"}, {"Material": "Multi-Domain_Sentiment_Dataset", "Method": "VFAE", "Metric": "Books", "Task": "Sentiment_Analysis", "score": "73.40"}, {"Material": "Multi-Domain_Sentiment_Dataset", "Method": "VFAE", "Metric": "DVD", "Task": "Sentiment_Analysis", "score": "76.57"}, {"Material": "Multi-Domain_Sentiment_Dataset", "Method": "VFAE", "Metric": "Electronics", "Task": "Sentiment_Analysis", "score": "80.53"}, {"Material": "Multi-Domain_Sentiment_Dataset", "Method": "VFAE", "Metric": "Kitchen", "Task": "Sentiment_Analysis", "score": "82.93"}]}
{"doc_id": "33998aff64ce51df8dee45989cdca4b6b1329ec4", "arxiv_id": "1710.10903", "title": "Graph Attention Networks", "n_ary_relations": [{"Material": "Cora", "Method": "GAT", "Metric": "Accuracy", "Task": "Document_Classification", "score": "83.0%"}]}
{"doc_id": "33a8d0a35390fde736744d4a0dd20dff7961c777", "arxiv_id": "1805.08090", "title": "Graph Capsule Convolutional Neural Networks", "n_ary_relations": [{"Material": "D_D", "Method": "GCAPS-CNN", "Metric": "Accuracy", "Task": "Graph_Classification", "score": "77,62%"}, {"Material": "IMDb-B", "Method": "GCAPS-CNN", "Metric": "Accuracy", "Task": "Graph_Classification", "score": "71.69%"}, {"Material": "NCI1", "Method": "GCAPS-CNN", "Metric": "Accuracy", "Task": "Graph_Classification", "score": "82.72%"}]}
{"doc_id": "34273979fd2a62fd7b49ee6d14a925864ff94e74", "arxiv_id": "1711.08028", "title": "Recurrent Relational Networks", "n_ary_relations": [{"Material": "bAbi", "Method": "_RR", "Metric": "Mean_Error_Rate", "Task": "Question_Answering", "score": "0.46%"}]}
{"doc_id": "346578304ff943b97b3efb1171ecd902cb4f6081", "arxiv_id": "1611.01673", "title": "Generative Multi-Adversarial Networks", "n_ary_relations": [{"Material": "CIFAR-10", "Method": "GMAN", "Metric": "Inception_score", "Task": "Image_Generation", "score": "6.00"}]}
{"doc_id": "34a6762ed8e92612ba4fdf02ee95d2ee0d587908", "arxiv_id": "1808.06281", "title": "Incremental Learning in Person Re-Identification", "n_ary_relations": [{"Material": "DukeMTMC-reID", "Method": "Incremental_Learning", "Metric": "MAP", "Task": "Person_Re-Identification", "score": "60.2"}, {"Material": "DukeMTMC-reID", "Method": "Incremental_Learning", "Metric": "Rank-1", "Task": "Person_Re-Identification", "score": "80.0"}, {"Material": "Market-1501", "Method": "Incremental_Learning", "Metric": "MAP", "Task": "Person_Re-Identification", "score": "71.8"}, {"Material": "Market-1501", "Method": "Incremental_Learning", "Metric": "Rank-1", "Task": "Person_Re-Identification", "score": "89.3"}]}
{"doc_id": "34cf90fcbf83025666c5c86ec30ac58b632b27b0", "arxiv_id": "1710.06555", "title": "Learning Deep Context-Aware Features over Body and Latent Parts for Person Re-identification", "n_ary_relations": [{"Material": "Market-1501", "Method": "MSCAN", "Metric": "MAP", "Task": "Person_Re-Identification", "score": "57.53"}, {"Material": "Market-1501", "Method": "MSCAN", "Metric": "Rank-1", "Task": "Person_Re-Identification", "score": "80.31"}]}
{"doc_id": "34f63959ea4a13a05948274a1558c6854a051150", "arxiv_id": "1901.11504", "title": "Multi-Task Deep Neural Networks for Natural Language Understanding", "n_ary_relations": [{"Material": "MultiNLI", "Method": "MT-DNN", "Metric": "Matched", "Task": "Natural_Language_Inference", "score": "86.7"}, {"Material": "MultiNLI", "Method": "MT-DNN", "Metric": "Mismatched", "Task": "Natural_Language_Inference", "score": "86.0"}, {"Material": "Quora_Question_Pairs", "Method": "MT-DNN", "Metric": "Accuracy", "Task": "Paraphrase_Identification", "score": "89.6"}, {"Material": "SNLI", "Method": "MT-DNN", "Metric": "__Test_Accuracy", "Task": "Natural_Language_Inference", "score": "91.1"}, {"Material": "SNLI", "Method": "MT-DNN", "Metric": "__Train_Accuracy", "Task": "Natural_Language_Inference", "score": "96.8"}, {"Material": "SNLI", "Method": "MT-DNN", "Metric": "Parameters", "Task": "Natural_Language_Inference", "score": "110m"}, {"Material": "SST-2_Binary_classification", "Method": "MT-DNN", "Metric": "Accuracy", "Task": "Sentiment_Analysis", "score": "95.6"}, {"Material": "SciTail", "Method": "MT-DNN", "Metric": "Accuracy", "Task": "Natural_Language_Inference", "score": "94.1"}]}
{"doc_id": "3526555fa0178c101ee9896252c818f9e03532a5", "arxiv_id": "1704.03557", "title": "Cutting the Error by Half: Investigation of Very Deep CNN and Advanced Training Strategies for Document Image Classification", "n_ary_relations": [{"Material": "RVL-CDIP", "Method": "Transfer_Learning_from_AlexNet__VGG-16__GoogLeNet_and_ResNet50", "Metric": "Accuracy", "Task": "Document_Image_Classification", "score": "90.97%"}]}
{"doc_id": "35502af359aa60ae8047df172e29503cfb29c3f9", "arxiv_id": "1712.08273", "title": "Recurrent Pixel Embedding for Instance Grouping", "n_ary_relations": [{"Material": "PASCAL_VOC_2012__60_proposals_per_image", "Method": "Recurrent_Pixel_Embedding", "Metric": "Average_Recall", "Task": "Object_Proposal_Generation", "score": "0.814"}]}
{"doc_id": "357776cd7ee889af954f0dfdbaee71477c09ac18", "arxiv_id": "1511.05644", "title": "Adversarial Autoencoders", "n_ary_relations": [{"Material": "MNIST", "Method": "Adversarial_AE", "Metric": "Accuracy", "Task": "Unsupervised_MNIST", "score": "95.9"}, {"Material": "MNIST", "Method": "Adversarial_AE", "Metric": "Accuracy", "Task": "Unsupervised_image_classification", "score": "95.9"}]}
{"doc_id": "3580d8a5e7584e98d547ebfed900749d347f6714", "arxiv_id": "1711.09724", "title": "Table-to-text Generation by Structure-aware Seq2seq Learning", "n_ary_relations": [{"Material": "WikiBio", "Method": "Field-gating_Seq2seq___dual_attention", "Metric": "BLEU", "Task": "Table-to-text_Generation", "score": "44.89"}, {"Material": "WikiBio", "Method": "Field-gating_Seq2seq___dual_attention___beam_search", "Metric": "BLEU", "Task": "Table-to-text_Generation", "score": "44.71"}, {"Material": "WikiBio", "Method": "Field-gating_Seq2seq___dual_attention", "Metric": "ROUGE", "Task": "Table-to-text_Generation", "score": "41.21"}, {"Material": "WikiBio", "Method": "Field-gating_Seq2seq___dual_attention___beam_search", "Metric": "ROUGE", "Task": "Table-to-text_Generation", "score": "41.65"}]}
{"doc_id": "35c1668dc64d24a28c6041978e5fcca754eb2f4b", "arxiv_id": "1511.06732", "title": "Sequence Level Training with Recurrent Neural Networks", "n_ary_relations": [{"Material": "IWSLT2015_German-English", "Method": "Word-level_LSTM_w_attn", "Metric": "BLEU_score", "Task": "Machine_Translation", "score": "20.2"}]}
{"doc_id": "35ff11e0a5e465c810a30b022b26a9d577a434ce", "arxiv_id": "1611.05774", "title": "What Do Recurrent Neural Network Grammars Learn About Syntax?", "n_ary_relations": [{"Material": "Penn_Treebank", "Method": "Stack-only_RNNG", "Metric": "F1_score", "Task": "Constituency_Parsing", "score": "93.6"}]}
{"doc_id": "3600aac8edc5bc015e69f2ffa893c21b6d4e1057", "arxiv_id": "1711.07246", "title": "Face Attention Network: An Effective Face Detector for the Occluded Faces", "n_ary_relations": [{"Material": "MAFA", "Method": "FAN", "Metric": "MAP", "Task": "Occluded_Face_Detection", "score": "88.3%"}]}
{"doc_id": "360cfa09b2f7c8e10b1831d899c5a51aefa1883e", "arxiv_id": "1803.10225", "title": "Light Gated Recurrent Units for Speech Recognition", "n_ary_relations": [{"Material": "TIMIT", "Method": "Li-GRU___fMLLR_features", "Metric": "Percentage_error", "Task": "Speech_Recognition", "score": "14.9"}, {"Material": "TIMIT", "Method": "Light_Gated_Recurrent_Units", "Metric": "Percentage_error", "Task": "Speech_Recognition", "score": "16.7"}]}
{"doc_id": "364da079f91a6cb385997be990af06e9ddf6e888", "arxiv_id": "1412.1058", "title": "Effective Use of Word Order for Text Categorization with Convolutional Neural Networks", "n_ary_relations": [{"Material": "IMDb", "Method": "seq2-bown-CNN", "Metric": "Accuracy", "Task": "Sentiment_Analysis", "score": "92.33"}]}
{"doc_id": "3652c2d20f198dc39ad159eba55d08341c56d628", "arxiv_id": "1406.3332", "title": "Convolutional Kernel Networks", "n_ary_relations": [{"Material": "CIFAR-10", "Method": "CKN", "Metric": "Percentage_correct", "Task": "Image_Classification", "score": "82.2"}, {"Material": "MNIST", "Method": "CKN", "Metric": "Percentage_error", "Task": "Image_Classification", "score": "0.4"}, {"Material": "STL-10", "Method": "CKN", "Metric": "Percentage_correct", "Task": "Image_Classification", "score": 62.32}]}
{"doc_id": "36911f5fc4f4eb1221f832114946de4773cf78e6", "arxiv_id": "1901.04085", "title": "Passage Re-ranking with BERT", "n_ary_relations": [{"Material": "MS_MARCO", "Method": "BERT___Small_Training", "Metric": "MRR", "Task": "Passage_Re-Ranking", "score": "0.359"}]}
{"doc_id": "36973330ae638571484e1f68aaf455e3e6f18ae9", "arxiv_id": "1510.08160", "title": "Scale-Aware Fast R-CNN for Pedestrian Detection", "n_ary_relations": [{"Material": "Caltech", "Method": "SA-FastRCNN", "Metric": "Reasonable_Miss_Rate", "Task": "Pedestrian_Detection", "score": "9.68"}]}
{"doc_id": "36a03f648b40d209ce361550dbe1c823ddb715b5", "arxiv_id": "1711.07399", "title": "V2V-PoseNet: Voxel-to-Voxel Prediction Network for Accurate 3D Hand and Human Pose Estimation from a Single Depth Map", "n_ary_relations": [{"Material": "_ITOP_front-view", "Method": "V2V-PoseNet", "Metric": "Mean_mAP", "Task": "Pose_Estimation", "score": "88.74"}, {"Material": "HANDS_2017", "Method": "V2V-PoseNet", "Metric": "Average_3D_Error", "Task": "Hand_Pose_Estimation", "score": "9.95"}, {"Material": "ICVL_Hands", "Method": "V2V-PoseNet", "Metric": "Average_3D_Error", "Task": "Hand_Pose_Estimation", "score": "6.28"}, {"Material": "ITOP_top-view", "Method": "V2V-PoseNet", "Metric": "Mean_mAP", "Task": "Pose_Estimation", "score": "83.44"}, {"Material": "MSRA_Hands", "Method": "V2V-PoseNet", "Metric": "Average_3D_Error", "Task": "Hand_Pose_Estimation", "score": "7.49"}, {"Material": "NYU_Hands", "Method": "V2V-PoseNet", "Metric": "Average_3D_Error", "Task": "Hand_Pose_Estimation", "score": " 8.42"}]}
{"doc_id": "36b1ba4287c4884df27dd684c4c7f66f32e943db", "arxiv_id": "1808.07018", "title": "Hypernetwork Knowledge Graph Embeddings", "n_ary_relations": [{"Material": "_FB15k", "Method": "HypER", "Metric": "Hits_1", "Task": "Link_Prediction", "score": "0.734"}, {"Material": "_FB15k", "Method": "HypER", "Metric": "Hits_10", "Task": "Link_Prediction", "score": "0.885"}, {"Material": "_FB15k", "Method": "HypER", "Metric": "Hits_3", "Task": "Link_Prediction", "score": "0.829"}, {"Material": "_FB15k", "Method": "HypER", "Metric": "MRR", "Task": "Link_Prediction", "score": "0.790"}, {"Material": "FB15k-237", "Method": "HypER", "Metric": "Hits_1", "Task": "Link_Prediction", "score": "0.252"}, {"Material": "FB15k-237", "Method": "HypER", "Metric": "Hits_10", "Task": "Link_Prediction", "score": "0.520"}, {"Material": "FB15k-237", "Method": "HypER", "Metric": "Hits_3", "Task": "Link_Prediction", "score": "0.376"}, {"Material": "FB15k-237", "Method": "HypER", "Metric": "MRR", "Task": "Link_Prediction", "score": "0.341"}, {"Material": "WN18", "Method": "HypER", "Metric": "Hits_1", "Task": "Link_Prediction", "score": "0.947"}, {"Material": "WN18", "Method": "HypER", "Metric": "Hits_10", "Task": "Link_Prediction", "score": "0.958"}, {"Material": "WN18", "Method": "HypER", "Metric": "Hits_3", "Task": "Link_Prediction", "score": "0.955"}, {"Material": "WN18", "Method": "HypER", "Metric": "MRR", "Task": "Link_Prediction", "score": "0.951"}, {"Material": "WN18RR", "Method": "HypER", "Metric": "Hits_1", "Task": "Link_Prediction", "score": "0.436"}, {"Material": "WN18RR", "Method": "HypER", "Metric": "Hits_10", "Task": "Link_Prediction", "score": "0.522"}, {"Material": "WN18RR", "Method": "HypER", "Metric": "Hits_3", "Task": "Link_Prediction", "score": "0.477"}, {"Material": "WN18RR", "Method": "HypER", "Metric": "MRR", "Task": "Link_Prediction", "score": "0.465"}]}
{"doc_id": "36c3972569a6949ecca90bfa6f8e99883e092845", "arxiv_id": "1807.09956", "title": "Pythia v0.1: the Winning Entry to the VQA Challenge 2018", "n_ary_relations": [{"Material": "VQA_v2", "Method": "Pythia_v0_1", "Metric": "Accuracy", "Task": "Visual_Question_Answering", "score": "70.24%"}]}
{"doc_id": "3729a9a140aa13b3b26210d333fd19659fc21471", "arxiv_id": "1611.01587", "title": "A Joint Many-Task Model: Growing a Neural Network for Multiple NLP Tasks", "n_ary_relations": [{"Material": "Penn_Treebank", "Method": "JMT", "Metric": "F1_score", "Task": "Chunking", "score": "95.77"}]}
{"doc_id": "372bc106c61e7eb004835e85bbfee997409f176a", "arxiv_id": "1606.07536", "title": "Coupled Generative Adversarial Networks", "n_ary_relations": [{"Material": "Cityscapes_Labels-to-Photo", "Method": "CoGAN", "Metric": "Class_IOU", "Task": "Image-to-Image_Translation", "score": "0.06"}, {"Material": "Cityscapes_Labels-to-Photo", "Method": "CoGAN", "Metric": "Per-class_Accuracy", "Task": "Image-to-Image_Translation", "score": "10%"}, {"Material": "Cityscapes_Labels-to-Photo", "Method": "CoGAN", "Metric": "Per-pixel_Accuracy", "Task": "Image-to-Image_Translation", "score": "40%"}, {"Material": "Cityscapes_Photo-to-Labels", "Method": "CoGAN", "Metric": "Class_IOU", "Task": "Image-to-Image_Translation", "score": " 0.08"}, {"Material": "Cityscapes_Photo-to-Labels", "Method": "CoGAN", "Metric": "Per-class_Accuracy", "Task": "Image-to-Image_Translation", "score": "11%"}, {"Material": "Cityscapes_Photo-to-Labels", "Method": "CoGAN", "Metric": "Per-pixel_Accuracy", "Task": "Image-to-Image_Translation", "score": "45%"}]}
{"doc_id": "37a18be8c599b781cc28b6a62d8f11e8a6a75169", "arxiv_id": "1810.11654", "title": "3D MRI brain tumor segmentation using autoencoder regularization", "n_ary_relations": [{"Material": "BRATS_2018", "Method": "NVDLMED", "Metric": "Dice_Score", "Task": "Brain_Tumor_Segmentation", "score": "0.87049"}]}
{"doc_id": "37b685caf39b38b07af60eacf1a7d7ada2122372", "arxiv_id": "1612.00606", "title": "SyncSpecCNN: Synchronized Spectral CNN for 3D Shape Segmentation", "n_ary_relations": [{"Material": "ShapeNet-Part", "Method": "SSCNN", "Metric": "Class_Average_IoU", "Task": "3D_Part_Segmentation", "score": "82.0"}, {"Material": "ShapeNet-Part", "Method": "SSCNN", "Metric": "Instance_Average_IoU", "Task": "3D_Part_Segmentation", "score": "84.7"}]}
{"doc_id": "380b2c78d21ae6c43d418b6f0cb0222d5293d345", "arxiv_id": "1603.03793", "title": "Training with Exploration Improves a Greedy Stack LSTM Parser", "n_ary_relations": [{"Material": "Penn_Treebank", "Method": "Arc-hybrid", "Metric": "LAS", "Task": "Dependency_Parsing", "score": "91.42"}, {"Material": "Penn_Treebank", "Method": "Arc-hybrid", "Metric": "POS", "Task": "Dependency_Parsing", "score": "97.3"}, {"Material": "Penn_Treebank", "Method": "Arc-hybrid", "Metric": "UAS", "Task": "Dependency_Parsing", "score": "93.56"}]}
{"doc_id": "3861ae2a6bdd2a759c2d901a6583e63a216bc2fc", "arxiv_id": "1711.02132", "title": "Weighted Transformer Network for Machine Translation", "n_ary_relations": [{"Material": "WMT2014_English-French", "Method": "Weighted_Transformer__large_", "Metric": "BLEU_score", "Task": "Machine_Translation", "score": "41.4"}, {"Material": "WMT2014_English-German", "Method": "Weighted_Transformer__large_", "Metric": "BLEU_score", "Task": "Machine_Translation", "score": "28.9"}]}
{"doc_id": "38d7920f0e8a3a672ea37c8612b2b2947b9ba9d1", "arxiv_id": "1805.09300", "title": "SNIPER: Efficient Multi-Scale Training", "n_ary_relations": [{"Material": "COCO", "Method": "SNIPER", "Metric": "Bounding_Box_AP", "Task": "Object_Detection", "score": "46.1"}, {"Material": "PASCAL_VOC_2007", "Method": "SNIPER", "Metric": "MAP", "Task": "Object_Detection", "score": "86.9%"}]}
{"doc_id": "39978ba7c83333475d6825d0ff897692933895fc", "arxiv_id": "1502.03240", "title": "Conditional Random Fields as Recurrent Neural Networks", "n_ary_relations": [{"Material": "Cityscapes", "Method": "CRF-RNN", "Metric": "Frame__fps_", "Task": "Real-Time_Semantic_Segmentation", "score": "1.4"}, {"Material": "Cityscapes", "Method": "CRF-RNN", "Metric": "Mean_IoU", "Task": "Semantic_Segmentation", "score": "62.5%"}, {"Material": "Cityscapes", "Method": "CRF-RNN", "Metric": "Time__ms_", "Task": "Real-Time_Semantic_Segmentation", "score": "700"}, {"Material": "Cityscapes", "Method": "CRF-RNN", "Metric": "mIoU", "Task": "Real-Time_Semantic_Segmentation", "score": "62.5%"}, {"Material": "PASCAL_Context", "Method": "CRF-RNN", "Metric": "mIoU", "Task": "Semantic_Segmentation", "score": "39.3"}, {"Material": "PASCAL_VOC_2012", "Method": "CRF-RNN", "Metric": "Mean_IoU", "Task": "Semantic_Segmentation", "score": "74.7%"}]}
{"doc_id": "39dba6f22d72853561a4ed684be265e179a39e4f", "arxiv_id": "1409.3215", "title": "Sequence to Sequence Learning with Neural Networks", "n_ary_relations": [{"Material": "WMT2014_English-French", "Method": "LSTM", "Metric": "BLEU_score", "Task": "Machine_Translation", "score": 34.81}, {"Material": "WMT2014_English-French", "Method": "SMT_LSTM5", "Metric": "BLEU_score", "Task": "Machine_Translation", "score": 36.5}]}
{"doc_id": "3a28fe49e7a856ddd60d134696a891ed7bca5962", "arxiv_id": "", "title": "Small-Scale Pedestrian Detection Based on Topological Line Localization and Temporal Feature Aggregation", "n_ary_relations": [{"Material": "CityPersons", "Method": "TLL", "Metric": "Bare_MR_-2", "Task": "Pedestrian_Detection", "score": "10.0"}, {"Material": "CityPersons", "Method": "TLL_MRF", "Metric": "Bare_MR_-2", "Task": "Pedestrian_Detection", "score": "9.2"}, {"Material": "CityPersons", "Method": "TLL", "Metric": "Heavy_MR_-2", "Task": "Pedestrian_Detection", "score": "53.6"}, {"Material": "CityPersons", "Method": "TLL_MRF", "Metric": "Heavy_MR_-2", "Task": "Pedestrian_Detection", "score": "52.0"}, {"Material": "CityPersons", "Method": "TLL", "Metric": "Partial_MR_-2", "Task": "Pedestrian_Detection", "score": "17.2"}, {"Material": "CityPersons", "Method": "TLL_MRF", "Metric": "Partial_MR_-2", "Task": "Pedestrian_Detection", "score": "15.9"}, {"Material": "CityPersons", "Method": "TLL", "Metric": "Reasonable_MR_-2", "Task": "Pedestrian_Detection", "score": "15.5"}, {"Material": "CityPersons", "Method": "TLL_MRF", "Metric": "Reasonable_MR_-2", "Task": "Pedestrian_Detection", "score": "14.4"}]}
{"doc_id": "3a61d5fbc8d99310965fd91b12527d1cd69d7116", "arxiv_id": "1904.08900", "title": "CornerNet-Lite: Efficient Keypoint based Object Detection", "n_ary_relations": [{"Material": "COCO", "Method": "CornerNet-Saccade", "Metric": "Bounding_Box_AP", "Task": "Object_Detection", "score": "43.2"}, {"Material": "COCO", "Method": "CornerNet-Squeeze", "Metric": "Bounding_Box_AP", "Task": "Object_Detection", "score": "34.4"}, {"Material": "COCO", "Method": "CornerNet-Squeeze", "Metric": "FPS", "Task": "Real-Time_Object_Detection", "score": "30"}, {"Material": "COCO", "Method": "CornerNet-Squeeze", "Metric": "MAP", "Task": "Real-Time_Object_Detection", "score": "34.4%"}]}
{"doc_id": "3a7895b17db0cda7bbf86bcda52c46a3e03b6ded", "arxiv_id": "1811.00405", "title": "DialogueRNN: An Attentive RNN for Emotion Detection in Conversations", "n_ary_relations": [{"Material": "IEMOCAP", "Method": "DialogueRNN", "Metric": "F1", "Task": "Emotion_Recognition_in_Conversation", "score": "64.5%"}]}
{"doc_id": "3a8d537bcec370d37990d39eab01c729496ad057", "arxiv_id": "", "title": "Learning a Hierarchical Latent-Variable Model of 3D Shapes", "n_ary_relations": [{"Material": "ModelNet40", "Method": "Variational_Shape_Learner", "Metric": "Accuracy", "Task": "3D_Object_Recognition", "score": "84.5%"}]}
{"doc_id": "3b1b94441010615195a5c404409ce2416860508c", "arxiv_id": "1603.02814", "title": "Image Captioning and Visual Question Answering Based on Attributes and External Knowledge", "n_ary_relations": [{"Material": "COCO_Visual_Question_Answering__VQA__real_images_1_0_open_ended", "Method": "CNN-RNN", "Metric": "Percentage_correct", "Task": "Visual_Question_Answering", "score": 59.5}]}
{"doc_id": "3b1d8eb163ffff598c2faa0d9d7cf933857a359f", "arxiv_id": "1711.04289", "title": "Neural Natural Language Inference Models Enhanced with External Knowledge", "n_ary_relations": [{"Material": "SNLI", "Method": "KIM", "Metric": "__Test_Accuracy", "Task": "Natural_Language_Inference", "score": "88.6"}, {"Material": "SNLI", "Method": "KIM_Ensemble", "Metric": "__Test_Accuracy", "Task": "Natural_Language_Inference", "score": "89.1"}, {"Material": "SNLI", "Method": "KIM", "Metric": "__Train_Accuracy", "Task": "Natural_Language_Inference", "score": "94.1"}, {"Material": "SNLI", "Method": "KIM_Ensemble", "Metric": "__Train_Accuracy", "Task": "Natural_Language_Inference", "score": "93.6"}, {"Material": "SNLI", "Method": "KIM", "Metric": "Parameters", "Task": "Natural_Language_Inference", "score": "4.3m"}, {"Material": "SNLI", "Method": "KIM_Ensemble", "Metric": "Parameters", "Task": "Natural_Language_Inference", "score": "43m"}]}
{"doc_id": "3b9732bb07dc99bde5e1f9f75251c6ea5039373e", "arxiv_id": "1509.06461", "title": "Deep Reinforcement Learning with Double Q-Learning", "n_ary_relations": [{"Material": "Atari_2600_Alien", "Method": "DDQN__tuned__hs", "Metric": "Score", "Task": "Atari_Games", "score": 1033.4}, {"Material": "Atari_2600_Alien", "Method": "DQN_hs", "Metric": "Score", "Task": "Atari_Games", "score": 634.0}, {"Material": "Atari_2600_Alien", "Method": "DQN_noop", "Metric": "Score", "Task": "Atari_Games", "score": 1620.0}, {"Material": "Atari_2600_Alien", "Method": "Prior_Duel_hs", "Metric": "Score", "Task": "Atari_Games", "score": 823.7}, {"Material": "Atari_2600_Amidar", "Method": "DDQN__tuned__hs", "Metric": "Score", "Task": "Atari_Games", "score": 169.1}, {"Material": "Atari_2600_Amidar", "Method": "DQN_hs", "Metric": "Score", "Task": "Atari_Games", "score": 178.4}, {"Material": "Atari_2600_Amidar", "Method": "DQN_noop", "Metric": "Score", "Task": "Atari_Games", "score": 978.0}, {"Material": "Atari_2600_Amidar", "Method": "Prior_Duel_hs", "Metric": "Score", "Task": "Atari_Games", "score": 238.4}, {"Material": "Atari_2600_Assault", "Method": "DDQN__tuned__hs", "Metric": "Score", "Task": "Atari_Games", "score": 6060.8}, {"Material": "Atari_2600_Assault", "Method": "DQN_hs", "Metric": "Score", "Task": "Atari_Games", "score": 3489.3}, {"Material": "Atari_2600_Assault", "Method": "DQN_noop", "Metric": "Score", "Task": "Atari_Games", "score": 4280.4}, {"Material": "Atari_2600_Assault", "Method": "Prior_Duel_hs", "Metric": "Score", "Task": "Atari_Games", "score": 10950.6}, {"Material": "Atari_2600_Asterix", "Method": "DDQN__tuned__hs", "Metric": "Score", "Task": "Atari_Games", "score": 16837.0}, {"Material": "Atari_2600_Asterix", "Method": "DQN_hs", "Metric": "Score", "Task": "Atari_Games", "score": 3170.5}, {"Material": "Atari_2600_Asterix", "Method": "DQN_noop", "Metric": "Score", "Task": "Atari_Games", "score": 4359.0}, {"Material": "Atari_2600_Asterix", "Method": "Prior_Duel_hs", "Metric": "Score", "Task": "Atari_Games", "score": 364200.0}, {"Material": "Atari_2600_Asteroids", "Method": "DDQN__tuned__hs", "Metric": "Score", "Task": "Atari_Games", "score": 1193.2}, {"Material": "Atari_2600_Asteroids", "Method": "DQN_hs", "Metric": "Score", "Task": "Atari_Games", "score": 1458.7}, {"Material": "Atari_2600_Asteroids", "Method": "DQN_noop", "Metric": "Score", "Task": "Atari_Games", "score": 1364.5}, {"Material": "Atari_2600_Asteroids", "Method": "Prior_Duel_hs", "Metric": "Score", "Task": "Atari_Games", "score": 1021.9}, {"Material": "Atari_2600_Atlantis", "Method": "DDQN__tuned__hs", "Metric": "Score", "Task": "Atari_Games", "score": 319688.0}, {"Material": "Atari_2600_Atlantis", "Method": "DQN_hs", "Metric": "Score", "Task": "Atari_Games", "score": 292491.0}, {"Material": "Atari_2600_Atlantis", "Method": "DQN_noop", "Metric": "Score", "Task": "Atari_Games", "score": 279987.0}, {"Material": "Atari_2600_Atlantis", "Method": "Prior_Duel_hs", "Metric": "Score", "Task": "Atari_Games", "score": 423252.0}, {"Material": "Atari_2600_Bank_Heist", "Method": "DDQN__tuned__hs", "Metric": "Score", "Task": "Atari_Games", "score": 886.0}, {"Material": "Atari_2600_Bank_Heist", "Method": "DQN_hs", "Metric": "Score", "Task": "Atari_Games", "score": 312.7}, {"Material": "Atari_2600_Bank_Heist", "Method": "DQN_noop", "Metric": "Score", "Task": "Atari_Games", "score": 455.0}, {"Material": "Atari_2600_Bank_Heist", "Method": "Prior_Duel_hs", "Metric": "Score", "Task": "Atari_Games", "score": 1004.6}, {"Material": "Atari_2600_Battle_Zone", "Method": "DDQN__tuned__hs", "Metric": "Score", "Task": "Atari_Games", "score": 24740.0}, {"Material": "Atari_2600_Battle_Zone", "Method": "DQN_hs", "Metric": "Score", "Task": "Atari_Games", "score": 23750.0}, {"Material": "Atari_2600_Battle_Zone", "Method": "DQN_noop", "Metric": "Score", "Task": "Atari_Games", "score": 29900.0}, {"Material": "Atari_2600_Battle_Zone", "Method": "Prior_Duel_hs", "Metric": "Score", "Task": "Atari_Games", "score": 30650.0}, {"Material": "Atari_2600_Beam_Rider", "Method": "DDQN__tuned__hs", "Metric": "Score", "Task": "Atari_Games", "score": 17417.2}, {"Material": "Atari_2600_Beam_Rider", "Method": "DQN_hs", "Metric": "Score", "Task": "Atari_Games", "score": 9743.2}, {"Material": "Atari_2600_Beam_Rider", "Method": "DQN_noop", "Metric": "Score", "Task": "Atari_Games", "score": 8627.5}, {"Material": "Atari_2600_Beam_Rider", "Method": "Prior_Duel_hs", "Metric": "Score", "Task": "Atari_Games", "score": 37412.2}, {"Material": "Atari_2600_Berzerk", "Method": "DDQN__tuned__hs", "Metric": "Score", "Task": "Atari_Games", "score": 1011.1}, {"Material": "Atari_2600_Berzerk", "Method": "DQN_hs", "Metric": "Score", "Task": "Atari_Games", "score": 493.4}, {"Material": "Atari_2600_Berzerk", "Method": "DQN_noop", "Metric": "Score", "Task": "Atari_Games", "score": 585.6}, {"Material": "Atari_2600_Berzerk", "Method": "Prior_Duel_hs", "Metric": "Score", "Task": "Atari_Games", "score": 2178.6}, {"Material": "Atari_2600_Bowling", "Method": "DDQN__tuned__hs", "Metric": "Score", "Task": "Atari_Games", "score": 69.6}, {"Material": "Atari_2600_Bowling", "Method": "DQN_hs", "Metric": "Score", "Task": "Atari_Games", "score": 56.5}, {"Material": "Atari_2600_Bowling", "Method": "DQN_noop", "Metric": "Score", "Task": "Atari_Games", "score": 50.4}, {"Material": "Atari_2600_Bowling", "Method": "Prior_Duel_hs", "Metric": "Score", "Task": "Atari_Games", "score": 50.4}, {"Material": "Atari_2600_Boxing", "Method": "DDQN__tuned__hs", "Metric": "Score", "Task": "Atari_Games", "score": 73.5}, {"Material": "Atari_2600_Boxing", "Method": "DQN_hs", "Metric": "Score", "Task": "Atari_Games", "score": 70.3}, {"Material": "Atari_2600_Boxing", "Method": "DQN_noop", "Metric": "Score", "Task": "Atari_Games", "score": 88.0}, {"Material": "Atari_2600_Boxing", "Method": "Prior_Duel_hs", "Metric": "Score", "Task": "Atari_Games", "score": 79.2}, {"Material": "Atari_2600_Breakout", "Method": "DDQN__tuned__hs", "Metric": "Score", "Task": "Atari_Games", "score": 368.9}, {"Material": "Atari_2600_Breakout", "Method": "DQN_hs", "Metric": "Score", "Task": "Atari_Games", "score": 354.5}, {"Material": "Atari_2600_Breakout", "Method": "DQN_noop", "Metric": "Score", "Task": "Atari_Games", "score": 385.5}, {"Material": "Atari_2600_Breakout", "Method": "Prior_Duel_hs", "Metric": "Score", "Task": "Atari_Games", "score": 354.6}, {"Material": "Atari_2600_Centipede", "Method": "DDQN__tuned__hs", "Metric": "Score", "Task": "Atari_Games", "score": 3853.5}, {"Material": "Atari_2600_Centipede", "Method": "DQN_hs", "Metric": "Score", "Task": "Atari_Games", "score": 3973.9}, {"Material": "Atari_2600_Centipede", "Method": "DQN_noop", "Metric": "Score", "Task": "Atari_Games", "score": 4657.7}, {"Material": "Atari_2600_Centipede", "Method": "Prior_Duel_hs", "Metric": "Score", "Task": "Atari_Games", "score": 5570.2}, {"Material": "Atari_2600_Chopper_Command", "Method": "DDQN__tuned__hs", "Metric": "Score", "Task": "Atari_Games", "score": 3495.0}, {"Material": "Atari_2600_Chopper_Command", "Method": "DQN_hs", "Metric": "Score", "Task": "Atari_Games", "score": 5017.0}, {"Material": "Atari_2600_Chopper_Command", "Method": "DQN_noop", "Metric": "Score", "Task": "Atari_Games", "score": 6126.0}, {"Material": "Atari_2600_Chopper_Command", "Method": "Prior_Duel_hs", "Metric": "Score", "Task": "Atari_Games", "score": 8058.0}, {"Material": "Atari_2600_Crazy_Climber", "Method": "DDQN__tuned__hs", "Metric": "Score", "Task": "Atari_Games", "score": 113782.0}, {"Material": "Atari_2600_Crazy_Climber", "Method": "DQN_hs", "Metric": "Score", "Task": "Atari_Games", "score": 98128.0}, {"Material": "Atari_2600_Crazy_Climber", "Method": "DQN_noop", "Metric": "Score", "Task": "Atari_Games", "score": 110763.0}, {"Material": "Atari_2600_Crazy_Climber", "Method": "Prior_Duel_hs", "Metric": "Score", "Task": "Atari_Games", "score": 127853.0}, {"Material": "Atari_2600_Demon_Attack", "Method": "DDQN__tuned__hs", "Metric": "Score", "Task": "Atari_Games", "score": 69803.4}, {"Material": "Atari_2600_Demon_Attack", "Method": "DQN_hs", "Metric": "Score", "Task": "Atari_Games", "score": 12550.7}, {"Material": "Atari_2600_Demon_Attack", "Method": "DQN_noop", "Metric": "Score", "Task": "Atari_Games", "score": 12149.4}, {"Material": "Atari_2600_Demon_Attack", "Method": "Prior_Duel_hs", "Metric": "Score", "Task": "Atari_Games", "score": 73371.3}, {"Material": "Atari_2600_Double_Dunk", "Method": "DDQN__tuned__hs", "Metric": "Score", "Task": "Atari_Games", "score": -0.30000000000000004}, {"Material": "Atari_2600_Double_Dunk", "Method": "DQN_hs", "Metric": "Score", "Task": "Atari_Games", "score": -6.0}, {"Material": "Atari_2600_Double_Dunk", "Method": "DQN_noop", "Metric": "Score", "Task": "Atari_Games", "score": -6.6}, {"Material": "Atari_2600_Double_Dunk", "Method": "Prior_Duel_hs", "Metric": "Score", "Task": "Atari_Games", "score": -10.7}, {"Material": "Atari_2600_Enduro", "Method": "DDQN__tuned__hs", "Metric": "Score", "Task": "Atari_Games", "score": 1216.6}, {"Material": "Atari_2600_Enduro", "Method": "DQN_hs", "Metric": "Score", "Task": "Atari_Games", "score": 626.7}, {"Material": "Atari_2600_Enduro", "Method": "DQN_noop", "Metric": "Score", "Task": "Atari_Games", "score": 729.0}, {"Material": "Atari_2600_Enduro", "Method": "Prior_Duel_hs", "Metric": "Score", "Task": "Atari_Games", "score": 2223.9}, {"Material": "Atari_2600_Fishing_Derby", "Method": "DDQN__tuned__hs", "Metric": "Score", "Task": "Atari_Games", "score": 3.2}, {"Material": "Atari_2600_Fishing_Derby", "Method": "DQN_hs", "Metric": "Score", "Task": "Atari_Games", "score": -1.6}, {"Material": "Atari_2600_Fishing_Derby", "Method": "DQN_noop", "Metric": "Score", "Task": "Atari_Games", "score": -4.9}, {"Material": "Atari_2600_Fishing_Derby", "Method": "Prior_Duel_hs", "Metric": "Score", "Task": "Atari_Games", "score": 17.0}, {"Material": "Atari_2600_Freeway", "Method": "DDQN__tuned__hs", "Metric": "Score", "Task": "Atari_Games", "score": 28.8}, {"Material": "Atari_2600_Freeway", "Method": "DQN_hs", "Metric": "Score", "Task": "Atari_Games", "score": 26.9}, {"Material": "Atari_2600_Freeway", "Method": "DQN_noop", "Metric": "Score", "Task": "Atari_Games", "score": 30.8}, {"Material": "Atari_2600_Freeway", "Method": "Prior_Duel_hs", "Metric": "Score", "Task": "Atari_Games", "score": 28.2}, {"Material": "Atari_2600_Frostbite", "Method": "DDQN__tuned__hs", "Metric": "Score", "Task": "Atari_Games", "score": 1448.1}, {"Material": "Atari_2600_Frostbite", "Method": "DQN_hs", "Metric": "Score", "Task": "Atari_Games", "score": 496.1}, {"Material": "Atari_2600_Frostbite", "Method": "DQN_noop", "Metric": "Score", "Task": "Atari_Games", "score": 797.4}, {"Material": "Atari_2600_Frostbite", "Method": "Prior_Duel_hs", "Metric": "Score", "Task": "Atari_Games", "score": 4038.4}, {"Material": "Atari_2600_Gopher", "Method": "DDQN__tuned__hs", "Metric": "Score", "Task": "Atari_Games", "score": 15253.0}, {"Material": "Atari_2600_Gopher", "Method": "DQN_hs", "Metric": "Score", "Task": "Atari_Games", "score": 8190.4}, {"Material": "Atari_2600_Gopher", "Method": "DQN_noop", "Metric": "Score", "Task": "Atari_Games", "score": 8777.4}, {"Material": "Atari_2600_Gopher", "Method": "Prior_Duel_hs", "Metric": "Score", "Task": "Atari_Games", "score": 105148.4}, {"Material": "Atari_2600_Gravitar", "Method": "DDQN__tuned__hs", "Metric": "Score", "Task": "Atari_Games", "score": 200.5}, {"Material": "Atari_2600_Gravitar", "Method": "DQN_hs", "Metric": "Score", "Task": "Atari_Games", "score": 298.0}, {"Material": "Atari_2600_Gravitar", "Method": "DQN_noop", "Metric": "Score", "Task": "Atari_Games", "score": 473.0}, {"Material": "Atari_2600_Gravitar", "Method": "Prior_Duel_hs", "Metric": "Score", "Task": "Atari_Games", "score": 167.0}, {"Material": "Atari_2600_HERO", "Method": "DDQN__tuned__hs", "Metric": "Score", "Task": "Atari_Games", "score": 14892.5}, {"Material": "Atari_2600_HERO", "Method": "DQN_hs", "Metric": "Score", "Task": "Atari_Games", "score": 14992.9}, {"Material": "Atari_2600_HERO", "Method": "DQN_noop", "Metric": "Score", "Task": "Atari_Games", "score": 20437.8}, {"Material": "Atari_2600_HERO", "Method": "Prior_Duel_hs", "Metric": "Score", "Task": "Atari_Games", "score": 15459.2}, {"Material": "Atari_2600_Ice_Hockey", "Method": "DDQN__tuned__hs", "Metric": "Score", "Task": "Atari_Games", "score": -2.5}, {"Material": "Atari_2600_Ice_Hockey", "Method": "DQN_hs", "Metric": "Score", "Task": "Atari_Games", "score": -1.6}, {"Material": "Atari_2600_Ice_Hockey", "Method": "DQN_noop", "Metric": "Score", "Task": "Atari_Games", "score": -1.9}, {"Material": "Atari_2600_Ice_Hockey", "Method": "Prior_Duel_hs", "Metric": "Score", "Task": "Atari_Games", "score": 0.5}, {"Material": "Atari_2600_James_Bond", "Method": "DDQN__tuned__hs", "Metric": "Score", "Task": "Atari_Games", "score": 573.0}, {"Material": "Atari_2600_James_Bond", "Method": "DQN_hs", "Metric": "Score", "Task": "Atari_Games", "score": 697.5}, {"Material": "Atari_2600_James_Bond", "Method": "DQN_noop", "Metric": "Score", "Task": "Atari_Games", "score": 768.5}, {"Material": "Atari_2600_James_Bond", "Method": "Prior_Duel_hs", "Metric": "Score", "Task": "Atari_Games", "score": 585.0}, {"Material": "Atari_2600_Kangaroo", "Method": "DDQN__tuned__hs", "Metric": "Score", "Task": "Atari_Games", "score": 11204.0}, {"Material": "Atari_2600_Kangaroo", "Method": "DQN_hs", "Metric": "Score", "Task": "Atari_Games", "score": 4496.0}, {"Material": "Atari_2600_Kangaroo", "Method": "DQN_noop", "Metric": "Score", "Task": "Atari_Games", "score": 7259.0}, {"Material": "Atari_2600_Kangaroo", "Method": "Prior_Duel_hs", "Metric": "Score", "Task": "Atari_Games", "score": 861.0}, {"Material": "Atari_2600_Krull", "Method": "DDQN__tuned__hs", "Metric": "Score", "Task": "Atari_Games", "score": 6796.1}, {"Material": "Atari_2600_Krull", "Method": "DQN_hs", "Metric": "Score", "Task": "Atari_Games", "score": 6206.0}, {"Material": "Atari_2600_Krull", "Method": "DQN_noop", "Metric": "Score", "Task": "Atari_Games", "score": 8422.3}, {"Material": "Atari_2600_Krull", "Method": "Prior_Duel_hs", "Metric": "Score", "Task": "Atari_Games", "score": 7658.6}, {"Material": "Atari_2600_Kung-Fu_Master", "Method": "DDQN__tuned__hs", "Metric": "Score", "Task": "Atari_Games", "score": 30207.0}, {"Material": "Atari_2600_Kung-Fu_Master", "Method": "DQN_hs", "Metric": "Score", "Task": "Atari_Games", "score": 20882.0}, {"Material": "Atari_2600_Kung-Fu_Master", "Method": "DQN_noop", "Metric": "Score", "Task": "Atari_Games", "score": 26059.0}, {"Material": "Atari_2600_Kung-Fu_Master", "Method": "Prior_Duel_hs", "Metric": "Score", "Task": "Atari_Games", "score": 37484.0}, {"Material": "Atari_2600_Montezuma_s_Revenge", "Method": "DDQN__tuned__hs", "Metric": "Score", "Task": "Atari_Games", "score": 42.0}, {"Material": "Atari_2600_Montezuma_s_Revenge", "Method": "DQN_hs", "Metric": "Score", "Task": "Atari_Games", "score": 47.0}, {"Material": "Atari_2600_Montezuma_s_Revenge", "Method": "DQN_noop", "Metric": "Score", "Task": "Atari_Games", "score": 0.0}, {"Material": "Atari_2600_Montezuma_s_Revenge", "Method": "Prior_Duel_hs", "Metric": "Score", "Task": "Atari_Games", "score": 24.0}, {"Material": "Atari_2600_Ms__Pacman", "Method": "DDQN__tuned__hs", "Metric": "Score", "Task": "Atari_Games", "score": 1241.3}, {"Material": "Atari_2600_Ms__Pacman", "Method": "DQN_hs", "Metric": "Score", "Task": "Atari_Games", "score": 1092.3}, {"Material": "Atari_2600_Ms__Pacman", "Method": "DQN_noop", "Metric": "Score", "Task": "Atari_Games", "score": 3085.6}, {"Material": "Atari_2600_Ms__Pacman", "Method": "Prior_Duel_hs", "Metric": "Score", "Task": "Atari_Games", "score": 1007.8}, {"Material": "Atari_2600_Name_This_Game", "Method": "DDQN__tuned__hs", "Metric": "Score", "Task": "Atari_Games", "score": 8960.3}, {"Material": "Atari_2600_Name_This_Game", "Method": "DQN_hs", "Metric": "Score", "Task": "Atari_Games", "score": 6738.8}, {"Material": "Atari_2600_Name_This_Game", "Method": "DQN_noop", "Metric": "Score", "Task": "Atari_Games", "score": 8207.8}, {"Material": "Atari_2600_Name_This_Game", "Method": "Prior_Duel_hs", "Metric": "Score", "Task": "Atari_Games", "score": 13637.9}, {"Material": "Atari_2600_Pong", "Method": "DDQN__tuned__hs", "Metric": "Score", "Task": "Atari_Games", "score": 19.1}, {"Material": "Atari_2600_Pong", "Method": "DQN_hs", "Metric": "Score", "Task": "Atari_Games", "score": 18.0}, {"Material": "Atari_2600_Pong", "Method": "DQN_noop", "Metric": "Score", "Task": "Atari_Games", "score": 19.5}, {"Material": "Atari_2600_Pong", "Method": "Prior_Duel_hs", "Metric": "Score", "Task": "Atari_Games", "score": 18.4}, {"Material": "Atari_2600_Private_Eye", "Method": "DDQN__tuned__hs", "Metric": "Score", "Task": "Atari_Games", "score": -575.5}, {"Material": "Atari_2600_Private_Eye", "Method": "DQN_hs", "Metric": "Score", "Task": "Atari_Games", "score": 207.9}, {"Material": "Atari_2600_Private_Eye", "Method": "DQN_noop", "Metric": "Score", "Task": "Atari_Games", "score": 146.7}, {"Material": "Atari_2600_Private_Eye", "Method": "Prior_Duel_hs", "Metric": "Score", "Task": "Atari_Games", "score": 1277.6}, {"Material": "Atari_2600_Q_Bert", "Method": "DDQN__tuned__hs", "Metric": "Score", "Task": "Atari_Games", "score": 11020.8}, {"Material": "Atari_2600_Q_Bert", "Method": "DQN_hs", "Metric": "Score", "Task": "Atari_Games", "score": 9271.5}, {"Material": "Atari_2600_Q_Bert", "Method": "DQN_noop", "Metric": "Score", "Task": "Atari_Games", "score": 13117.3}, {"Material": "Atari_2600_Q_Bert", "Method": "Prior_Duel_hs", "Metric": "Score", "Task": "Atari_Games", "score": 14063.0}, {"Material": "Atari_2600_River_Raid", "Method": "DDQN__tuned__hs", "Metric": "Score", "Task": "Atari_Games", "score": 10838.4}, {"Material": "Atari_2600_River_Raid", "Method": "DQN_hs", "Metric": "Score", "Task": "Atari_Games", "score": 4748.5}, {"Material": "Atari_2600_River_Raid", "Method": "DQN_noop", "Metric": "Score", "Task": "Atari_Games", "score": 7377.6}, {"Material": "Atari_2600_River_Raid", "Method": "Prior_Duel_hs", "Metric": "Score", "Task": "Atari_Games", "score": 16496.8}, {"Material": "Atari_2600_Road_Runner", "Method": "DDQN__tuned__hs", "Metric": "Score", "Task": "Atari_Games", "score": 43156.0}, {"Material": "Atari_2600_Road_Runner", "Method": "DQN_hs", "Metric": "Score", "Task": "Atari_Games", "score": 35215.0}, {"Material": "Atari_2600_Road_Runner", "Method": "DQN_noop", "Metric": "Score", "Task": "Atari_Games", "score": 39544.0}, {"Material": "Atari_2600_Road_Runner", "Method": "Prior_Duel_hs", "Metric": "Score", "Task": "Atari_Games", "score": 54630.0}, {"Material": "Atari_2600_Robotank", "Method": "DDQN__tuned__hs", "Metric": "Score", "Task": "Atari_Games", "score": 59.1}, {"Material": "Atari_2600_Robotank", "Method": "DQN_hs", "Metric": "Score", "Task": "Atari_Games", "score": 58.7}, {"Material": "Atari_2600_Robotank", "Method": "DQN_noop", "Metric": "Score", "Task": "Atari_Games", "score": 63.9}, {"Material": "Atari_2600_Robotank", "Method": "Prior_Duel_hs", "Metric": "Score", "Task": "Atari_Games", "score": 24.7}, {"Material": "Atari_2600_Seaquest", "Method": "DDQN__tuned__hs", "Metric": "Score", "Task": "Atari_Games", "score": 14498.0}, {"Material": "Atari_2600_Seaquest", "Method": "DQN_hs", "Metric": "Score", "Task": "Atari_Games", "score": 4216.7}, {"Material": "Atari_2600_Seaquest", "Method": "DQN_noop", "Metric": "Score", "Task": "Atari_Games", "score": 5860.6}, {"Material": "Atari_2600_Seaquest", "Method": "Prior_Duel_hs", "Metric": "Score", "Task": "Atari_Games", "score": 1431.2}, {"Material": "Atari_2600_Space_Invaders", "Method": "DDQN__tuned__hs", "Metric": "Score", "Task": "Atari_Games", "score": 2628.7}, {"Material": "Atari_2600_Space_Invaders", "Method": "DQN_hs", "Metric": "Score", "Task": "Atari_Games", "score": 1293.8}, {"Material": "Atari_2600_Space_Invaders", "Method": "DQN_noop", "Metric": "Score", "Task": "Atari_Games", "score": 1692.3}, {"Material": "Atari_2600_Space_Invaders", "Method": "Prior_Duel_hs", "Metric": "Score", "Task": "Atari_Games", "score": 8978.0}, {"Material": "Atari_2600_Star_Gunner", "Method": "DDQN__tuned__hs", "Metric": "Score", "Task": "Atari_Games", "score": 58365.0}, {"Material": "Atari_2600_Star_Gunner", "Method": "DQN_hs", "Metric": "Score", "Task": "Atari_Games", "score": 52970.0}, {"Material": "Atari_2600_Star_Gunner", "Method": "DQN_noop", "Metric": "Score", "Task": "Atari_Games", "score": 54282.0}, {"Material": "Atari_2600_Star_Gunner", "Method": "Prior_Duel_hs", "Metric": "Score", "Task": "Atari_Games", "score": 127073.0}, {"Material": "Atari_2600_Tennis", "Method": "DDQN__tuned__hs", "Metric": "Score", "Task": "Atari_Games", "score": -7.8}, {"Material": "Atari_2600_Tennis", "Method": "DQN_hs", "Metric": "Score", "Task": "Atari_Games", "score": 11.1}, {"Material": "Atari_2600_Tennis", "Method": "DQN_noop", "Metric": "Score", "Task": "Atari_Games", "score": 12.2}, {"Material": "Atari_2600_Tennis", "Method": "Prior_Duel_hs", "Metric": "Score", "Task": "Atari_Games", "score": -13.2}, {"Material": "Atari_2600_Time_Pilot", "Method": "DDQN__tuned__hs", "Metric": "Score", "Task": "Atari_Games", "score": 6608.0}, {"Material": "Atari_2600_Time_Pilot", "Method": "DQN_hs", "Metric": "Score", "Task": "Atari_Games", "score": 4786.0}, {"Material": "Atari_2600_Time_Pilot", "Method": "DQN_noop", "Metric": "Score", "Task": "Atari_Games", "score": 4870.0}, {"Material": "Atari_2600_Time_Pilot", "Method": "Prior_Duel_hs", "Metric": "Score", "Task": "Atari_Games", "score": 4871.0}, {"Material": "Atari_2600_Tutankham", "Method": "DDQN__tuned__hs", "Metric": "Score", "Task": "Atari_Games", "score": 92.2}, {"Material": "Atari_2600_Tutankham", "Method": "DQN_hs", "Metric": "Score", "Task": "Atari_Games", "score": 45.6}, {"Material": "Atari_2600_Tutankham", "Method": "DQN_noop", "Metric": "Score", "Task": "Atari_Games", "score": 68.1}, {"Material": "Atari_2600_Tutankham", "Method": "Prior_Duel_hs", "Metric": "Score", "Task": "Atari_Games", "score": 108.6}, {"Material": "Atari_2600_Up_and_Down", "Method": "DDQN__tuned__hs", "Metric": "Score", "Task": "Atari_Games", "score": 19086.9}, {"Material": "Atari_2600_Up_and_Down", "Method": "DQN_hs", "Metric": "Score", "Task": "Atari_Games", "score": 8038.5}, {"Material": "Atari_2600_Up_and_Down", "Method": "DQN_noop", "Metric": "Score", "Task": "Atari_Games", "score": 9989.9}, {"Material": "Atari_2600_Up_and_Down", "Method": "Prior_Duel_hs", "Metric": "Score", "Task": "Atari_Games", "score": 22681.3}, {"Material": "Atari_2600_Venture", "Method": "DDQN__tuned__hs", "Metric": "Score", "Task": "Atari_Games", "score": 21.0}, {"Material": "Atari_2600_Venture", "Method": "DQN_hs", "Metric": "Score", "Task": "Atari_Games", "score": 136.0}, {"Material": "Atari_2600_Venture", "Method": "DQN_noop", "Metric": "Score", "Task": "Atari_Games", "score": 163.0}, {"Material": "Atari_2600_Venture", "Method": "Prior_Duel_hs", "Metric": "Score", "Task": "Atari_Games", "score": 29.0}, {"Material": "Atari_2600_Video_Pinball", "Method": "DDQN__tuned__hs", "Metric": "Score", "Task": "Atari_Games", "score": 367823.7}, {"Material": "Atari_2600_Video_Pinball", "Method": "DQN_hs", "Metric": "Score", "Task": "Atari_Games", "score": 154414.1}, {"Material": "Atari_2600_Video_Pinball", "Method": "DQN_noop", "Metric": "Score", "Task": "Atari_Games", "score": 196760.4}, {"Material": "Atari_2600_Video_Pinball", "Method": "Prior_Duel_hs", "Metric": "Score", "Task": "Atari_Games", "score": 447408.6}, {"Material": "Atari_2600_Wizard_of_Wor", "Method": "DDQN__tuned__hs", "Metric": "Score", "Task": "Atari_Games", "score": 6201.0}, {"Material": "Atari_2600_Wizard_of_Wor", "Method": "DQN_hs", "Metric": "Score", "Task": "Atari_Games", "score": 1609.0}, {"Material": "Atari_2600_Wizard_of_Wor", "Method": "DQN_noop", "Metric": "Score", "Task": "Atari_Games", "score": 2704.0}, {"Material": "Atari_2600_Wizard_of_Wor", "Method": "Prior_Duel_hs", "Metric": "Score", "Task": "Atari_Games", "score": 10471.0}, {"Material": "Atari_2600_Zaxxon", "Method": "DDQN__tuned__hs", "Metric": "Score", "Task": "Atari_Games", "score": 8593.0}, {"Material": "Atari_2600_Zaxxon", "Method": "DQN_hs", "Metric": "Score", "Task": "Atari_Games", "score": 4412.0}, {"Material": "Atari_2600_Zaxxon", "Method": "DQN_noop", "Metric": "Score", "Task": "Atari_Games", "score": 5363.0}, {"Material": "Atari_2600_Zaxxon", "Method": "Prior_Duel_hs", "Metric": "Score", "Task": "Atari_Games", "score": 11320.0}]}
{"doc_id": "3c1d781f2dab8da12e3cb0e4d7abfb440a340a09", "arxiv_id": "1802.05577", "title": "DR-BiLSTM: Dependent Reading Bidirectional LSTM for Natural Language Inference", "n_ary_relations": [{"Material": "SNLI", "Method": "450D_DR-BiLSTM", "Metric": "__Test_Accuracy", "Task": "Natural_Language_Inference", "score": "88.5"}, {"Material": "SNLI", "Method": "450D_DR-BiLSTM_Ensemble", "Metric": "__Test_Accuracy", "Task": "Natural_Language_Inference", "score": "89.3"}, {"Material": "SNLI", "Method": "450D_DR-BiLSTM", "Metric": "__Train_Accuracy", "Task": "Natural_Language_Inference", "score": "94.1"}, {"Material": "SNLI", "Method": "450D_DR-BiLSTM_Ensemble", "Metric": "__Train_Accuracy", "Task": "Natural_Language_Inference", "score": "94.8"}, {"Material": "SNLI", "Method": "450D_DR-BiLSTM", "Metric": "Parameters", "Task": "Natural_Language_Inference", "score": "7.5m"}, {"Material": "SNLI", "Method": "450D_DR-BiLSTM_Ensemble", "Metric": "Parameters", "Task": "Natural_Language_Inference", "score": "45m"}]}
{"doc_id": "3c78c6df5eb1695b6a399e346dde880af27d1016", "arxiv_id": "1710.10723", "title": "Simple and Effective Multi-Paragraph Reading Comprehension", "n_ary_relations": [{"Material": "SQuAD1_1", "Method": "BiDAF___Self_Attention__single_model_", "Metric": "EM", "Task": "Question_Answering", "score": "72.139"}, {"Material": "SQuAD1_1", "Method": "BiDAF___Self_Attention__single_model_", "Metric": "F1", "Task": "Question_Answering", "score": "81.048"}, {"Material": "TriviaQA", "Method": "S-Norm", "Metric": "EM", "Task": "Question_Answering", "score": "66.37"}, {"Material": "TriviaQA", "Method": "S-Norm", "Metric": "F1", "Task": "Question_Answering", "score": "71.32"}]}
{"doc_id": "3d18ce183b5a5b4dcaa1216e30b774ef49eaa46f", "arxiv_id": "1804.01005", "title": "Face Alignment in Full Pose Range: A 3D Total Solution", "n_ary_relations": [{"Material": "AFLW2000", "Method": "3DDFA", "Metric": "MAE", "Task": "Head_Pose_Estimation", "score": " 7.393"}, {"Material": "AFLW2000-3D", "Method": "3DDFA", "Metric": "Mean_NME_", "Task": "3D_Face_Reconstruction", "score": "5.3695%"}, {"Material": "AFLW2000-3D", "Method": "3DDFA___SDM", "Metric": "Mean_NME_", "Task": "Face_Alignment", "score": "4.94%"}, {"Material": "BIWI", "Method": "3DDFA", "Metric": "MAE", "Task": "Head_Pose_Estimation", "score": "19.068"}, {"Material": "Florence", "Method": "3DDFA", "Metric": "Mean_NME_", "Task": "3D_Face_Reconstruction", "score": "6.3833%"}]}
{"doc_id": "3d5d9d8e74b215609eabba80ef79a35ebf460e49", "arxiv_id": "1905.01270", "title": "DRIT++: Diverse Image-to-Image Translation via Disentangled Representations", "n_ary_relations": [{"Material": "GTAV-to-Cityscapes_Labels", "Method": "Domain_adaptation___ResNet-101", "Metric": "mIoU", "Task": "Synthetic-to-Real_Translation", "score": "43.2"}]}
{"doc_id": "3d734edc41c13fb4da2c3709e8255b004d083962", "arxiv_id": "1707.07128", "title": "Single image super-resolution with dilated convolution based multi-scale information learning inception module", "n_ary_relations": [{"Material": "Set14_-_4x_upscaling", "Method": "MSSRNet", "Metric": "PSNR", "Task": "Image_Super-Resolution", "score": "27.83"}, {"Material": "Set14_-_4x_upscaling", "Method": "MSSRNet", "Metric": "SSIM", "Task": "Image_Super-Resolution", "score": "0.7631"}, {"Material": "Set5_-_4x_upscaling", "Method": "MSSRNet", "Metric": "PSNR", "Task": "Image_Super-Resolution", "score": "31.10"}, {"Material": "Set5_-_4x_upscaling", "Method": "MSSRNet", "Metric": "SSIM", "Task": "Image_Super-Resolution", "score": "0.8777"}]}
{"doc_id": "3dd2f70f48588e9bb89f1e5eec7f0d8750dd920a", "arxiv_id": "1504.08083", "title": "Fast R-CNN", "n_ary_relations": [{"Material": "PASCAL_VOC_2007", "Method": "FRCN", "Metric": "MAP", "Task": "Object_Detection", "score": "70.0%"}]}
{"doc_id": "3e58fbb8cb96880e018ca18a60e2d86e3cb0c10a", "arxiv_id": "1705.07422", "title": "Generative Partition Networks for Multi-Person Pose Estimation", "n_ary_relations": [{"Material": "MPII_Multi-Person", "Method": "Generative_Partition_Networks", "Metric": "AP", "Task": "Multi-Person_Pose_Estimation", "score": "80.4%"}, {"Material": "WAF", "Method": "Generative_Partition_Networks", "Metric": "AP", "Task": "Multi-Person_Pose_Estimation", "score": "84.8"}]}
{"doc_id": "3e79a574d776c46bbe6d34f41b1e83b5d0f698f2", "arxiv_id": "1805.02474", "title": "Sentence-State LSTM for Text Representation", "n_ary_relations": [{"Material": "CoNLL_2003__English_", "Method": "S-LSTM", "Metric": "F1", "Task": "Named_Entity_Recognition__NER_", "score": "91.57"}, {"Material": "IMDb", "Method": "S-LSTM", "Metric": "Accuracy", "Task": "Sentiment_Analysis", "score": "87.15"}, {"Material": "MR", "Method": "S-LSTM", "Metric": "Accuracy", "Task": "Sentiment_Analysis", "score": "76.2"}, {"Material": "Penn_Treebank", "Method": "S-LSTM", "Metric": "Accuracy", "Task": "Part-Of-Speech_Tagging", "score": "97.55"}]}
{"doc_id": "3e7f54801c886ea2061650fd24fc481e39be152f", "arxiv_id": "", "title": "Towards Viewpoint Invariant 3D Human Pose Estimation", "n_ary_relations": [{"Material": "_ITOP_front-view", "Method": "Multi-task_learning___viewpoint_invariance", "Metric": "Mean_mAP", "Task": "Pose_Estimation", "score": "77.4"}, {"Material": "ITOP_top-view", "Method": "Multi-task_learning___viewpoint_invariance", "Metric": "Mean_mAP", "Task": "Pose_Estimation", "score": "75.5"}]}
{"doc_id": "3e95925d2bca43223453010ff8516a492287ce19", "arxiv_id": "1805.09655", "title": "Global-Locally Self-Attentive Encoder for Dialogue State Tracking", "n_ary_relations": [{"Material": "Second_dialogue_state_tracking_challenge", "Method": "Zhong_et_al_", "Metric": "Area", "Task": "Dialogue_State_Tracking", "score": "-"}, {"Material": "Second_dialogue_state_tracking_challenge", "Method": "Zhong_et_al_", "Metric": "Food", "Task": "Dialogue_State_Tracking", "score": "-"}, {"Material": "Second_dialogue_state_tracking_challenge", "Method": "Zhong_et_al_", "Metric": "Joint", "Task": "Dialogue_State_Tracking", "score": "74.5"}, {"Material": "Second_dialogue_state_tracking_challenge", "Method": "Zhong_et_al_", "Metric": "Price", "Task": "Dialogue_State_Tracking", "score": "-"}, {"Material": "Second_dialogue_state_tracking_challenge", "Method": "Zhong_et_al_", "Metric": "Request", "Task": "Dialogue_State_Tracking", "score": "97.5"}, {"Material": "Wizard-of-Oz", "Method": "Zhong_et_al_", "Metric": "Joint", "Task": "Dialogue_State_Tracking", "score": "88.1"}, {"Material": "Wizard-of-Oz", "Method": "Zhong_et_al_", "Metric": "Request", "Task": "Dialogue_State_Tracking", "score": "97.1"}]}
{"doc_id": "3f3a483402a3a2b800cf2c86506a37f6ef1a5332", "arxiv_id": "1511.06645", "title": "DeepCut: Joint Subset Partition and Labeling for Multi Person Pose Estimation", "n_ary_relations": [{"Material": "MPII_Human_Pose", "Method": "DeepCut", "Metric": "PCKh-0_5", "Task": "Pose_Estimation", "score": "82.40%"}, {"Material": "WAF", "Method": "DeepCut", "Metric": "AOP", "Task": "Multi-Person_Pose_Estimation", "score": "86.5%"}]}
{"doc_id": "3f45d73a7b8d10a59a68688c11950e003f4852fc", "arxiv_id": "", "title": "Person re-identification by Local Maximal Occurrence representation and metric learning", "n_ary_relations": [{"Material": "DukeMTMC-reID", "Method": "LOMO___XQDA", "Metric": "MAP", "Task": "Person_Re-Identification", "score": "17.04"}, {"Material": "DukeMTMC-reID", "Method": "LOMO___XQDA", "Metric": "Rank-1", "Task": "Person_Re-Identification", "score": "30.75"}, {"Material": "Market-1501", "Method": "LOMO___XQDA", "Metric": "MAP", "Task": "Person_Re-Identification", "score": "22.22"}, {"Material": "Market-1501", "Method": "LOMO___XQDA", "Metric": "Rank-1", "Task": "Person_Re-Identification", "score": "43.79"}]}
{"doc_id": "3febb2bed8865945e7fddc99efd791887bb7e14f", "arxiv_id": "1802.05365", "title": "Deep Contextualized Word Representations", "n_ary_relations": [{"Material": "ACL-ARC", "Method": "BiLSTM-Attention___ELMo", "Metric": "F1", "Task": "Citation_Intent_Classification", "score": "54.6"}, {"Material": "CoNLL_2003__English_", "Method": "BiLSTM-CRF_ELMo", "Metric": "F1", "Task": "Named_Entity_Recognition__NER_", "score": "92.22"}, {"Material": "CoNLL_2012", "Method": "_Lee_et_al___2017__ELMo", "Metric": "Avg_F1", "Task": "Coreference_Resolution", "score": "70.4"}, {"Material": "OntoNotes", "Method": "_He_et_al___2017____ELMo", "Metric": "F1", "Task": "Semantic_Role_Labeling", "score": "84.6"}, {"Material": "SNLI", "Method": "ESIM___ELMo", "Metric": "__Test_Accuracy", "Task": "Natural_Language_Inference", "score": "88.7"}, {"Material": "SNLI", "Method": "ESIM___ELMo_Ensemble", "Metric": "__Test_Accuracy", "Task": "Natural_Language_Inference", "score": "89.3"}, {"Material": "SNLI", "Method": "ESIM___ELMo", "Metric": "__Train_Accuracy", "Task": "Natural_Language_Inference", "score": "91.6"}, {"Material": "SNLI", "Method": "ESIM___ELMo_Ensemble", "Metric": "__Train_Accuracy", "Task": "Natural_Language_Inference", "score": "92.1"}, {"Material": "SNLI", "Method": "ESIM___ELMo", "Metric": "Parameters", "Task": "Natural_Language_Inference", "score": "8.0m"}, {"Material": "SNLI", "Method": "ESIM___ELMo_Ensemble", "Metric": "Parameters", "Task": "Natural_Language_Inference", "score": "40m"}, {"Material": "SQuAD1_1", "Method": "BiDAF___Self_Attention___ELMo__ensemble_", "Metric": "EM", "Task": "Question_Answering", "score": "81.003"}, {"Material": "SQuAD1_1", "Method": "BiDAF___Self_Attention___ELMo__single_model_", "Metric": "EM", "Task": "Question_Answering", "score": "78.580"}, {"Material": "SQuAD1_1", "Method": "BiDAF___Self_Attention___ELMo__ensemble_", "Metric": "F1", "Task": "Question_Answering", "score": "87.432"}, {"Material": "SQuAD1_1", "Method": "BiDAF___Self_Attention___ELMo__single_model_", "Metric": "F1", "Task": "Question_Answering", "score": "85.833"}, {"Material": "SQuAD2_0", "Method": "BiDAF___Self_Attention___ELMo__single_model_", "Metric": "EM", "Task": "Question_Answering", "score": "63.372"}, {"Material": "SQuAD2_0", "Method": "BiDAF___Self_Attention___ELMo__single_model_", "Metric": "F1", "Task": "Question_Answering", "score": "66.251"}, {"Material": "SST-5_Fine-grained_classification", "Method": "BCN_ELMo", "Metric": "Accuracy", "Task": "Sentiment_Analysis", "score": "54.7"}]}
{"doc_id": "40193e7ba0fbd7153a1fe15e95563463b67c71f3", "arxiv_id": "1903.09359", "title": "Joint 3D Face Reconstruction and Dense Face Alignment from A Single Image with 2D-Assisted Self-Supervised Learning", "n_ary_relations": [{"Material": "AFLW2000-3D", "Method": "2DASL", "Metric": "Mean_NME_", "Task": "Face_Alignment", "score": "3.53%"}]}
{"doc_id": "4087ebc37a1650dbb5d8205af0850bee74f3784b", "arxiv_id": "1812.01216", "title": "Parameter Re-Initialization through Cyclical Batch Size Schedules", "n_ary_relations": [{"Material": "SNLI", "Method": "CBS-1___ESIM", "Metric": "__Test_Accuracy", "Task": "Natural_Language_Inference", "score": "86.73"}]}
{"doc_id": "40b0fced8bc45f548ca7f79922e62478d2043220", "arxiv_id": "1411.1091", "title": "Do Convnets Learn Correspondence?", "n_ary_relations": [{"Material": "_Pascal3D_", "Method": "ConvNet", "Metric": "Mean_PCK", "Task": "Keypoint_Detection", "score": "48.5"}]}
{"doc_id": "40b4596a0ae4f4ff065f3f13f36db39543e50068", "arxiv_id": "1711.11556", "title": "ROAD: Reality Oriented Adaptation for Semantic Segmentation of Urban Scenes", "n_ary_relations": [{"Material": "GTAV-to-Cityscapes_Labels", "Method": "ROAD", "Metric": "mIoU", "Task": "Synthetic-to-Real_Translation", "score": "39.4"}]}
{"doc_id": "40eb1e54cb5382dfd3b7efd16dc7df826262ea52", "arxiv_id": "1711.08488", "title": "Frustum PointNets for 3D Object Detection from RGB-D Data", "n_ary_relations": [{"Material": "KITTI_Cars_Easy", "Method": "Frustum_PointNets", "Metric": "AP", "Task": "3D_Object_Detection", "score": "81.20%"}, {"Material": "KITTI_Cars_Easy", "Method": "Frustum_PointNets", "Metric": "AP", "Task": "Object_Localization", "score": "88.70%"}, {"Material": "KITTI_Cars_Hard", "Method": "Frustum_PointNets", "Metric": "AP", "Task": "3D_Object_Detection", "score": "62.19%"}, {"Material": "KITTI_Cars_Hard", "Method": "Frustum_PointNets", "Metric": "AP", "Task": "Object_Localization", "score": "75.33%"}, {"Material": "KITTI_Cars_Moderate", "Method": "Frustum_PointNets", "Metric": "AP", "Task": "3D_Object_Detection", "score": " 70.39%"}, {"Material": "KITTI_Cars_Moderate", "Method": "Frustum_PointNets", "Metric": "AP", "Task": "Object_Localization", "score": "84.00%"}, {"Material": "KITTI_Cyclists_Easy", "Method": "Frustum_PointNets", "Metric": "AP", "Task": "3D_Object_Detection", "score": "71.96%"}, {"Material": "KITTI_Cyclists_Easy", "Method": "Frustum_PointNets", "Metric": "AP", "Task": "Object_Localization", "score": "75.38%"}, {"Material": "KITTI_Cyclists_Hard", "Method": "Frustum_PointNets", "Metric": "AP", "Task": "3D_Object_Detection", "score": "50.39%"}, {"Material": "KITTI_Cyclists_Hard", "Method": "Frustum_PointNets", "Metric": "AP", "Task": "Object_Localization", "score": "54.68%"}, {"Material": "KITTI_Cyclists_Moderate", "Method": "Frustum_PointNets", "Metric": "AP", "Task": "3D_Object_Detection", "score": "56.77%"}, {"Material": "KITTI_Cyclists_Moderate", "Method": "Frustum_PointNets", "Metric": "AP", "Task": "Object_Localization", "score": "61.96%"}, {"Material": "KITTI_Pedestrians_Easy", "Method": "Frustum_PointNets", "Metric": "AP", "Task": "3D_Object_Detection", "score": "51.21%"}, {"Material": "KITTI_Pedestrians_Easy", "Method": "Frustum_PointNets", "Metric": "AP", "Task": "Object_Localization", "score": "58.09%"}, {"Material": "KITTI_Pedestrians_Hard", "Method": "Frustum_PointNets", "Metric": "AP", "Task": "3D_Object_Detection", "score": "40.23%"}, {"Material": "KITTI_Pedestrians_Hard", "Method": "Frustum_PointNets", "Metric": "AP", "Task": "Object_Localization", "score": "47.20%"}, {"Material": "KITTI_Pedestrians_Moderate", "Method": "Frustum_PointNets", "Metric": "AP", "Task": "3D_Object_Detection", "score": "44.89%"}, {"Material": "KITTI_Pedestrians_Moderate", "Method": "Frustum_PointNets", "Metric": "AP", "Task": "Object_Localization", "score": "50.22%"}, {"Material": "SUN-RGBD", "Method": "Frustum_PointNets", "Metric": "MAP", "Task": "3D_Object_Detection", "score": "54.0%"}]}
{"doc_id": "41232a69c0f8d4b993e6c6e00b16c223442c962f", "arxiv_id": "1711.04434", "title": "Faithful to the Original: Fact Aware Neural Abstractive Summarization", "n_ary_relations": [{"Material": "GigaWord", "Method": "FTSum_g", "Metric": "ROUGE-1", "Task": "Text_Summarization", "score": "37.27"}, {"Material": "GigaWord", "Method": "FTSum_g", "Metric": "ROUGE-2", "Task": "Text_Summarization", "score": "17.65"}, {"Material": "GigaWord", "Method": "FTSum_g", "Metric": "ROUGE-L", "Task": "Text_Summarization", "score": "34.24"}]}
{"doc_id": "41951953579a0e3620f0235e5fcb80b930e6eee3", "arxiv_id": "1406.4773", "title": "Deep Learning Face Representation by Joint Identification-Verification", "n_ary_relations": [{"Material": "Labeled_Faces_in_the_Wild", "Method": "DeepId2", "Metric": "Accuracy", "Task": "Face_Verification", "score": "99.15%"}]}
{"doc_id": "41b38da2f4137c957537908f9cb70cbd2fac8bc1", "arxiv_id": "1701.01879", "title": "Greedy search for descriptive spatial face features", "n_ary_relations": [{"Material": "Cohn-Kanade", "Method": "Sequential_forward_selection", "Metric": "Accuracy", "Task": "Facial_Expression_Recognition", "score": "88.7%"}]}
{"doc_id": "41d08fb733f3e50ac183490f84d6377dffccf350", "arxiv_id": "1612.00603", "title": "A Point Set Generation Network for 3D Object Reconstruction from a Single Image", "n_ary_relations": [{"Material": "Data3D_R2N2", "Method": "PSG", "Metric": "Avg_F1", "Task": "3D_Object_Reconstruction", "score": "48.58"}]}
{"doc_id": "420c46d7cafcb841309f02ad04cf51cb1f190a48", "arxiv_id": "1511.07122", "title": "Multi-Scale Context Aggregation by Dilated Convolutions", "n_ary_relations": [{"Material": "ADE20K", "Method": "DilatedNet", "Metric": "Validation_mIoU", "Task": "Semantic_Segmentation", "score": "32.31"}, {"Material": "CamVid", "Method": "Dilation10", "Metric": "Frame__fps_", "Task": "Real-Time_Semantic_Segmentation", "score": "4.4"}, {"Material": "CamVid", "Method": "Dilated_Convolutions", "Metric": "Mean_IoU", "Task": "Semantic_Segmentation", "score": "65.3%"}, {"Material": "CamVid", "Method": "Dilation10", "Metric": "Time__ms_", "Task": "Real-Time_Semantic_Segmentation", "score": "227"}, {"Material": "CamVid", "Method": "Dilation10", "Metric": "mIoU", "Task": "Real-Time_Semantic_Segmentation", "score": "65.3%"}, {"Material": "Cityscapes", "Method": "Dilation10", "Metric": "Frame__fps_", "Task": "Real-Time_Semantic_Segmentation", "score": "0.25"}, {"Material": "Cityscapes", "Method": "Dilation10", "Metric": "Mean_IoU", "Task": "Semantic_Segmentation", "score": "67.1%"}, {"Material": "Cityscapes", "Method": "Dilation10", "Metric": "Time__ms_", "Task": "Real-Time_Semantic_Segmentation", "score": "4000"}, {"Material": "Cityscapes", "Method": "Dilation10", "Metric": "mIoU", "Task": "Real-Time_Semantic_Segmentation", "score": "67.1%"}, {"Material": "PASCAL_VOC_2012", "Method": "Dilated_Convolutions", "Metric": "Mean_IoU", "Task": "Semantic_Segmentation", "score": "67.6%"}]}
{"doc_id": "424561d8585ff8ebce7d5d07de8dbf7aae5e7270", "arxiv_id": "1506.01497", "title": "Faster R-CNN: Towards Real-Time Object Detection with Region Proposal Networks", "n_ary_relations": [{"Material": "PASCAL_VOC_2007", "Method": "Faster_R-CNN", "Metric": "FPS", "Task": "Real-Time_Object_Detection", "score": "7"}, {"Material": "PASCAL_VOC_2007", "Method": "Faster_R-CNN", "Metric": "MAP", "Task": "Object_Detection", "score": "73.2%"}, {"Material": "PASCAL_VOC_2007", "Method": "Faster_R-CNN", "Metric": "MAP", "Task": "Real-Time_Object_Detection", "score": "73.2%"}]}
{"doc_id": "424aef7340ee618132cc3314669400e23ad910ba", "arxiv_id": "1611.01462", "title": "Tying Word Vectors and Word Classifiers: A Loss Framework for Language Modeling", "n_ary_relations": [{"Material": "Penn_Treebank__Word_Level_", "Method": "Tied_Variational_LSTM___augmented_loss", "Metric": "Params", "Task": "Language_Modelling", "score": "24M"}, {"Material": "Penn_Treebank__Word_Level_", "Method": "Tied_Variational_LSTM___augmented_loss", "Metric": "Test_perplexity", "Task": "Language_Modelling", "score": "73.2"}, {"Material": "Penn_Treebank__Word_Level_", "Method": "Tied_Variational_LSTM___augmented_loss", "Metric": "Validation_perplexity", "Task": "Language_Modelling", "score": "75.7"}]}
{"doc_id": "42764b57d0794b63487a295ce8c07eeb6961477e", "arxiv_id": "1512.04412", "title": "Instance-Aware Semantic Segmentation via Multi-task Network Cascades", "n_ary_relations": [{"Material": "PASCAL-Person-Part", "Method": "MNC", "Metric": "AP_0_5", "Task": "Multi-Human_Parsing", "score": "38.80%"}]}
{"doc_id": "42e80c73867bff9eaff6beceb8730fc1276283b9", "arxiv_id": "1902.01313", "title": "An Effective Approach to Unsupervised Machine Translation", "n_ary_relations": [{"Material": "WMT2014_English-French", "Method": "SMT___NMT__tuning_and_joint_refinement_", "Metric": "BLEU", "Task": "Unsupervised_Machine_Translation", "score": "36.2"}, {"Material": "WMT2014_English-German", "Method": "SMT___NMT__tuning_and_joint_refinement_", "Metric": "BLEU", "Task": "Unsupervised_Machine_Translation", "score": "22.5"}, {"Material": "WMT2014_French-English", "Method": "SMT___NMT__tuning_and_joint_refinement_", "Metric": "BLEU", "Task": "Unsupervised_Machine_Translation", "score": "33.5"}, {"Material": "WMT2014_German-English", "Method": "SMT___NMT__tuning_and_joint_refinement_", "Metric": "BLEU", "Task": "Unsupervised_Machine_Translation", "score": "27.0"}, {"Material": "WMT2016_English-German", "Method": "SMT___NMT__tuning_and_joint_refinement_", "Metric": "BLEU", "Task": "Unsupervised_Machine_Translation", "score": "26.9"}, {"Material": "WMT2016_German-English", "Method": "SMT___NMT__tuning_and_joint_refinement_", "Metric": "BLEU", "Task": "Unsupervised_Machine_Translation", "score": "34.4"}]}
{"doc_id": "42f20d37f4eba56284a941d5f9f58609ee650de0", "arxiv_id": "1712.06116", "title": "Learning a Single Convolutional Super-Resolution Network for Multiple Degradations", "n_ary_relations": [{"Material": "BSD100_-_4x_upscaling", "Method": "SRMDNF", "Metric": "PSNR", "Task": "Image_Super-Resolution", "score": "27.49"}, {"Material": "BSD100_-_4x_upscaling", "Method": "SRMDNF", "Metric": "SSIM", "Task": "Image_Super-Resolution", "score": "0.734"}, {"Material": "Set14_-_4x_upscaling", "Method": "SRMDNF", "Metric": "PSNR", "Task": "Image_Super-Resolution", "score": "28.35"}, {"Material": "Set14_-_4x_upscaling", "Method": "SRMDNF", "Metric": "SSIM", "Task": "Image_Super-Resolution", "score": "0.777"}, {"Material": "Set5_-_4x_upscaling", "Method": "SRMDNF", "Metric": "PSNR", "Task": "Image_Super-Resolution", "score": "31.96"}, {"Material": "Set5_-_4x_upscaling", "Method": "SRMDNF", "Metric": "SSIM", "Task": "Image_Super-Resolution", "score": "0.893"}, {"Material": "Urban100_-_4x_upscaling", "Method": "SRMDNF", "Metric": "PSNR", "Task": "Image_Super-Resolution", "score": "25.68"}, {"Material": "Urban100_-_4x_upscaling", "Method": "SRMDNF", "Metric": "SSIM", "Task": "Image_Super-Resolution", "score": "0.773"}]}
{"doc_id": "432d8cba544bf7b09b0455561fea098177a85db1", "arxiv_id": "1606.02185", "title": "Towards a Neural Statistician", "n_ary_relations": [{"Material": "OMNIGLOT_-_1-Shot_Learning", "Method": "Neural_Statistician", "Metric": "Accuracy", "Task": "Few-Shot_Image_Classification", "score": "98.1%"}, {"Material": "OMNIGLOT_-_5-Shot_Learning", "Method": "Neural_Statistician", "Metric": "Accuracy", "Task": "Few-Shot_Image_Classification", "score": "99.5%"}]}
{"doc_id": "43428880d75b3a14257c3ee9bda054e61eb869c0", "arxiv_id": "1705.03122", "title": "Convolutional Sequence to Sequence Learning", "n_ary_relations": [{"Material": "IWSLT2015_English-German", "Method": "ConvS2S", "Metric": "BLEU_score", "Task": "Machine_Translation", "score": "26.73"}, {"Material": "IWSLT2015_German-English", "Method": "ConvS2S", "Metric": "BLEU_score", "Task": "Machine_Translation", "score": "32.31"}, {"Material": "WMT2014_English-French", "Method": "ConvS2S", "Metric": "BLEU_score", "Task": "Machine_Translation", "score": "40.46"}, {"Material": "WMT2014_English-French", "Method": "ConvS2S__ensemble_", "Metric": "BLEU_score", "Task": "Machine_Translation", "score": 41.29}, {"Material": "WMT2014_English-German", "Method": "ConvS2S", "Metric": "BLEU_score", "Task": "Machine_Translation", "score": "25.16"}, {"Material": "WMT2014_English-German", "Method": "ConvS2S__ensemble_", "Metric": "BLEU_score", "Task": "Machine_Translation", "score": 26.36}, {"Material": "WMT2016_English-Romanian", "Method": "ConvS2S_BPE40k", "Metric": "BLEU_score", "Task": "Machine_Translation", "score": 29.88}]}
{"doc_id": "434bf475addfb580707208618f99c8be0c55cf95", "arxiv_id": "1509.05371", "title": "DeXpression: Deep Convolutional Neural Network for Expression Recognition", "n_ary_relations": [{"Material": "MMI", "Method": "DeXpression", "Metric": "Accuracy", "Task": "Facial_Expression_Recognition", "score": "98.63%"}]}
{"doc_id": "435259c5f3cffd75ef837a8e638cc8f6244e25c4", "arxiv_id": "1712.05319", "title": "Deep CNN ensembles and suggestive annotations for infant brain MRI segmentation", "n_ary_relations": [{"Material": "iSEG_2017_Challenge", "Method": "LiviaNet__SemiDenseNet_", "Metric": "Dice_Score", "Task": "Infant_Brain_Mri_Segmentation", "score": "0.9243"}]}
{"doc_id": "4402c6c8445f17f4161e0f64573b7e28df1ca180", "arxiv_id": "1611.00144", "title": "Product-Based Neural Networks for User Response Prediction", "n_ary_relations": [{"Material": "Amazon", "Method": "PNN", "Metric": "AUC", "Task": "Click-Through_Rate_Prediction", "score": "0.8679"}, {"Material": "Bing_News", "Method": "PNN", "Metric": "AUC", "Task": "Click-Through_Rate_Prediction", "score": "0.8321"}, {"Material": "Bing_News", "Method": "PNN", "Metric": "Log_Loss", "Task": "Click-Through_Rate_Prediction", "score": "0.2775"}, {"Material": "Company_", "Method": "IPNN", "Metric": "AUC", "Task": "Click-Through_Rate_Prediction", "score": "0.8664"}, {"Material": "Company_", "Method": "OPNN", "Metric": "AUC", "Task": "Click-Through_Rate_Prediction", "score": "0.8658"}, {"Material": "Company_", "Method": "PNN_", "Metric": "AUC", "Task": "Click-Through_Rate_Prediction", "score": "0.8672"}, {"Material": "Company_", "Method": "IPNN", "Metric": "Log_Loss", "Task": "Click-Through_Rate_Prediction", "score": "0.02637"}, {"Material": "Company_", "Method": "OPNN", "Metric": "Log_Loss", "Task": "Click-Through_Rate_Prediction", "score": "0.02641"}, {"Material": "Company_", "Method": "PNN_", "Metric": "Log_Loss", "Task": "Click-Through_Rate_Prediction", "score": "0.02636"}, {"Material": "Criteo", "Method": "IPNN", "Metric": "AUC", "Task": "Click-Through_Rate_Prediction", "score": "0.7972"}, {"Material": "Criteo", "Method": "OPNN", "Metric": "AUC", "Task": "Click-Through_Rate_Prediction", "score": "0.7982"}, {"Material": "Criteo", "Method": "PNN_", "Metric": "AUC", "Task": "Click-Through_Rate_Prediction", "score": "0.7987"}, {"Material": "Criteo", "Method": "IPNN", "Metric": "Log_Loss", "Task": "Click-Through_Rate_Prediction", "score": "0.45323"}, {"Material": "Criteo", "Method": "OPNN", "Metric": "Log_Loss", "Task": "Click-Through_Rate_Prediction", "score": "0.45256"}, {"Material": "Criteo", "Method": "PNN_", "Metric": "Log_Loss", "Task": "Click-Through_Rate_Prediction", "score": "0.45214"}, {"Material": "Dianping", "Method": "PNN", "Metric": "AUC", "Task": "Click-Through_Rate_Prediction", "score": "0.8445"}, {"Material": "Dianping", "Method": "PNN", "Metric": "Log_Loss", "Task": "Click-Through_Rate_Prediction", "score": "0.3424"}, {"Material": "MovieLens_20M", "Method": "PNN", "Metric": "AUC", "Task": "Click-Through_Rate_Prediction", "score": "0.7321"}, {"Material": "iPinYou", "Method": "IPNN", "Metric": "AUC", "Task": "Click-Through_Rate_Prediction", "score": "0.7914"}, {"Material": "iPinYou", "Method": "OPNN", "Metric": "AUC", "Task": "Click-Through_Rate_Prediction", "score": "0.8174"}, {"Material": "iPinYou", "Method": "PNN_", "Metric": "AUC", "Task": "Click-Through_Rate_Prediction", "score": "0.7661"}]}
{"doc_id": "44c5dec4d1295d34f052d3243d8e08f14a3c0990", "arxiv_id": "1901.02860", "title": "Transformer-XL: Attentive Language Models beyond a Fixed-Length Context", "n_ary_relations": [{"Material": "Hutter_Prize", "Method": "12-layer_Transformer-XL", "Metric": "Bit_per_Character__BPC_", "Task": "Language_Modelling", "score": "1.06"}, {"Material": "Hutter_Prize", "Method": "18-layer_Transformer-XL", "Metric": "Bit_per_Character__BPC_", "Task": "Language_Modelling", "score": "1.03"}, {"Material": "Hutter_Prize", "Method": "24-layer_Transformer-XL", "Metric": "Bit_per_Character__BPC_", "Task": "Language_Modelling", "score": "0.99"}, {"Material": "Hutter_Prize", "Method": "12-layer_Transformer-XL", "Metric": "Number_of_params", "Task": "Language_Modelling", "score": "41M"}, {"Material": "Hutter_Prize", "Method": "18-layer_Transformer-XL", "Metric": "Number_of_params", "Task": "Language_Modelling", "score": "88M"}, {"Material": "Hutter_Prize", "Method": "24-layer_Transformer-XL", "Metric": "Number_of_params", "Task": "Language_Modelling", "score": "277M"}, {"Material": "One_Billion_Word", "Method": "Transformer-XL_Base", "Metric": "Number_of_params", "Task": "Language_Modelling", "score": "0.46B"}, {"Material": "One_Billion_Word", "Method": "Transformer-XL_Large", "Metric": "Number_of_params", "Task": "Language_Modelling", "score": "0.8B"}, {"Material": "One_Billion_Word", "Method": "Transformer-XL_Base", "Metric": "PPL", "Task": "Language_Modelling", "score": "23.5"}, {"Material": "One_Billion_Word", "Method": "Transformer-XL_Large", "Metric": "PPL", "Task": "Language_Modelling", "score": "21.8"}, {"Material": "Penn_Treebank__Word_Level_", "Method": "Transformer-XL", "Metric": "Params", "Task": "Language_Modelling", "score": "24M"}, {"Material": "Penn_Treebank__Word_Level_", "Method": "Transformer-XL", "Metric": "Test_perplexity", "Task": "Language_Modelling", "score": "54.55"}, {"Material": "Penn_Treebank__Word_Level_", "Method": "Transformer-XL", "Metric": "Validation_perplexity", "Task": "Language_Modelling", "score": "56.72"}, {"Material": "Text8", "Method": "Transformer-XL_-_24_layers", "Metric": "Bit_per_Character__BPC_", "Task": "Language_Modelling", "score": "1.08"}, {"Material": "Text8", "Method": "Transformer-XL_-_24_layers", "Metric": "Number_of_params", "Task": "Language_Modelling", "score": "277M"}, {"Material": "WikiText-103", "Method": "Transformer-XL_Large", "Metric": "Number_of_params", "Task": "Language_Modelling", "score": "257M"}, {"Material": "WikiText-103", "Method": "Transformer-XL_Standard", "Metric": "Number_of_params", "Task": "Language_Modelling", "score": "151M"}, {"Material": "WikiText-103", "Method": "Transformer-XL_Large", "Metric": "Test_perplexity", "Task": "Language_Modelling", "score": "18.3"}, {"Material": "WikiText-103", "Method": "Transformer-XL_Standard", "Metric": "Test_perplexity", "Task": "Language_Modelling", "score": "24.0"}, {"Material": "WikiText-103", "Method": "Transformer-XL_Large", "Metric": "Validation_perplexity", "Task": "Language_Modelling", "score": "18.2"}, {"Material": "WikiText-103", "Method": "Transformer-XL_Standard", "Metric": "Validation_perplexity", "Task": "Language_Modelling", "score": "23.1"}, {"Material": "enwiki8", "Method": "Transformer-XL_-_12_layers", "Metric": "Bit_per_Character__BPC_", "Task": "Language_Modelling", "score": "1.06"}, {"Material": "enwiki8", "Method": "Transformer-XL_-_18_layers", "Metric": "Bit_per_Character__BPC_", "Task": "Language_Modelling", "score": "1.03"}, {"Material": "enwiki8", "Method": "Transformer-XL_-_24_layers", "Metric": "Bit_per_Character__BPC_", "Task": "Language_Modelling", "score": "0.99"}, {"Material": "enwiki8", "Method": "Transformer-XL_-_12_layers", "Metric": "Number_of_params", "Task": "Language_Modelling", "score": "41M"}, {"Material": "enwiki8", "Method": "Transformer-XL_-_18_layers", "Metric": "Number_of_params", "Task": "Language_Modelling", "score": "88M"}, {"Material": "enwiki8", "Method": "Transformer-XL_-_24_layers", "Metric": "Number_of_params", "Task": "Language_Modelling", "score": "277M"}]}
{"doc_id": "44da806ae67ae9885592492202b3dc5f50182cc8", "arxiv_id": "1806.02559", "title": "Shape Robust Text Detection With Progressive Scale Expansion Network", "n_ary_relations": [{"Material": "IC15", "Method": "PSENet-1s", "Metric": "F-Measure", "Task": "Scene_Text_Detection", "score": "87.08%"}, {"Material": "IC17-MLT", "Method": "PSENet-1s", "Metric": "F-Measure", "Task": "Scene_Text_Detection", "score": "72.45%"}, {"Material": "SCUT-CTW1500", "Method": "PSENet-1s", "Metric": "F-Measure", "Task": "Curved_Text_Detection", "score": "81.17%"}]}
{"doc_id": "4508f81033c9a7cec785ce4d16f1193920c1b341", "arxiv_id": "1610.10099", "title": "Neural Machine Translation in Linear Time", "n_ary_relations": [{"Material": "WMT2014_English-French", "Method": "ByteNet", "Metric": "BLEU_score", "Task": "Machine_Translation", "score": "23.8"}, {"Material": "WMT2014_English-German", "Method": "ByteNet", "Metric": "BLEU_score", "Task": "Machine_Translation", "score": "23.75"}, {"Material": "WMT2015_English-German", "Method": "ByteNet", "Metric": "BLEU_score", "Task": "Machine_Translation", "score": 26.26}]}
{"doc_id": "450e9676991b91e6b5eba3f77ac95dd0d3d6b655", "arxiv_id": "1610.02915", "title": "Deep Pyramidal Residual Networks", "n_ary_relations": [{"Material": "CIFAR-10", "Method": "Deep_pyramidal_residual_network", "Metric": "Percentage_correct", "Task": "Image_Classification", "score": "96.69"}, {"Material": "CIFAR-10", "Method": "Deep_pyramidal_residual_network", "Metric": "Percentage_error", "Task": "Image_Classification", "score": "3.31"}]}
{"doc_id": "4543052aeaf52fdb01fced9b3ccf97827582cef5", "arxiv_id": "1808.02194", "title": "Quantized Densely Connected U-Nets for Efficient Landmark Localization", "n_ary_relations": [{"Material": "MPII_Human_Pose", "Method": "DU-Net", "Metric": "PCKh-0_5", "Task": "Pose_Estimation", "score": "91.2%"}]}
{"doc_id": "454dd76eb0a82286c054a6dd9d9413e09ad66801", "arxiv_id": "1609.05600", "title": "Graph-Structured Representations for Visual Question Answering", "n_ary_relations": [{"Material": "COCO_Visual_Question_Answering__VQA__abstract_1_0_multiple_choice", "Method": "Graph_VQA", "Metric": "Percentage_correct", "Task": "Visual_Question_Answering", "score": 74.37}, {"Material": "COCO_Visual_Question_Answering__VQA__abstract_images_1_0_open_ended", "Method": "Graph_VQA", "Metric": "Percentage_correct", "Task": "Visual_Question_Answering", "score": 70.42}]}
{"doc_id": "45b559e6271570598602fcf9777ed6f2f2d133e6", "arxiv_id": "1509.08967", "title": "Very deep multilingual convolutional neural networks for LVCSR", "n_ary_relations": [{"Material": "Switchboard___Hub500", "Method": "Deep_CNN__10_conv__4_FC_layers___multi-scale_feature_maps", "Metric": "Percentage_error", "Task": "Speech_Recognition", "score": 12.2}]}
{"doc_id": "45e8ef229fae18b0a2ab328037d8e520866c3c81", "arxiv_id": "1708.01101", "title": "Learning Feature Pyramids for Human Pose Estimation", "n_ary_relations": [{"Material": "Leeds_Sports_Poses", "Method": "Pyramid_Residual_Modules__PRMs_", "Metric": "PCK", "Task": "Pose_Estimation", "score": "93.9%"}, {"Material": "MPII_Human_Pose", "Method": "Pyramid_Residual_Modules__PRMs_", "Metric": "PCKh-0_5", "Task": "Pose_Estimation", "score": " 92.0%"}]}
{"doc_id": "45fdc73a239e9c6ea65e98c96f6a2d6dc35d6f72", "arxiv_id": "1806.07789", "title": "Quaternion Convolutional Neural Networks for End-to-End Automatic Speech Recognition", "n_ary_relations": [{"Material": "TIMIT", "Method": "QCNN-10L-256FM", "Metric": "Percentage_error", "Task": "Speech_Recognition", "score": "19.64"}]}
{"doc_id": "46018a894d533813d67322827ca51f78aed6d59e", "arxiv_id": "1505.03540", "title": "Brain tumor segmentation with Deep Neural Networks", "n_ary_relations": [{"Material": "BRATS-2013", "Method": "InputCascadeCNN", "Metric": "Dice_Score", "Task": "Brain_Tumor_Segmentation", "score": "0.88"}]}
{"doc_id": "462d4e265c9cbe9ad5feeb9a7736184a90b36fed", "arxiv_id": "1808.09075", "title": "Evaluating the Utility of Hand-crafted Features in Sequence Labelling", "n_ary_relations": [{"Material": "CoNLL_2003__English_", "Method": "CRF___AutoEncoder", "Metric": "F1", "Task": "Named_Entity_Recognition__NER_", "score": "91.87"}, {"Material": "CoNLL_2003__English_", "Method": "Neural-CRF_AE", "Metric": "F1", "Task": "Named_Entity_Recognition__NER_", "score": "92.29"}]}
