{"doc_id": "02567fd428a675ca91a0c6786f47f3e35881bcbd", "arxiv_id": "1611.01731", "title": "Deep Label Distribution Learning With Label Ambiguity", "n_ary_relations": [{"Material": "ChaLearn_2015", "Method": "DLDL_VGG-Face", "Metric": "MAE", "Task": "Age_Estimation", "score": "3.51"}, {"Material": "MORPH_Album2", "Method": "DLDL_VGG-Face", "Metric": "MAE", "Task": "Age_Estimation", "score": "2.42\u00b10.01"}]}
{"doc_id": "02b3d1d162080d9aefd3fc30a0bcc9a843073b5d", "arxiv_id": "1602.02410", "title": "Exploring the Limits of Language Modeling", "n_ary_relations": [{"Material": "One_Billion_Word", "Method": "LSTM-8192-1024", "Metric": "Number_of_params", "Task": "Language_Modelling", "score": "1.8B"}, {"Material": "One_Billion_Word", "Method": "LSTM-8192-1024___CNN_Input", "Metric": "Number_of_params", "Task": "Language_Modelling", "score": "1.04B"}, {"Material": "One_Billion_Word", "Method": "LSTM-8192-1024", "Metric": "PPL", "Task": "Language_Modelling", "score": "30.6"}, {"Material": "One_Billion_Word", "Method": "LSTM-8192-1024___CNN_Input", "Metric": "PPL", "Task": "Language_Modelling", "score": "30.0"}]}
{"doc_id": "0398552184f80db111e9c28bf533b395f233ac00", "arxiv_id": "1703.01290", "title": "Bridging Saliency Detection to Weakly Supervised Object Detection Based on Self-Paced Curriculum Learning", "n_ary_relations": [{"Material": "PASCAL_VOC_2007", "Method": "Self-paced_curriculum_learning", "Metric": "MAP", "Task": "Weakly_Supervised_Object_Detection", "score": "31.3"}]}
{"doc_id": "05d2700846c0323f79c1344aca5333994c7c03a5", "arxiv_id": "1604.08242", "title": "The IBM 2016 English Conversational Telephone Speech Recognition System", "n_ary_relations": [{"Material": "Switchboard___Hub500", "Method": "IBM_2016", "Metric": "Percentage_error", "Task": "Speech_Recognition", "score": 6.9}, {"Material": "Switchboard___Hub500", "Method": "RNN___VGG___LSTM_acoustic_model_trained_on_SWB_Fisher_CH__N-gram____model_M____NNLM_language_model", "Metric": "Percentage_error", "Task": "Speech_Recognition", "score": 6.6}, {"Material": "swb_hub_500_WER_fullSWBCH", "Method": "RNN___VGG___LSTM_acoustic_model_trained_on_SWB_Fisher_CH__N-gram____model_M____NNLM_language_model", "Metric": "Percentage_error", "Task": "Speech_Recognition", "score": 12.2}]}
{"doc_id": "0626908dd710b91aece1a81f4ca0635f23fc47f3", "arxiv_id": "1512.00567", "title": "Rethinking the Inception Architecture for Computer Vision", "n_ary_relations": [{"Material": "ImageNet", "Method": "Inception_V3", "Metric": "Top_1_Accuracy", "Task": "Image_Classification", "score": "78.8%"}, {"Material": "ImageNet", "Method": "Inception_V3", "Metric": "Top_5_Accuracy", "Task": "Image_Classification", "score": "94.4%"}]}
{"doc_id": "0678a8abea82793993cd89383319da75f6dc4be3", "arxiv_id": "1511.03776", "title": "ProNet: Learning to Propose Object-Specific Boxes for Cascaded Neural Networks", "n_ary_relations": [{"Material": "COCO", "Method": "ProNet", "Metric": "MAP", "Task": "Weakly_Supervised_Object_Detection", "score": "43.5"}]}
{"doc_id": "081531984770a74e87dbd68907061b4b0f3631bf", "arxiv_id": "1611.05250", "title": "Real-Time Video Super-Resolution with Spatio-Temporal Networks and Motion Compensation", "n_ary_relations": [{"Material": "Vid4_-_4x_upscaling", "Method": "VESPCN", "Metric": "MOVIE", "Task": "Video_Super-Resolution", "score": "5.82"}, {"Material": "Vid4_-_4x_upscaling", "Method": "bicubic", "Metric": "MOVIE", "Task": "Video_Super-Resolution", "score": "9.31"}, {"Material": "Vid4_-_4x_upscaling", "Method": "VESPCN", "Metric": "PSNR", "Task": "Video_Super-Resolution", "score": "25.35"}, {"Material": "Vid4_-_4x_upscaling", "Method": "bicubic", "Metric": "PSNR", "Task": "Video_Super-Resolution", "score": "23.82"}, {"Material": "Vid4_-_4x_upscaling", "Method": "VESPCN", "Metric": "SSIM", "Task": "Video_Super-Resolution", "score": "0.7557"}, {"Material": "Vid4_-_4x_upscaling", "Method": "bicubic", "Metric": "SSIM", "Task": "Video_Super-Resolution", "score": "0.6548"}]}
{"doc_id": "0834e74304b547c9354b6d7da6fa78ef47a48fa8", "arxiv_id": "1503.03578", "title": "LINE: Large-scale Information Network Embedding", "n_ary_relations": [{"Material": "BlogCatalog", "Method": "LINE", "Metric": "Accuracy", "Task": "Node_Classification", "score": "20.50%"}, {"Material": "BlogCatalog", "Method": "LINE", "Metric": "Macro-F1", "Task": "Node_Classification", "score": "0.192"}, {"Material": "Wikipedia", "Method": "LINE", "Metric": "Accuracy", "Task": "Node_Classification", "score": "17.50%"}, {"Material": "Wikipedia", "Method": "LINE", "Metric": "Macro-F1", "Task": "Node_Classification", "score": "0.164"}]}
{"doc_id": "0a3381f0432c5cfe491c718349d7a44e5814592c", "arxiv_id": "1607.06153", "title": "Compositional Sequence Labeling Models for Error Detection in Learner Writing", "n_ary_relations": [{"Material": "CoNLL-2014_A1", "Method": "Bi-LSTM__trained_on_FCE_", "Metric": "F0_5", "Task": "Grammatical_Error_Detection", "score": "16.4"}, {"Material": "CoNLL-2014_A1", "Method": "Bi-LSTM__unrestricted_data_", "Metric": "F0_5", "Task": "Grammatical_Error_Detection", "score": "34.3 "}, {"Material": "CoNLL-2014_A2", "Method": "Bi-LSTM__trained_on_FCE_", "Metric": "F0_5", "Task": "Grammatical_Error_Detection", "score": "23.9"}, {"Material": "CoNLL-2014_A2", "Method": "Bi-LSTM__unrestricted_data_", "Metric": "F0_5", "Task": "Grammatical_Error_Detection", "score": "44.0"}, {"Material": "FCE", "Method": "Bi-LSTM", "Metric": "F0_5", "Task": "Grammatical_Error_Detection", "score": "41.1"}]}
{"doc_id": "0a6c36de8726b6feaab586046ddc1d1a008f44f9", "arxiv_id": "1501.05759", "title": "Filtered channel features for pedestrian detection", "n_ary_relations": [{"Material": "Caltech", "Method": "Checkerboards_", "Metric": "Reasonable_Miss_Rate", "Task": "Pedestrian_Detection", "score": "17.1"}]}
{"doc_id": "0c47cad9729c38d9db1f75491b1ee4bd883a5d4e", "arxiv_id": "1809.08370", "title": "Semi-Supervised Sequence Modeling with Cross-View Training", "n_ary_relations": [{"Material": "CCGBank", "Method": "Clark_et_al_", "Metric": "Accuracy", "Task": "CCG_Supertagging", "score": "96.1"}, {"Material": "CoNLL_2003__English_", "Method": "CVT___Multi-Task", "Metric": "F1", "Task": "Named_Entity_Recognition__NER_", "score": "92.61"}, {"Material": "Ontonotes_v5__English_", "Method": "CVT___Multi-Task", "Metric": "F1", "Task": "Named_Entity_Recognition__NER_", "score": "88.81"}, {"Material": "Penn_Treebank", "Method": "CVT___Multi-Task", "Metric": "LAS", "Task": "Dependency_Parsing", "score": "95.02"}, {"Material": "Penn_Treebank", "Method": "CVT___Multi-Task", "Metric": "POS", "Task": "Dependency_Parsing", "score": "---"}, {"Material": "Penn_Treebank", "Method": "CVT___Multi-Task", "Metric": "UAS", "Task": "Dependency_Parsing", "score": "96.61"}]}
{"doc_id": "0dc9eb7d17f2def56ad930945f2521653f04c3fa", "arxiv_id": "1412.1454", "title": "Skip-gram Language Modeling Using Sparse Non-negative Matrix Probability Estimation", "n_ary_relations": [{"Material": "One_Billion_Word", "Method": "Sparse_Non-Negative", "Metric": "Number_of_params", "Task": "Language_Modelling", "score": "33B"}, {"Material": "One_Billion_Word", "Method": "Sparse_Non-Negative", "Metric": "PPL", "Task": "Language_Modelling", "score": "52.9"}]}
{"doc_id": "107010b7f2abe3c0c9df62bcef35eb77f6fc76df", "arxiv_id": "1505.07818", "title": "Domain-Adversarial Training of Neural Networks", "n_ary_relations": [{"Material": "Multi-Domain_Sentiment_Dataset", "Method": "DANN", "Metric": "Average", "Task": "Sentiment_Analysis", "score": "76.26"}, {"Material": "Multi-Domain_Sentiment_Dataset", "Method": "DANN", "Metric": "Books", "Task": "Sentiment_Analysis", "score": "71.43"}, {"Material": "Multi-Domain_Sentiment_Dataset", "Method": "DANN", "Metric": "DVD", "Task": "Sentiment_Analysis", "score": "75.40"}, {"Material": "Multi-Domain_Sentiment_Dataset", "Method": "DANN", "Metric": "Electronics", "Task": "Sentiment_Analysis", "score": "77.67"}, {"Material": "Multi-Domain_Sentiment_Dataset", "Method": "DANN", "Metric": "Kitchen", "Task": "Sentiment_Analysis", "score": "80.53"}]}
{"doc_id": "1130d8fdd931225c2d7563c3808367726cfa1c3a", "arxiv_id": "1706.00531", "title": "PixelGAN Autoencoders", "n_ary_relations": [{"Material": "MNIST", "Method": "PixelGAN_Autoencoders", "Metric": "Accuracy", "Task": "Unsupervised_MNIST", "score": "94.73"}, {"Material": "MNIST", "Method": "PixelGAN_Autoencoders", "Metric": "Accuracy", "Task": "Unsupervised_image_classification", "score": "94.73"}]}
{"doc_id": "11356cd6bb0f2776a88cd584ff108470414c6594", "arxiv_id": "1706.01307", "title": "Submanifold Sparse Convolutional Networks", "n_ary_relations": [{"Material": "ShapeNet-Part", "Method": "SSCN", "Metric": "Instance_Average_IoU", "Task": "3D_Part_Segmentation", "score": "86.0"}]}
{"doc_id": "11da0c54ba904a1cb31a09d10da55f73e8825c61", "arxiv_id": "1512.08422", "title": "Natural Language Inference by Tree-Based Convolution and Heuristic Matching", "n_ary_relations": [{"Material": "SNLI", "Method": "300D_Tree-based_CNN_encoders", "Metric": "__Test_Accuracy", "Task": "Natural_Language_Inference", "score": "82.1"}, {"Material": "SNLI", "Method": "300D_Tree-based_CNN_encoders", "Metric": "__Train_Accuracy", "Task": "Natural_Language_Inference", "score": "83.3"}, {"Material": "SNLI", "Method": "300D_Tree-based_CNN_encoders", "Metric": "Parameters", "Task": "Natural_Language_Inference", "score": "3.5m"}]}
{"doc_id": "1235dd37312cb20aced0e97d953f6379d8a0c7d4", "arxiv_id": "1806.05645", "title": "Grounded Textual Entailment", "n_ary_relations": [{"Material": "V-SNLI", "Method": "BiMPM", "Metric": "Accuracy", "Task": "Natural_Language_Inference", "score": "86.41"}, {"Material": "V-SNLI", "Method": "V-BiMPM", "Metric": "Accuracy", "Task": "Natural_Language_Inference", "score": "86.99"}]}
{"doc_id": "14318685b5959b51d0f1e3db34643eb2855dc6d9", "arxiv_id": "1409.4842", "title": "Going deeper with convolutions", "n_ary_relations": [{"Material": "ImageNet", "Method": "Inception_V1", "Metric": "Top_1_Accuracy", "Task": "Image_Classification", "score": "69.8%"}, {"Material": "ImageNet", "Method": "Inception_V1", "Metric": "Top_5_Accuracy", "Task": "Image_Classification", "score": "89.9%"}, {"Material": "ImageNet_Detection", "Method": "Inception_V1", "Metric": "MAP", "Task": "Object_Detection", "score": "43.9%"}]}
{"doc_id": "16051bbe3a7f7c77a952ebf76722ea655e8906ca", "arxiv_id": "1712.05248", "title": "Image Super-resolution via Feature-augmented Random Forest", "n_ary_relations": [{"Material": "BSD100_-_4x_upscaling", "Method": "FAFR_", "Metric": "PSNR", "Task": "Image_Super-Resolution", "score": "26.91"}, {"Material": "Set14_-_4x_upscaling", "Method": "FAFR_", "Metric": "PSNR", "Task": "Image_Super-Resolution", "score": "27.48"}, {"Material": "Set5_-_4x_upscaling", "Method": "FARF_", "Metric": "PSNR", "Task": "Image_Super-Resolution", "score": "30.45"}]}
{"doc_id": "160563abbd75265b19afc8b4169bab9e1eb33d97", "arxiv_id": "1812.10464", "title": "Massively Multilingual Sentence Embeddings for Zero-Shot Cross-Lingual Transfer and Beyond", "n_ary_relations": [{"Material": "BUCC_French-to-English", "Method": "Massively_Multilingual_Sentence_Embeddings", "Metric": "F1_score", "Task": "Cross-Lingual_Bitext_Mining", "score": "93.91"}, {"Material": "BUCC_German-to-English", "Method": "Massively_Multilingual_Sentence_Embeddings", "Metric": "F1_score", "Task": "Cross-Lingual_Bitext_Mining", "score": "96.19"}, {"Material": "MLDoc_Zero-Shot_English-to-French", "Method": "Massively_Multilingual_Sentence_Embeddings", "Metric": "Accuracy", "Task": "Cross-Lingual_Document_Classification", "score": "77.95%"}, {"Material": "MLDoc_Zero-Shot_English-to-German", "Method": "Massively_Multilingual_Sentence_Embeddings", "Metric": "Accuracy", "Task": "Cross-Lingual_Document_Classification", "score": "84.78%"}, {"Material": "MLDoc_Zero-Shot_English-to-Spanish", "Method": "Massively_Multilingual_Sentence_Embeddings", "Metric": "Accuracy", "Task": "Cross-Lingual_Document_Classification", "score": "77.33%"}, {"Material": "XNLI_Zero-Shot_English-to-French", "Method": "BiLSTM", "Metric": "Accuracy", "Task": "Cross-Lingual_Natural_Language_Inference", "score": "71.9%"}, {"Material": "XNLI_Zero-Shot_English-to-German", "Method": "BiLSTM", "Metric": "Accuracy", "Task": "Cross-Lingual_Natural_Language_Inference", "score": "72.6%"}, {"Material": "XNLI_Zero-Shot_English-to-Spanish", "Method": "BiLSTM", "Metric": "Accuracy", "Task": "Cross-Lingual_Natural_Language_Inference", "score": "72.9%"}]}
{"doc_id": "175f74a09241b6cb5101a2a09978095720db7d5f", "arxiv_id": "1805.02704", "title": "Image Super-Resolution via Dual-State Recurrent Networks", "n_ary_relations": [{"Material": "BSD100_-_4x_upscaling", "Method": "DSRN", "Metric": "PSNR", "Task": "Image_Super-Resolution", "score": "27.25"}, {"Material": "BSD100_-_4x_upscaling", "Method": "DSRN", "Metric": "SSIM", "Task": "Image_Super-Resolution", "score": "0.724"}, {"Material": "Set14_-_4x_upscaling", "Method": "DSRN", "Metric": "PSNR", "Task": "Image_Super-Resolution", "score": "28.07"}, {"Material": "Set14_-_4x_upscaling", "Method": "DSRN", "Metric": "SSIM", "Task": "Image_Super-Resolution", "score": "0.770"}, {"Material": "Set5_-_4x_upscaling", "Method": "DSRN", "Metric": "PSNR", "Task": "Image_Super-Resolution", "score": "31.40"}, {"Material": "Set5_-_4x_upscaling", "Method": "DSRN", "Metric": "SSIM", "Task": "Image_Super-Resolution", "score": "0.883"}, {"Material": "Urban100_-_4x_upscaling", "Method": "DSRN", "Metric": "PSNR", "Task": "Image_Super-Resolution", "score": "25.08"}, {"Material": "Urban100_-_4x_upscaling", "Method": "DSRN", "Metric": "SSIM", "Task": "Image_Super-Resolution", "score": "0.747"}]}
{"doc_id": "1778e32c18bd611169e64c1805a51abff341ca53", "arxiv_id": "1709.04348", "title": "Natural Language Inference over Interaction Space", "n_ary_relations": [{"Material": "Quora_Question_Pairs", "Method": "DIIN", "Metric": "Accuracy", "Task": "Paraphrase_Identification", "score": "89.06"}, {"Material": "SNLI", "Method": "448D_Densely_Interactive_Inference_Network__DIIN__code_", "Metric": "__Test_Accuracy", "Task": "Natural_Language_Inference", "score": "88.0"}, {"Material": "SNLI", "Method": "448D_Densely_Interactive_Inference_Network__DIIN__code__Ensemble", "Metric": "__Test_Accuracy", "Task": "Natural_Language_Inference", "score": "88.9"}, {"Material": "SNLI", "Method": "448D_Densely_Interactive_Inference_Network__DIIN__code_", "Metric": "__Train_Accuracy", "Task": "Natural_Language_Inference", "score": "91.2"}, {"Material": "SNLI", "Method": "448D_Densely_Interactive_Inference_Network__DIIN__code__Ensemble", "Metric": "__Train_Accuracy", "Task": "Natural_Language_Inference", "score": "92.3"}, {"Material": "SNLI", "Method": "448D_Densely_Interactive_Inference_Network__DIIN__code_", "Metric": "Parameters", "Task": "Natural_Language_Inference", "score": "4.4m"}, {"Material": "SNLI", "Method": "448D_Densely_Interactive_Inference_Network__DIIN__code__Ensemble", "Metric": "Parameters", "Task": "Natural_Language_Inference", "score": "17m"}]}
{"doc_id": "178275dbdcfa267e41a9d5efe386ee5874c6d23f", "arxiv_id": "1711.00066", "title": "Fraternal Dropout", "n_ary_relations": [{"Material": "Penn_Treebank__Word_Level_", "Method": "AWD-LSTM_3-layer_with_Fraternal_dropout", "Metric": "Params", "Task": "Language_Modelling", "score": "24M"}, {"Material": "Penn_Treebank__Word_Level_", "Method": "AWD-LSTM_3-layer_with_Fraternal_dropout", "Metric": "Test_perplexity", "Task": "Language_Modelling", "score": "56.8"}, {"Material": "Penn_Treebank__Word_Level_", "Method": "AWD-LSTM_3-layer_with_Fraternal_dropout", "Metric": "Validation_perplexity", "Task": "Language_Modelling", "score": "58.9"}, {"Material": "WikiText-2", "Method": "AWD-LSTM_3-layer_with_Fraternal_dropout", "Metric": "Number_of_params", "Task": "Language_Modelling", "score": "34M"}, {"Material": "WikiText-2", "Method": "AWD-LSTM_3-layer_with_Fraternal_dropout", "Metric": "Test_perplexity", "Task": "Language_Modelling", "score": "64.1"}, {"Material": "WikiText-2", "Method": "AWD-LSTM_3-layer_with_Fraternal_dropout", "Metric": "Validation_perplexity", "Task": "Language_Modelling", "score": "66.8"}]}
{"doc_id": "178631e0f0e624b1607c7a7a2507ed30d4e83a42", "arxiv_id": "1303.5778", "title": "Speech recognition with deep recurrent neural networks", "n_ary_relations": [{"Material": "TIMIT", "Method": "Bi-LSTM___skip_connections_w__CTC", "Metric": "Percentage_error", "Task": "Speech_Recognition", "score": 17.7}]}
{"doc_id": "18168aea48a22f6fe2fe407c0ff70083cba225a7", "arxiv_id": "", "title": "Image Restoration Using Very Deep Convolutional Encoder-Decoder Networks with Symmetric Skip Connections", "n_ary_relations": [{"Material": "BSD100_-_4x_upscaling", "Method": "RED30", "Metric": "PSNR", "Task": "Image_Super-Resolution", "score": "27.40"}, {"Material": "BSD100_-_4x_upscaling", "Method": "RED30", "Metric": "SSIM", "Task": "Image_Super-Resolution", "score": "0.7290"}, {"Material": "Set5_-_4x_upscaling", "Method": "RED30", "Metric": "PSNR", "Task": "Image_Super-Resolution", "score": "31.51"}, {"Material": "Set5_-_4x_upscaling", "Method": "RED30", "Metric": "SSIM", "Task": "Image_Super-Resolution", "score": "0.8869"}]}
{"doc_id": "193089d56758ab88391d846edd08d359b1f9a863", "arxiv_id": "1611.05666", "title": "A Discriminatively Learned CNN Embedding for Person Reidentification", "n_ary_relations": [{"Material": "Market-1501", "Method": "DLCE", "Metric": "MAP", "Task": "Person_Re-Identification", "score": "59.9"}, {"Material": "Market-1501", "Method": "DLCE", "Metric": "Rank-1", "Task": "Person_Re-Identification", "score": "79.5"}]}
{"doc_id": "193b518bc3025804c6d587c74cbc154d91478417", "arxiv_id": "1802.10349", "title": "Learning to Adapt Structured Output Space for Semantic Segmentation", "n_ary_relations": [{"Material": "GTAV-to-Cityscapes_Labels", "Method": "Single-level_Adaptation", "Metric": "mIoU", "Task": "Synthetic-to-Real_Translation", "score": "41.4"}]}
{"doc_id": "1d0dcb458aa4d30b51f7c74b159be687f39120a0", "arxiv_id": "1709.08325", "title": "Pose-Driven Deep Convolutional Model for Person Re-identification", "n_ary_relations": [{"Material": "Market-1501", "Method": "PDF", "Metric": "MAP", "Task": "Person_Re-Identification", "score": "63.41"}, {"Material": "Market-1501", "Method": "PDF", "Metric": "Rank-1", "Task": "Person_Re-Identification", "score": "84.14"}]}
{"doc_id": "1f08598381af9146d0fd9a61b30d0e51a7331689", "arxiv_id": "", "title": "Learner Network Replay Experiences Sampled experience Updated priorities Initial priorities Generated experience Network parameters Actor Environment Network", "n_ary_relations": [{"Material": "Atari-57", "Method": "Ape-X", "Metric": "Medium_Human-Normalized_Score", "Task": "Atari_Games", "score": "434.1%"}]}
{"doc_id": "2138a7127429d67746ec78de46d6820fee0e548e", "arxiv_id": "1804.00823", "title": "Graph2Seq: Graph to Sequence Learning with Attention-based Neural Networks", "n_ary_relations": [{"Material": "WikiSQL", "Method": "Graph2Seq-PGE", "Metric": "BLEU-4", "Task": "SQL-to-Text", "score": "38.97"}]}
{"doc_id": "21a1654b856cf0c64e60e58258669b374cb05539", "arxiv_id": "1506.02640", "title": "You Only Look Once: Unified, Real-Time Object Detection", "n_ary_relations": [{"Material": "PASCAL_VOC_2007", "Method": "YOLO", "Metric": "FPS", "Task": "Real-Time_Object_Detection", "score": "46"}, {"Material": "PASCAL_VOC_2007", "Method": "YOLO", "Metric": "MAP", "Task": "Object_Detection", "score": "63.4%"}, {"Material": "PASCAL_VOC_2007", "Method": "YOLO", "Metric": "MAP", "Task": "Real-Time_Object_Detection", "score": "63.4%"}]}
{"doc_id": "232b43584b2236669c0a53702ad89ab10c3886ea", "arxiv_id": "", "title": "Implicit Quantile Networks for Distributional Reinforcement Learning", "n_ary_relations": [{"Material": "Atari_2600_Alien", "Method": "IQN", "Metric": "Score", "Task": "Atari_Games", "score": "7022"}, {"Material": "Atari_2600_Amidar", "Method": "IQN", "Metric": "Score", "Task": "Atari_Games", "score": "2946"}, {"Material": "Atari_2600_Assault", "Method": "IQN", "Metric": "Score", "Task": "Atari_Games", "score": "29091"}, {"Material": "Atari_2600_Asterix", "Method": "IQN", "Metric": "Score", "Task": "Atari_Games", "score": "342016"}, {"Material": "Atari_2600_Asteroids", "Method": "IQN", "Metric": "Score", "Task": "Atari_Games", "score": "2898"}, {"Material": "Atari_2600_Atlantis", "Method": "IQN", "Metric": "Score", "Task": "Atari_Games", "score": "978200"}, {"Material": "Atari_2600_Bank_Heist", "Method": "IQN", "Metric": "Score", "Task": "Atari_Games", "score": "1416"}, {"Material": "Atari_2600_Battle_Zone", "Method": "IQN", "Metric": "Score", "Task": "Atari_Games", "score": "42244"}, {"Material": "Atari_2600_Beam_Rider", "Method": "IQN", "Metric": "Score", "Task": "Atari_Games", "score": "42776"}, {"Material": "Atari_2600_Berzerk", "Method": "IQN", "Metric": "Score", "Task": "Atari_Games", "score": "1053"}, {"Material": "Atari_2600_Bowling", "Method": "IQN", "Metric": "Score", "Task": "Atari_Games", "score": "86.5"}, {"Material": "Atari_2600_Boxing", "Method": "IQN", "Metric": "Score", "Task": "Atari_Games", "score": "99.8"}, {"Material": "Atari_2600_Breakout", "Method": "IQN", "Metric": "Score", "Task": "Atari_Games", "score": "734"}, {"Material": "Atari_2600_Centipede", "Method": "IQN", "Metric": "Score", "Task": "Atari_Games", "score": "11561"}, {"Material": "Atari_2600_Chopper_Command", "Method": "IQN", "Metric": "Score", "Task": "Atari_Games", "score": "16836"}, {"Material": "Atari_2600_Crazy_Climber", "Method": "IQN", "Metric": "Score", "Task": "Atari_Games", "score": "179082"}, {"Material": "Atari_2600_Defender", "Method": "IQN", "Metric": "Score", "Task": "Atari_Games", "score": "53537"}, {"Material": "Atari_2600_Demon_Attack", "Method": "IQN", "Metric": "Score", "Task": "Atari_Games", "score": "128580"}, {"Material": "Atari_2600_Double_Dunk", "Method": "IQN", "Metric": "Score", "Task": "Atari_Games", "score": "5.6"}, {"Material": "Atari_2600_Enduro", "Method": "IQN", "Metric": "Score", "Task": "Atari_Games", "score": "2359"}, {"Material": "Atari_2600_Fishing_Derby", "Method": "IQN", "Metric": "Score", "Task": "Atari_Games", "score": "33.8"}, {"Material": "Atari_2600_Freeway", "Method": "IQN", "Metric": "Score", "Task": "Atari_Games", "score": "34.0"}, {"Material": "Atari_2600_Frostbite", "Method": "IQN", "Metric": "Score", "Task": "Atari_Games", "score": "4324"}, {"Material": "Atari_2600_Gopher", "Method": "IQN", "Metric": "Score", "Task": "Atari_Games", "score": "118365"}, {"Material": "Atari_2600_Gravitar", "Method": "IQN", "Metric": "Score", "Task": "Atari_Games", "score": "911"}, {"Material": "Atari_2600_HERO", "Method": "IQN", "Metric": "Score", "Task": "Atari_Games", "score": "28386"}, {"Material": "Atari_2600_Ice_Hockey", "Method": "IQN", "Metric": "Score", "Task": "Atari_Games", "score": "0.2"}, {"Material": "Atari_2600_James_Bond", "Method": "IQN", "Metric": "Score", "Task": "Atari_Games", "score": "35108"}, {"Material": "Atari_2600_Kangaroo", "Method": "IQN", "Metric": "Score", "Task": "Atari_Games", "score": "15487"}, {"Material": "Atari_2600_Krull", "Method": "IQN", "Metric": "Score", "Task": "Atari_Games", "score": "10707"}, {"Material": "Atari_2600_Kung-Fu_Master", "Method": "IQN", "Metric": "Score", "Task": "Atari_Games", "score": "73512"}, {"Material": "Atari_2600_Montezuma_s_Revenge", "Method": "IQN", "Metric": "Score", "Task": "Atari_Games", "score": "0.0"}, {"Material": "Atari_2600_Ms__Pacman", "Method": "IQN", "Metric": "Score", "Task": "Atari_Games", "score": "6349"}, {"Material": "Atari_2600_Name_This_Game", "Method": "IQN", "Metric": "Score", "Task": "Atari_Games", "score": "22682"}, {"Material": "Atari_2600_Phoenix", "Method": "IQN", "Metric": "Score", "Task": "Atari_Games", "score": "56599"}, {"Material": "Atari_2600_Pitfall_", "Method": "IQN", "Metric": "Score", "Task": "Atari_Games", "score": "0"}, {"Material": "Atari_2600_Pong", "Method": "IQN", "Metric": "Score", "Task": "Atari_Games", "score": "21.0"}, {"Material": "Atari_2600_Private_Eye", "Method": "IQN", "Metric": "Score", "Task": "Atari_Games", "score": "200"}, {"Material": "Atari_2600_Q_Bert", "Method": "IQN", "Metric": "Score", "Task": "Atari_Games", "score": "25750"}, {"Material": "Atari_2600_River_Raid", "Method": "IQN", "Metric": "Score", "Task": "Atari_Games", "score": "17765"}, {"Material": "Atari_2600_Road_Runner", "Method": "IQN", "Metric": "Score", "Task": "Atari_Games", "score": "57900"}, {"Material": "Atari_2600_Robotank", "Method": "IQN", "Metric": "Score", "Task": "Atari_Games", "score": "62.5"}, {"Material": "Atari_2600_Seaquest", "Method": "IQN", "Metric": "Score", "Task": "Atari_Games", "score": "30140"}, {"Material": "Atari_2600_Skiing", "Method": "IQN", "Metric": "Score", "Task": "Atari_Games", "score": "-9289"}, {"Material": "Atari_2600_Solaris", "Method": "IQN", "Metric": "Score", "Task": "Atari_Games", "score": "8007"}, {"Material": "Atari_2600_Space_Invaders", "Method": "IQN", "Metric": "Score", "Task": "Atari_Games", "score": "28888"}, {"Material": "Atari_2600_Star_Gunner", "Method": "IQN", "Metric": "Score", "Task": "Atari_Games", "score": "74677"}, {"Material": "Atari_2600_Surround", "Method": "IQN", "Metric": "Score", "Task": "Atari_Games", "score": "9.4"}, {"Material": "Atari_2600_Tennis", "Method": "IQN", "Metric": "Score", "Task": "Atari_Games", "score": "23.6"}, {"Material": "Atari_2600_Time_Pilot", "Method": "IQN", "Metric": "Score", "Task": "Atari_Games", "score": "12236"}, {"Material": "Atari_2600_Tutankham", "Method": "IQN", "Metric": "Score", "Task": "Atari_Games", "score": "293"}, {"Material": "Atari_2600_Up_and_Down", "Method": "IQN", "Metric": "Score", "Task": "Atari_Games", "score": "88148"}, {"Material": "Atari_2600_Venture", "Method": "IQN", "Metric": "Score", "Task": "Atari_Games", "score": "1318"}, {"Material": "Atari_2600_Video_Pinball", "Method": "IQN", "Metric": "Score", "Task": "Atari_Games", "score": "698045"}, {"Material": "Atari_2600_Wizard_of_Wor", "Method": "IQN", "Metric": "Score", "Task": "Atari_Games", "score": "31190"}, {"Material": "Atari_2600_Yars_Revenge", "Method": "IQN", "Metric": "Score", "Task": "Atari_Games", "score": "28379"}, {"Material": "Atari_2600_Zaxxon", "Method": "IQN", "Metric": "Score", "Task": "Atari_Games", "score": "21772"}]}
{"doc_id": "23d2d3a6ffebfecaa8930307fdcf451c147757c8", "arxiv_id": "1609.05473", "title": "SeqGAN: Sequence Generative Adversarial Nets with Policy Gradient", "n_ary_relations": [{"Material": "COCO_Captions", "Method": "SeqGAN", "Metric": "BLEU-2", "Task": "Text_Generation", "score": "0.831"}, {"Material": "COCO_Captions", "Method": "SeqGAN", "Metric": "BLEU-3", "Task": "Text_Generation", "score": "0.642"}, {"Material": "COCO_Captions", "Method": "SeqGAN", "Metric": "BLEU-4", "Task": "Text_Generation", "score": "0.521"}, {"Material": "COCO_Captions", "Method": "SeqGAN", "Metric": "BLEU-5", "Task": "Text_Generation", "score": "0.427"}, {"Material": "Chinese_Poems", "Method": "SeqGAN", "Metric": "BLEU-2", "Task": "Text_Generation", "score": "0.738"}, {"Material": "EMNLP2017_WMT", "Method": "SeqGAN", "Metric": "BLEU-2", "Task": "Text_Generation", "score": "0.859"}, {"Material": "EMNLP2017_WMT", "Method": "SeqGAN", "Metric": "BLEU-3", "Task": "Text_Generation", "score": "0.6015"}, {"Material": "EMNLP2017_WMT", "Method": "SeqGAN", "Metric": "BLEU-4", "Task": "Text_Generation", "score": "0.4541"}, {"Material": "EMNLP2017_WMT", "Method": "SeqGAN", "Metric": "BLEU-5", "Task": "Text_Generation", "score": "0.4498"}]}
{"doc_id": "24730424236724d3f798dec02901e7a1f1c4710e", "arxiv_id": "1708.09200", "title": "Joint maximum purity forest with application to image super-resolution", "n_ary_relations": [{"Material": "BSD100_-_4x_upscaling", "Method": "JMPF_", "Metric": "PSNR", "Task": "Image_Super-Resolution", "score": "26.87"}, {"Material": "Set14_-_4x_upscaling", "Method": "JMPF_", "Metric": "PSNR", "Task": "Image_Super-Resolution", "score": "27.37"}, {"Material": "Set5_-_4x_upscaling", "Method": "JMPF_", "Metric": "PSNR", "Task": "Image_Super-Resolution", "score": "30.24"}]}
{"doc_id": "249b3b7421d3cdb932eecfe4b67203e0e46806b2", "arxiv_id": "1809.02279", "title": "Cell-aware Stacked LSTMs for Modeling Sentences", "n_ary_relations": [{"Material": "Quora_Question_Pairs", "Method": "Bi-CAS-LSTM", "Metric": "Accuracy", "Task": "Paraphrase_Identification", "score": "88.6"}, {"Material": "SNLI", "Method": "300D_2-layer_Bi-CAS-LSTM", "Metric": "__Test_Accuracy", "Task": "Natural_Language_Inference", "score": "87"}, {"Material": "SST-2_Binary_classification", "Method": "Bi-CAS-LSTM", "Metric": "Accuracy", "Task": "Sentiment_Analysis", "score": "91.3"}, {"Material": "SST-5_Fine-grained_classification", "Method": "Bi-CAS-LSTM", "Metric": "Accuracy", "Task": "Sentiment_Analysis", "score": "53.6"}]}
{"doc_id": "25a784f7f8c94c42821ee078587fc38dffcd00a4", "arxiv_id": "1811.11662", "title": "Robust Face Detection via Learning Small Faces on Hard Images", "n_ary_relations": [{"Material": "Annotated_Faces_in_the_Wild", "Method": "Anchor-based", "Metric": "AP", "Task": "Face_Detection", "score": "0.9960"}, {"Material": "FDDB", "Method": "Anchor-based", "Metric": "AP", "Task": "Face_Detection", "score": "0.987"}, {"Material": "PASCAL_Face", "Method": "Anchor-based", "Metric": "AP", "Task": "Face_Detection", "score": "0.990"}, {"Material": "WIDER_Face__Hard_", "Method": "Anchor-based", "Metric": "AP", "Task": "Face_Detection", "score": "0.889"}]}
{"doc_id": "25f5df29342a04936ba0d308b4d1b8245a7e8f5c", "arxiv_id": "1602.00134", "title": "Convolutional Pose Machines", "n_ary_relations": [{"Material": "FLIC_Elbows", "Method": "Convolutional_Pose_Machines", "Metric": "PCK_0_2", "Task": "Pose_Estimation", "score": "97.59%"}, {"Material": "FLIC_Wrists", "Method": "Convolutional_Pose_Machines", "Metric": "PCK_0_2", "Task": "Pose_Estimation", "score": " 95.03%"}, {"Material": "Leeds_Sports_Poses", "Method": "Convolutional_Pose_Machines", "Metric": "PCK", "Task": "Pose_Estimation", "score": "90.5%"}, {"Material": "MPII_Human_Pose", "Method": "Convolutional_Pose_Machines", "Metric": "PCKh-0_5", "Task": "Pose_Estimation", "score": "88.52%"}]}
{"doc_id": "269730dbbabed8b8b5ba720e44a4c31b1f51e8f1", "arxiv_id": "", "title": "Query-Reduction Networks for Question Answering", "n_ary_relations": [{"Material": "bAbi", "Method": "QRN", "Metric": "Accuracy__trained_on_10k_", "Task": "Question_Answering", "score": "99.7%"}, {"Material": "bAbi", "Method": "QRN", "Metric": "Accuracy__trained_on_1k_", "Task": "Question_Answering", "score": "90.1%"}, {"Material": "bAbi", "Method": "QRN", "Metric": "Mean_Error_Rate", "Task": "Question_Answering", "score": "0.3%"}]}
{"doc_id": "270e65acc071b9e4e2a632720130c0e10cb6fa08", "arxiv_id": "1607.04492", "title": "Neural Tree Indexers for Text Understanding", "n_ary_relations": [{"Material": "SNLI", "Method": "300D_Full_tree_matching_NTI-SLSTM-LSTM_w__global_attention", "Metric": "__Test_Accuracy", "Task": "Natural_Language_Inference", "score": "87.3"}, {"Material": "SNLI", "Method": "300D_NTI-SLSTM-LSTM_encoders", "Metric": "__Test_Accuracy", "Task": "Natural_Language_Inference", "score": "83.4"}, {"Material": "SNLI", "Method": "300D_Full_tree_matching_NTI-SLSTM-LSTM_w__global_attention", "Metric": "__Train_Accuracy", "Task": "Natural_Language_Inference", "score": "88.5"}, {"Material": "SNLI", "Method": "300D_NTI-SLSTM-LSTM_encoders", "Metric": "__Train_Accuracy", "Task": "Natural_Language_Inference", "score": "82.5"}, {"Material": "SNLI", "Method": "300D_Full_tree_matching_NTI-SLSTM-LSTM_w__global_attention", "Metric": "Parameters", "Task": "Natural_Language_Inference", "score": "3.2m"}, {"Material": "SNLI", "Method": "300D_NTI-SLSTM-LSTM_encoders", "Metric": "Parameters", "Task": "Natural_Language_Inference", "score": "4.0m"}]}
{"doc_id": "2777cd26b2c257843273fe41ad4c5b8cdf1b1b75", "arxiv_id": "1804.03287", "title": "Understanding Humans in Crowded Scenes: Deep Nested Adversarial Learning and A New Benchmark for Multi-Human Parsing", "n_ary_relations": [{"Material": "MHP_v1_0", "Method": "NAN", "Metric": "AP_0_5", "Task": "Multi-Human_Parsing", "score": "57.09%"}, {"Material": "MHP_v2_0", "Method": "NAN", "Metric": "AP_0_5", "Task": "Multi-Human_Parsing", "score": "25.14%"}, {"Material": "PASCAL-Person-Part", "Method": "NAN", "Metric": "AP_0_5", "Task": "Multi-Human_Parsing", "score": "59.70%"}]}
{"doc_id": "27a99c21a1324f087b2f144adc119f04137dfd87", "arxiv_id": "1412.7149", "title": "Deep Fried Convnets", "n_ary_relations": [{"Material": "MNIST", "Method": "Deep_Fried_Convnets", "Metric": "Percentage_error", "Task": "Image_Classification", "score": "0.7"}]}
{"doc_id": "27aa0f3ec934925265f93fac7ff1cd1d70ceb618", "arxiv_id": "1804.09530", "title": "Strong Baselines for Neural Semi-Supervised Learning under Domain Shift", "n_ary_relations": [{"Material": "Multi-Domain_Sentiment_Dataset", "Method": "Multi-task_tri-training", "Metric": "Average", "Task": "Sentiment_Analysis", "score": "79.15"}, {"Material": "Multi-Domain_Sentiment_Dataset", "Method": "Multi-task_tri-training", "Metric": "Books", "Task": "Sentiment_Analysis", "score": "74.86"}, {"Material": "Multi-Domain_Sentiment_Dataset", "Method": "Multi-task_tri-training", "Metric": "DVD", "Task": "Sentiment_Analysis", "score": "78.14"}, {"Material": "Multi-Domain_Sentiment_Dataset", "Method": "Multi-task_tri-training", "Metric": "Electronics", "Task": "Sentiment_Analysis", "score": "81.45"}, {"Material": "Multi-Domain_Sentiment_Dataset", "Method": "Multi-task_tri-training", "Metric": "Kitchen", "Task": "Sentiment_Analysis", "score": "82.14"}]}
{"doc_id": "2a86bcdfb1d817ddb76ba202319f8267a36c0f62", "arxiv_id": "1807.03342", "title": "PCL: Proposal Cluster Learning for Weakly Supervised Object Detection", "n_ary_relations": [{"Material": "ImageNet", "Method": "PCL-OB-G-Ens___FRCNN", "Metric": "MAP", "Task": "Weakly_Supervised_Object_Detection", "score": "19.6"}, {"Material": "PASCAL_VOC_2007", "Method": "PCL-OB-G-Ens___FRCNN", "Metric": "MAP", "Task": "Weakly_Supervised_Object_Detection", "score": "48.8"}, {"Material": "PASCAL_VOC_2012", "Method": "PCL-OB-G-Ens___FRCNN", "Metric": "MAP", "Task": "Weakly_Supervised_Object_Detection", "score": "44.2"}]}
{"doc_id": "2f04ba0f74df046b0080ca78e56898bd4847898b", "arxiv_id": "1407.4023", "title": "Aggregate channel features for multi-view face detection", "n_ary_relations": [{"Material": "WIDER_Face__Easy_", "Method": "ACF-WIDER", "Metric": "AP", "Task": "Face_Detection", "score": "0.695"}, {"Material": "WIDER_Face__Hard_", "Method": "ACF-WIDER", "Metric": "AP", "Task": "Face_Detection", "score": "0.290"}, {"Material": "WIDER_Face__Medium_", "Method": "ACF-WIDER", "Metric": "AP", "Task": "Face_Detection", "score": "0.588"}]}
{"doc_id": "2f56b1ac5b9faac9527b6814778925e9242cf5fd", "arxiv_id": "1604.03540", "title": "Training Region-Based Object Detectors with Online Hard Example Mining", "n_ary_relations": [{"Material": "PASCAL_VOC_2007", "Method": "OHEM", "Metric": "MAP", "Task": "Object_Detection", "score": "78.9%"}]}
{"doc_id": "2f97ee95cad6a1f13596b108072b846c6f747d4e", "arxiv_id": "1609.03528", "title": "The microsoft 2016 conversational speech recognition system", "n_ary_relations": [{"Material": "Switchboard___Hub500", "Method": "Microsoft_2016", "Metric": "Percentage_error", "Task": "Speech_Recognition", "score": 6.2}, {"Material": "Switchboard___Hub500", "Method": "RNNLM", "Metric": "Percentage_error", "Task": "Speech_Recognition", "score": 6.9}, {"Material": "Switchboard___Hub500", "Method": "VGG_Resnet_LACE_BiLSTM_acoustic_model_trained_on_SWB_Fisher_CH__N-gram___RNNLM_language_model_trained_on_Switchboard_Fisher_Gigaword_Broadcast", "Metric": "Percentage_error", "Task": "Speech_Recognition", "score": 6.3}, {"Material": "swb_hub_500_WER_fullSWBCH", "Method": "VGG_Resnet_LACE_BiLSTM_acoustic_model_trained_on_SWB_Fisher_CH__N-gram___RNNLM_language_model_trained_on_Switchboard_Fisher_Gigaword_Broadcast", "Metric": "Percentage_error", "Task": "Speech_Recognition", "score": 11.9}]}
{"doc_id": "322a7dad274f440a92548faa8f2b2be666b2d01f", "arxiv_id": "1612.01105", "title": "Pyramid Scene Parsing Network", "n_ary_relations": [{"Material": "ADE20K", "Method": "PSPNet", "Metric": "Test_Score", "Task": "Semantic_Segmentation", "score": "0.5538"}, {"Material": "ADE20K", "Method": "PSPNet", "Metric": "Validation_mIoU", "Task": "Semantic_Segmentation", "score": "44.94"}, {"Material": "CamVid", "Method": "PSPNet", "Metric": "Frame__fps_", "Task": "Real-Time_Semantic_Segmentation", "score": "5.4"}, {"Material": "CamVid", "Method": "PSPNet", "Metric": "Mean_IoU", "Task": "Semantic_Segmentation", "score": "69.1%"}, {"Material": "CamVid", "Method": "PSPNet", "Metric": "Time__ms_", "Task": "Real-Time_Semantic_Segmentation", "score": "185"}, {"Material": "CamVid", "Method": "PSPNet", "Metric": "mIoU", "Task": "Real-Time_Semantic_Segmentation", "score": "69.1%"}, {"Material": "Cityscapes", "Method": "PSPNet", "Metric": "Frame__fps_", "Task": "Real-Time_Semantic_Segmentation", "score": " 0.78"}, {"Material": "Cityscapes", "Method": "PSPNet", "Metric": "Mean_IoU", "Task": "Semantic_Segmentation", "score": "81.2%"}, {"Material": "Cityscapes", "Method": "PSPNet", "Metric": "Time__ms_", "Task": "Real-Time_Semantic_Segmentation", "score": "1288"}, {"Material": "Cityscapes", "Method": "PSPNet", "Metric": "mIoU", "Task": "Real-Time_Semantic_Segmentation", "score": "81.2%"}, {"Material": "PASCAL_VOC_2012", "Method": "PSPNet", "Metric": "Mean_IoU", "Task": "Semantic_Segmentation", "score": "85.4%"}]}
{"doc_id": "325af39d281d5903a269c01fab8f53d7400a4c49", "arxiv_id": "1612.01465", "title": "ArtTrack: Articulated Multi-Person Tracking in the Wild", "n_ary_relations": [{"Material": "MPII_Multi-Person", "Method": "Articulated_Tracking", "Metric": "AP", "Task": "Multi-Person_Pose_Estimation", "score": "74.3%"}]}
{"doc_id": "33261d252218007147a71e40f8367ed152fa2fe0", "arxiv_id": "1406.3676", "title": "Question Answering with Subgraph Embeddings", "n_ary_relations": [{"Material": "WebQuestions", "Method": "Subgraph_embeddings", "Metric": "F1", "Task": "Question_Answering", "score": "39.2%"}]}
{"doc_id": "3448e6a5039417dc1ae890efeca3bef5390ace7c", "arxiv_id": "1803.05170", "title": "xDeepFM: Combining Explicit and Implicit Feature Interactions for Recommender Systems", "n_ary_relations": [{"Material": "Bing_News", "Method": "xDeepFM", "Metric": "AUC", "Task": "Click-Through_Rate_Prediction", "score": "0.8400"}, {"Material": "Bing_News", "Method": "xDeepFM", "Metric": "Log_Loss", "Task": "Click-Through_Rate_Prediction", "score": "0.2649"}, {"Material": "Criteo", "Method": "xDeepFM", "Metric": "AUC", "Task": "Click-Through_Rate_Prediction", "score": "0.8052"}, {"Material": "Criteo", "Method": "xDeepFM", "Metric": "Log_Loss", "Task": "Click-Through_Rate_Prediction", "score": "0.4418"}, {"Material": "Dianping", "Method": "xDeepFM", "Metric": "AUC", "Task": "Click-Through_Rate_Prediction", "score": "0.8639"}, {"Material": "Dianping", "Method": "xDeepFM", "Metric": "Log_Loss", "Task": "Click-Through_Rate_Prediction", "score": "0.3156"}]}
{"doc_id": "35734e8724559fb0d494e5cba6a28ad7a3d5dd4d", "arxiv_id": "1412.6572", "title": "Explaining and Harnessing Adversarial Examples", "n_ary_relations": [{"Material": "MNIST", "Method": "Explaining_and_Harnessing_Adversarial_Examples", "Metric": "Percentage_error", "Task": "Image_Classification", "score": "0.8"}]}
{"doc_id": "364c1a3df58d87cb40ab33fdf3831cf2862f3570", "arxiv_id": "1801.01641", "title": "aNMM: Ranking Short Answer Texts with Attention-Based Neural Matching Model", "n_ary_relations": [{"Material": "TrecQA", "Method": "aNMM", "Metric": "MAP", "Task": "Question_Answering", "score": "0.750"}, {"Material": "TrecQA", "Method": "aNMM", "Metric": "MRR", "Task": "Question_Answering", "score": "0.811"}]}
{"doc_id": "3842ee1e0fdfeff936b5c49973ff21adfaaf3929", "arxiv_id": "1702.05464", "title": "Adversarial Discriminative Domain Adaptation", "n_ary_relations": [{"Material": "SVNH-to-MNIST", "Method": "ADDA", "Metric": "Classification_Accuracy", "Task": "Unsupervised_Image-To-Image_Translation", "score": "76.0%"}]}
{"doc_id": "38cc89399dd6f5aaab1654f27ab3c9eeade12a36", "arxiv_id": "1711.08585", "title": "Exploiting Temporal Information for 3D Human Pose Estimation", "n_ary_relations": [{"Material": "Human3_6M", "Method": "Sequence-to-sequence_network_", "Metric": "Average_3D_Error", "Task": "3D_Human_Pose_Estimation", "score": "66.1"}]}
{"doc_id": "38e2f851b705faa0d0a698ed9885bd6834440073", "arxiv_id": "1806.02817", "title": "Probabilistic Model-Agnostic Meta-Learning", "n_ary_relations": [{"Material": "Mini-ImageNet_-_1-Shot_Learning", "Method": "PLATIPUS", "Metric": "Accuracy", "Task": "Few-Shot_Image_Classification", "score": "50.13%"}]}
{"doc_id": "3aa21de1a7c97e0458e10ed5730ce160bb436caa", "arxiv_id": "1804.01654", "title": "Pixel2Mesh: Generating 3D Mesh Models from Single RGB Images", "n_ary_relations": [{"Material": "Data3D_R2N2", "Method": "Pixel2Mesh", "Metric": "Avg_F1", "Task": "3D_Object_Reconstruction", "score": "59.72"}]}
{"doc_id": "3acc07f7f8951617276cf99483ed02aeb0a6eeac", "arxiv_id": "", "title": "Domain Adaptation for Semantic Segmentation of Urban Scenes", "n_ary_relations": [{"Material": "GTAV-to-Cityscapes_Labels", "Method": "CDA", "Metric": "mIoU", "Task": "Synthetic-to-Real_Translation", "score": "28.9"}]}
{"doc_id": "3ca3993b1f3536b15112f759067f62e999c5d38f", "arxiv_id": "1703.10896", "title": "BB8: A Scalable, Accurate, Robust to Partial Occlusion Method for Predicting the 3D Poses of Challenging Objects without Using Depth", "n_ary_relations": [{"Material": "LineMOD", "Method": "BB8", "Metric": "Accuracy", "Task": "6D_Pose_Estimation", "score": "83.9%"}]}
{"doc_id": "3cf31ecb2724b5088783d7c96a5fc0d5604cbf41", "arxiv_id": "1603.04351", "title": "Simple and Accurate Dependency Parsing Using Bidirectional LSTM Feature Representations", "n_ary_relations": [{"Material": "Penn_Treebank", "Method": "BIST_graph-based_parser", "Metric": "LAS", "Task": "Dependency_Parsing", "score": "91.0"}, {"Material": "Penn_Treebank", "Method": "BIST_transition-based_parser", "Metric": "LAS", "Task": "Dependency_Parsing", "score": "91.9"}, {"Material": "Penn_Treebank", "Method": "BIST_graph-based_parser", "Metric": "POS", "Task": "Dependency_Parsing", "score": "97.3"}, {"Material": "Penn_Treebank", "Method": "BIST_transition-based_parser", "Metric": "POS", "Task": "Dependency_Parsing", "score": "97.3"}, {"Material": "Penn_Treebank", "Method": "BIST_graph-based_parser", "Metric": "UAS", "Task": "Dependency_Parsing", "score": "93.1"}, {"Material": "Penn_Treebank", "Method": "BIST_transition-based_parser", "Metric": "UAS", "Task": "Dependency_Parsing", "score": "93.9"}]}
{"doc_id": "3daa086acd367dc971a2dc1382caba2031294233", "arxiv_id": "1709.03612", "title": "Holistic, Instance-Level Human Parsing", "n_ary_relations": [{"Material": "PASCAL-Person-Part", "Method": "Holistic_instance-level", "Metric": "AP_0_5", "Task": "Multi-Human_Parsing", "score": "40.60%"}]}
{"doc_id": "408e8eecc14c5cc60bbdfc486ba7a7fc97031788", "arxiv_id": "1406.6909", "title": "Discriminative Unsupervised Feature Learning with Convolutional Neural Networks", "n_ary_relations": [{"Material": "CIFAR-10", "Method": "Discriminative_Unsupervised_Feature_Learning_with_Convolutional_Neural_Networks", "Metric": "Percentage_correct", "Task": "Image_Classification", "score": "82"}, {"Material": "STL-10", "Method": "Discriminative_Unsupervised_Feature_Learning_with_Convolutional_Neural_Networks", "Metric": "Percentage_correct", "Task": "Image_Classification", "score": 72.8}]}
{"doc_id": "4365eb43a635bc6431dfaf3af1f7bf7bf55522cc", "arxiv_id": "1708.02863", "title": "CoupleNet: Coupling Global Structure with Local Parts for Object Detection", "n_ary_relations": [{"Material": "PASCAL_VOC_2007", "Method": "CoupleNet", "Metric": "MAP", "Task": "Object_Detection", "score": "82.7%"}]}
{"doc_id": "436b07bebaa1d1f05ef85415e10374048d25334d", "arxiv_id": "1701.06538", "title": "Outrageously Large Neural Networks: The Sparsely-Gated Mixture-of-Experts Layer", "n_ary_relations": [{"Material": "One_Billion_Word", "Method": "High-Budget_MoE", "Metric": "Number_of_params", "Task": "Language_Modelling", "score": "5B"}, {"Material": "One_Billion_Word", "Method": "Low-Budget_MoE", "Metric": "Number_of_params", "Task": "Language_Modelling", "score": "5B"}, {"Material": "One_Billion_Word", "Method": "High-Budget_MoE", "Metric": "PPL", "Task": "Language_Modelling", "score": " 28.0"}, {"Material": "One_Billion_Word", "Method": "Low-Budget_MoE", "Metric": "PPL", "Task": "Language_Modelling", "score": "34.1"}, {"Material": "WMT2014_English-French", "Method": "MoE", "Metric": "BLEU_score", "Task": "Machine_Translation", "score": "40.56"}, {"Material": "WMT2014_English-German", "Method": "MoE", "Metric": "BLEU_score", "Task": "Machine_Translation", "score": "26.03"}]}
{"doc_id": "44078d0daed8b13114cffb15b368acc467f96351", "arxiv_id": "1604.05417", "title": "Triplet probabilistic embedding for face verification and clustering", "n_ary_relations": [{"Material": "IJB-A", "Method": "Triplet_probabilistic_embedding", "Metric": "TAR___FAR_0_01", "Task": "Face_Verification", "score": "90%"}]}
{"doc_id": "45429c281e30f9e87ebcd1ae42e0656d2ead24d1", "arxiv_id": "1711.11585", "title": "High-Resolution Image Synthesis and Semantic Manipulation with Conditional GANs", "n_ary_relations": [{"Material": "ADE20K_Labels-to-Photos", "Method": "pix2pixHD", "Metric": "Accuracy", "Task": "Image-to-Image_Translation", "score": "69.2%"}, {"Material": "ADE20K_Labels-to-Photos", "Method": "pix2pixHD", "Metric": "FID", "Task": "Image-to-Image_Translation", "score": "81.8"}, {"Material": "ADE20K_Labels-to-Photos", "Method": "pix2pixHD", "Metric": "mIoU", "Task": "Image-to-Image_Translation", "score": "20.3"}, {"Material": "ADE20K-Outdoor_Labels-to-Photos", "Method": "pix2pixHD", "Metric": "Accuracy", "Task": "Image-to-Image_Translation", "score": "71.6%"}, {"Material": "ADE20K-Outdoor_Labels-to-Photos", "Method": "pix2pixHD", "Metric": "FID", "Task": "Image-to-Image_Translation", "score": "97.8"}, {"Material": "ADE20K-Outdoor_Labels-to-Photos", "Method": "pix2pixHD", "Metric": "mIoU", "Task": "Image-to-Image_Translation", "score": "17.4"}, {"Material": "COCO-Stuff_Labels-to-Photos", "Method": "pix2pixHD", "Metric": "Accuracy", "Task": "Image-to-Image_Translation", "score": "45.8%"}, {"Material": "COCO-Stuff_Labels-to-Photos", "Method": "pix2pixHD", "Metric": "FID", "Task": "Image-to-Image_Translation", "score": "111.5"}, {"Material": "COCO-Stuff_Labels-to-Photos", "Method": "pix2pixHD", "Metric": "mIoU", "Task": "Image-to-Image_Translation", "score": "14.6"}, {"Material": "Cityscapes_Labels-to-Photo", "Method": "pix2pixHD", "Metric": "Class_IOU", "Task": "Image-to-Image_Translation", "score": ""}, {"Material": "Cityscapes_Labels-to-Photo", "Method": "pix2pixHD", "Metric": "FID", "Task": "Image-to-Image_Translation", "score": "95"}, {"Material": "Cityscapes_Labels-to-Photo", "Method": "pix2pixHD", "Metric": "Per-class_Accuracy", "Task": "Image-to-Image_Translation", "score": ""}, {"Material": "Cityscapes_Labels-to-Photo", "Method": "pix2pixHD", "Metric": "Per-pixel_Accuracy", "Task": "Image-to-Image_Translation", "score": "81.4%"}, {"Material": "Cityscapes_Labels-to-Photo", "Method": "pix2pixHD", "Metric": "mIoU", "Task": "Image-to-Image_Translation", "score": "58.3"}]}
{"doc_id": "455da02e5048dffb51fb6ab5eb8aeca5926c9d9a", "arxiv_id": "1406.4729", "title": "Spatial Pyramid Pooling in Deep Convolutional Networks for Visual Recognition", "n_ary_relations": [{"Material": "PASCAL_VOC_2007", "Method": "SPP__Overfeat-7_", "Metric": "MAP", "Task": "Object_Detection", "score": "82.44%"}]}
