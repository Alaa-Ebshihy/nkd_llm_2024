,Unnamed: 0,paper_1,paper_2,paper_1_id,paper_2_id,datasets_diff,approach_diff,similar_pairs_arxiv_ids,syn_datasets_diff,syn_approach_diff
0,0,wk_paper_1,wk_paper_2,11,12,"sent: Article 1 uses different datasets from the medical domain sourced mainly from PubMed, while Article 2 uses medical domain datasets sourced from different sources. sent: Article 1 uses 20 systematic review datasets, while Article 2 uses 23 systematic review datasets. ","sent: Article 1 and Article 2 use supervised learning approach. sent: Article 1 uses TF-IDF, log-linear model and LDA topic modelling for feature extraction, while Article 2 uses deep denoinsing encoder and feed forward neural networks for feature extraction. Article 1 and Article 2 uses SVM classification for systematic reviews for binary relevance.","[['1511.06038', '1503.03244'], ['1603.01547', '1503.03244'], ['1606.01549', '1503.03244'], ['1503.03244', '1606.01549'], ['1503.03244', '1603.01547'], ['1503.03244', '1511.06038'], ['1512.03385', '1612.03144'], ['1612.03144', '1512.03385']]","['sent: Article 1 uses multiple datasets:  WikiQA, and  QASent, while Article 2 uses SemEvalCQA dataset.', 'sent: Article 1 uses multiple datasets:  CNN   Daily Mail,  SearchQA, and  Children s Book Test, while Article 2 uses SemEvalCQA dataset.', 'sent: Article 1 uses multiple datasets:  CNN   Daily Mail,  Quasar, and  Children s Book Test, while Article 2 uses SemEvalCQA dataset.', 'sent: Article 1 uses SemEvalCQA dataset, while Article 2 uses multiple datasets:  CNN   Daily Mail,  Quasar, and  Children s Book Test.', 'sent: Article 1 uses SemEvalCQA dataset, while Article 2 uses multiple datasets:  CNN   Daily Mail,  SearchQA, and  Children s Book Test.', 'sent: Article 1 uses SemEvalCQA dataset, while Article 2 uses multiple datasets:  WikiQA, and  QASent.', 'sent: Article 1 and Article 2 use COCO dataset. sent: Article 1 uses multiple datasets:  CIFAR-10, and  PASCAL VOC 2007, while Article 2 does not use specific datasets for experiments.', 'sent: Article 1 and Article 2 use COCO dataset. sent: Article 1 does not use specific datasets for experiments, while Article 2 uses multiple datasets:  CIFAR-10, and  PASCAL VOC 2007.']","['sent: Article 1 uses LSTM approach for Question Answering, while Article 2 uses ARC-II for Question Answering. sent: Article 1 uses Attentive LSTM approach for Question Answering, while Article 2 uses ARC-II for Question Answering. sent: Article 1 uses LSTM  lexical overlap   dist output  approach for Question Answering, while Article 2 uses ARC-II for Question Answering.', 'sent: Article 1 uses ASR approach for Question Answering, while Article 2 uses ARC-II for Question Answering. sent: Article 1 uses AS reader  greedy  approach for Question Answering, while Article 2 uses ARC-II for Question Answering. sent: Article 1 uses AS Reader  single model  approach for Question Answering, while Article 2 uses ARC-II for Question Answering. sent: Article 1 uses AS reader  avg  approach for Question Answering, while Article 2 uses ARC-II for Question Answering. sent: Article 1 uses AS Reader  ensemble model  approach for Question Answering, while Article 2 uses ARC-II for Question Answering.', 'sent: Article 1 uses GA reader approach for Question Answering, while Article 2 uses ARC-II for Question Answering. sent: Article 1 uses NSE approach for Question Answering, while Article 2 uses ARC-II for Question Answering. sent: Article 1 uses GA   feature   fix L w  approach for Question Answering, while Article 2 uses ARC-II for Question Answering. sent: Article 1 uses GA Reader approach for Question Answering, while Article 2 uses ARC-II for Question Answering. sent: Article 1 uses GA approach for Question Answering, while Article 2 uses ARC-II for Question Answering.', 'sent: Article 1 uses ARC-II approach for Question Answering, while Article 2 uses GA reader for Question Answering. sent: Article 1 uses ARC-II approach for Question Answering, while Article 2 uses NSE for Question Answering. sent: Article 1 uses ARC-II approach for Question Answering, while Article 2 uses GA   feature   fix L w  for Question Answering. sent: Article 1 uses ARC-II approach for Question Answering, while Article 2 uses GA Reader for Question Answering. sent: Article 1 uses ARC-II approach for Question Answering, while Article 2 uses GA for Question Answering.', 'sent: Article 1 uses ARC-II approach for Question Answering, while Article 2 uses ASR for Question Answering. sent: Article 1 uses ARC-II approach for Question Answering, while Article 2 uses AS reader  greedy  for Question Answering. sent: Article 1 uses ARC-II approach for Question Answering, while Article 2 uses AS Reader  single model  for Question Answering. sent: Article 1 uses ARC-II approach for Question Answering, while Article 2 uses AS reader  avg  for Question Answering. sent: Article 1 uses ARC-II approach for Question Answering, while Article 2 uses AS Reader  ensemble model  for Question Answering.', 'sent: Article 1 uses ARC-II approach for Question Answering, while Article 2 uses LSTM for Question Answering. sent: Article 1 uses ARC-II approach for Question Answering, while Article 2 uses Attentive LSTM for Question Answering. sent: Article 1 uses ARC-II approach for Question Answering, while Article 2 uses LSTM  lexical overlap   dist output  for Question Answering.', 'sent: Article 1 uses ResNet-101 approach for Object Detection, while Article 2 uses Faster R-CNN   FPN for Object Detection. sent: Article 1 uses ResNet approach for Object Detection, while Article 2 uses Faster R-CNN   FPN for Object Detection. sent: Article 1 uses Faster R-CNN   box refinement   context   multi-scale testing approach for Object Detection, while Article 2 uses Faster R-CNN   FPN for Object Detection.', 'sent: Article 1 uses Faster R-CNN   FPN approach for Object Detection, while Article 2 uses ResNet-101 for Object Detection. sent: Article 1 uses Faster R-CNN   FPN approach for Object Detection, while Article 2 uses ResNet for Object Detection. sent: Article 1 uses Faster R-CNN   FPN approach for Object Detection, while Article 2 uses Faster R-CNN   box refinement   context   multi-scale testing for Object Detection.']"
1,1,wk_paper_1,wk_paper_3,11,13,sent: Article 1 and Article 2 uses different datasets from the medical domain sourced mainly from PubMed. sent: Article 1 and Article 2 uses 20 systematic review datasets.,"sent: Article 1 and Article 2 use supervised learning approach. sent: Article 1 uses TF-IDF, log-linear model and LDA topic modelling for feature extraction, while Article 2 GLOVE word embeddings for feature extraction. Article 1 uses SVM classification for systematic reviews for binary relevance, while Articla 2 uses a Multi-Channel Convolutional Neural Network (CNN) clasification approach. ","[['1511.06038', '1603.01547'], ['1511.06038', '1503.03244'], ['1603.01547', '1511.06038'], ['1603.01547', '1606.01549'], ['1603.01547', '1503.03244'], ['1606.01549', '1503.03244'], ['1606.01549', '1603.01547'], ['1503.03244', '1606.01549'], ['1503.03244', '1603.01547'], ['1503.03244', '1511.06038'], ['1506.03767', '1412.6806'], ['1506.03767', '1512.03385'], ['1506.03767', '1503.04596'], ['1412.6806', '1506.03767'], ['1412.6806', '1512.03385'], ['1512.03385', '1503.04596'], ['1503.04596', '1512.03385'], ['1607.01759', '1901.11504'], ['1901.11504', '1805.02474'], ['1901.11504', '1811.09386'], ['1901.11504', '1509.01626'], ['1901.11504', '1412.1058'], ['1901.11504', '1607.01759'], ['1901.11504', '1812.01207'], ['1602.06023', '1711.04434'], ['1711.04434', '1602.06023'], ['1506.07503', '1806.07789']]","['sent: Article 1 uses multiple datasets:  WikiQA, and  QASent, while Article 2 uses multiple datasets:  CNN   Daily Mail,  SearchQA, and  Children s Book Test.', 'sent: Article 1 uses multiple datasets:  WikiQA, and  QASent, while Article 2 uses SemEvalCQA dataset.', 'sent: Article 1 uses multiple datasets:  CNN   Daily Mail,  SearchQA, and  Children s Book Test, while Article 2 uses multiple datasets:  WikiQA, and  QASent.', 'sent: Article 1 and Article 2 use CNN   Daily Mail dataset.sent: Article 1 and Article 2 use Children s Book Test dataset. sent: Article 1 uses SearchQA dataset, while Article 2 uses Quasar dataset.', 'sent: Article 1 uses multiple datasets:  CNN   Daily Mail,  SearchQA, and  Children s Book Test, while Article 2 uses SemEvalCQA dataset.', 'sent: Article 1 uses multiple datasets:  CNN   Daily Mail,  Quasar, and  Children s Book Test, while Article 2 uses SemEvalCQA dataset.', 'sent: Article 1 and Article 2 use CNN   Daily Mail dataset.sent: Article 1 and Article 2 use Children s Book Test dataset. sent: Article 1 uses Quasar dataset, while Article 2 uses SearchQA dataset.', 'sent: Article 1 uses SemEvalCQA dataset, while Article 2 uses multiple datasets:  CNN   Daily Mail,  Quasar, and  Children s Book Test.', 'sent: Article 1 uses SemEvalCQA dataset, while Article 2 uses multiple datasets:  CNN   Daily Mail,  SearchQA, and  Children s Book Test.', 'sent: Article 1 uses SemEvalCQA dataset, while Article 2 uses multiple datasets:  WikiQA, and  QASent.', 'sent: Article 1 and Article 2 use CIFAR-10 dataset.sent: Article 1 and Article 2 use CIFAR-100 dataset.', 'sent: Article 1 and Article 2 use CIFAR-10 dataset. sent: Article 1 uses CIFAR-100 dataset, while Article 2 uses multiple datasets:  COCO, and  PASCAL VOC 2007.', 'sent: Article 1 and Article 2 use CIFAR-10 dataset. sent: Article 1 uses CIFAR-100 dataset, while Article 2 uses multiple datasets:  SVHN, and  MNIST.', 'sent: Article 1 and Article 2 use CIFAR-10 dataset.sent: Article 1 and Article 2 use CIFAR-100 dataset.', 'sent: Article 1 and Article 2 use CIFAR-10 dataset. sent: Article 1 uses CIFAR-100 dataset, while Article 2 uses multiple datasets:  COCO, and  PASCAL VOC 2007.', 'sent: Article 1 and Article 2 use CIFAR-10 dataset. sent: Article 1 uses multiple datasets:  COCO, and  PASCAL VOC 2007, while Article 2 uses multiple datasets:  SVHN, and  MNIST.', 'sent: Article 1 and Article 2 use CIFAR-10 dataset. sent: Article 1 uses multiple datasets:  SVHN, and  MNIST, while Article 2 uses multiple datasets:  COCO, and  PASCAL VOC 2007.', 'sent: Article 1 uses multiple datasets:  Yelp Fine-grained classification,  Amazon Review Polarity,  Amazon Review Full,  Sogou News,  DBpedia,  AG News,  Yelp Binary classification, and  Yahoo  Answers, while Article 2 uses multiple datasets:  Quora Question Pairs,  SNLI,  MultiNLI,  SciTail, and  SST-2 Binary classification.', 'sent: Article 1 uses multiple datasets:  Quora Question Pairs,  SNLI,  MultiNLI,  SciTail, and  SST-2 Binary classification, while Article 2 uses multiple datasets:  MR,  IMDb,  CoNLL 2003  English , and  Penn Treebank.', 'sent: Article 1 uses multiple datasets:  Quora Question Pairs,  SNLI,  MultiNLI,  SciTail, and  SST-2 Binary classification, while Article 2 uses multiple datasets:  Amazon Review Polarity,  Amazon Review Full,  DBpedia,  AG News, and  Yahoo  Answers.', 'sent: Article 1 uses multiple datasets:  Quora Question Pairs,  SNLI,  MultiNLI,  SciTail, and  SST-2 Binary classification, while Article 2 uses multiple datasets:  Yelp Fine-grained classification,  DBpedia,  AG News, and  Yelp Binary classification.', 'sent: Article 1 uses multiple datasets:  Quora Question Pairs,  SNLI,  MultiNLI,  SciTail, and  SST-2 Binary classification, while Article 2 uses IMDb dataset.', 'sent: Article 1 uses multiple datasets:  Quora Question Pairs,  SNLI,  MultiNLI,  SciTail, and  SST-2 Binary classification, while Article 2 uses multiple datasets:  Yelp Fine-grained classification,  Amazon Review Polarity,  Amazon Review Full,  Sogou News,  DBpedia,  AG News,  Yelp Binary classification, and  Yahoo  Answers.', 'sent: Article 1 and Article 2 use SST-2 Binary classification dataset. sent: Article 1 uses multiple datasets:  MultiNLI,  Quora Question Pairs,  SciTail, and  SNLI, while Article 2 uses SemEval 2018 Task 1E-c dataset.', 'sent: Article 1 and Article 2 use GigaWord dataset. sent: Article 1 uses DUC 2004 Task 1 dataset, while Article 2 does not use specific datasets for experiments.', 'sent: Article 1 and Article 2 use GigaWord dataset. sent: Article 1 does not use specific datasets for experiments, while Article 2 uses DUC 2004 Task 1 dataset.', 'sent: Article 1 and Article 2 use TIMIT dataset.']","['sent: Article 1 uses LSTM approach for Question Answering, while Article 2 uses ASR for Question Answering. sent: Article 1 uses LSTM approach for Question Answering, while Article 2 uses AS reader  greedy  for Question Answering. sent: Article 1 uses LSTM approach for Question Answering, while Article 2 uses AS Reader  single model  for Question Answering. sent: Article 1 uses LSTM approach for Question Answering, while Article 2 uses AS reader  avg  for Question Answering. sent: Article 1 uses LSTM approach for Question Answering, while Article 2 uses AS Reader  ensemble model  for Question Answering. sent: Article 1 uses Attentive LSTM approach for Question Answering, while Article 2 uses ASR for Question Answering. sent: Article 1 uses Attentive LSTM approach for Question Answering, while Article 2 uses AS reader  greedy  for Question Answering. sent: Article 1 uses Attentive LSTM approach for Question Answering, while Article 2 uses AS Reader  single model  for Question Answering. sent: Article 1 uses Attentive LSTM approach for Question Answering, while Article 2 uses AS reader  avg  for Question Answering. sent: Article 1 uses Attentive LSTM approach for Question Answering, while Article 2 uses AS Reader  ensemble model  for Question Answering. sent: Article 1 uses LSTM  lexical overlap   dist output  approach for Question Answering, while Article 2 uses ASR for Question Answering. sent: Article 1 uses LSTM  lexical overlap   dist output  approach for Question Answering, while Article 2 uses AS reader  greedy  for Question Answering. sent: Article 1 uses LSTM  lexical overlap   dist output  approach for Question Answering, while Article 2 uses AS Reader  single model  for Question Answering. sent: Article 1 uses LSTM  lexical overlap   dist output  approach for Question Answering, while Article 2 uses AS reader  avg  for Question Answering. sent: Article 1 uses LSTM  lexical overlap   dist output  approach for Question Answering, while Article 2 uses AS Reader  ensemble model  for Question Answering.', 'sent: Article 1 uses LSTM approach for Question Answering, while Article 2 uses ARC-II for Question Answering. sent: Article 1 uses Attentive LSTM approach for Question Answering, while Article 2 uses ARC-II for Question Answering. sent: Article 1 uses LSTM  lexical overlap   dist output  approach for Question Answering, while Article 2 uses ARC-II for Question Answering.', 'sent: Article 1 uses ASR approach for Question Answering, while Article 2 uses LSTM for Question Answering. sent: Article 1 uses ASR approach for Question Answering, while Article 2 uses Attentive LSTM for Question Answering. sent: Article 1 uses ASR approach for Question Answering, while Article 2 uses LSTM  lexical overlap   dist output  for Question Answering. sent: Article 1 uses AS reader  greedy  approach for Question Answering, while Article 2 uses LSTM for Question Answering. sent: Article 1 uses AS reader  greedy  approach for Question Answering, while Article 2 uses Attentive LSTM for Question Answering. sent: Article 1 uses AS reader  greedy  approach for Question Answering, while Article 2 uses LSTM  lexical overlap   dist output  for Question Answering. sent: Article 1 uses AS Reader  single model  approach for Question Answering, while Article 2 uses LSTM for Question Answering. sent: Article 1 uses AS Reader  single model  approach for Question Answering, while Article 2 uses Attentive LSTM for Question Answering. sent: Article 1 uses AS Reader  single model  approach for Question Answering, while Article 2 uses LSTM  lexical overlap   dist output  for Question Answering. sent: Article 1 uses AS reader  avg  approach for Question Answering, while Article 2 uses LSTM for Question Answering. sent: Article 1 uses AS reader  avg  approach for Question Answering, while Article 2 uses Attentive LSTM for Question Answering. sent: Article 1 uses AS reader  avg  approach for Question Answering, while Article 2 uses LSTM  lexical overlap   dist output  for Question Answering. sent: Article 1 uses AS Reader  ensemble model  approach for Question Answering, while Article 2 uses LSTM for Question Answering. sent: Article 1 uses AS Reader  ensemble model  approach for Question Answering, while Article 2 uses Attentive LSTM for Question Answering. sent: Article 1 uses AS Reader  ensemble model  approach for Question Answering, while Article 2 uses LSTM  lexical overlap   dist output  for Question Answering.', 'sent: Article 1 uses ASR approach for Question Answering, while Article 2 uses GA reader for Question Answering. sent: Article 1 uses ASR approach for Question Answering, while Article 2 uses NSE for Question Answering. sent: Article 1 uses ASR approach for Question Answering, while Article 2 uses GA   feature   fix L w  for Question Answering. sent: Article 1 uses ASR approach for Question Answering, while Article 2 uses GA Reader for Question Answering. sent: Article 1 uses ASR approach for Question Answering, while Article 2 uses GA for Question Answering. sent: Article 1 uses AS reader  greedy  approach for Question Answering, while Article 2 uses GA reader for Question Answering. sent: Article 1 uses AS reader  greedy  approach for Question Answering, while Article 2 uses NSE for Question Answering. sent: Article 1 uses AS reader  greedy  approach for Question Answering, while Article 2 uses GA   feature   fix L w  for Question Answering. sent: Article 1 uses AS reader  greedy  approach for Question Answering, while Article 2 uses GA Reader for Question Answering. sent: Article 1 uses AS reader  greedy  approach for Question Answering, while Article 2 uses GA for Question Answering. sent: Article 1 uses AS Reader  single model  approach for Question Answering, while Article 2 uses GA reader for Question Answering. sent: Article 1 uses AS Reader  single model  approach for Question Answering, while Article 2 uses NSE for Question Answering. sent: Article 1 uses AS Reader  single model  approach for Question Answering, while Article 2 uses GA   feature   fix L w  for Question Answering. sent: Article 1 uses AS Reader  single model  approach for Question Answering, while Article 2 uses GA Reader for Question Answering. sent: Article 1 uses AS Reader  single model  approach for Question Answering, while Article 2 uses GA for Question Answering. sent: Article 1 uses AS reader  avg  approach for Question Answering, while Article 2 uses GA reader for Question Answering. sent: Article 1 uses AS reader  avg  approach for Question Answering, while Article 2 uses NSE for Question Answering. sent: Article 1 uses AS reader  avg  approach for Question Answering, while Article 2 uses GA   feature   fix L w  for Question Answering. sent: Article 1 uses AS reader  avg  approach for Question Answering, while Article 2 uses GA Reader for Question Answering. sent: Article 1 uses AS reader  avg  approach for Question Answering, while Article 2 uses GA for Question Answering. sent: Article 1 uses AS Reader  ensemble model  approach for Question Answering, while Article 2 uses GA reader for Question Answering. sent: Article 1 uses AS Reader  ensemble model  approach for Question Answering, while Article 2 uses NSE for Question Answering. sent: Article 1 uses AS Reader  ensemble model  approach for Question Answering, while Article 2 uses GA   feature   fix L w  for Question Answering. sent: Article 1 uses AS Reader  ensemble model  approach for Question Answering, while Article 2 uses GA Reader for Question Answering. sent: Article 1 uses AS Reader  ensemble model  approach for Question Answering, while Article 2 uses GA for Question Answering. sent: Article 1 uses ASR approach for Open-Domain Question Answering, while Article 2 uses GA for Open-Domain Question Answering.', 'sent: Article 1 uses ASR approach for Question Answering, while Article 2 uses ARC-II for Question Answering. sent: Article 1 uses AS reader  greedy  approach for Question Answering, while Article 2 uses ARC-II for Question Answering. sent: Article 1 uses AS Reader  single model  approach for Question Answering, while Article 2 uses ARC-II for Question Answering. sent: Article 1 uses AS reader  avg  approach for Question Answering, while Article 2 uses ARC-II for Question Answering. sent: Article 1 uses AS Reader  ensemble model  approach for Question Answering, while Article 2 uses ARC-II for Question Answering.', 'sent: Article 1 uses GA reader approach for Question Answering, while Article 2 uses ARC-II for Question Answering. sent: Article 1 uses NSE approach for Question Answering, while Article 2 uses ARC-II for Question Answering. sent: Article 1 uses GA   feature   fix L w  approach for Question Answering, while Article 2 uses ARC-II for Question Answering. sent: Article 1 uses GA Reader approach for Question Answering, while Article 2 uses ARC-II for Question Answering. sent: Article 1 uses GA approach for Question Answering, while Article 2 uses ARC-II for Question Answering.', 'sent: Article 1 uses GA reader approach for Question Answering, while Article 2 uses ASR for Question Answering. sent: Article 1 uses GA reader approach for Question Answering, while Article 2 uses AS reader  greedy  for Question Answering. sent: Article 1 uses GA reader approach for Question Answering, while Article 2 uses AS Reader  single model  for Question Answering. sent: Article 1 uses GA reader approach for Question Answering, while Article 2 uses AS reader  avg  for Question Answering. sent: Article 1 uses GA reader approach for Question Answering, while Article 2 uses AS Reader  ensemble model  for Question Answering. sent: Article 1 uses NSE approach for Question Answering, while Article 2 uses ASR for Question Answering. sent: Article 1 uses NSE approach for Question Answering, while Article 2 uses AS reader  greedy  for Question Answering. sent: Article 1 uses NSE approach for Question Answering, while Article 2 uses AS Reader  single model  for Question Answering. sent: Article 1 uses NSE approach for Question Answering, while Article 2 uses AS reader  avg  for Question Answering. sent: Article 1 uses NSE approach for Question Answering, while Article 2 uses AS Reader  ensemble model  for Question Answering. sent: Article 1 uses GA   feature   fix L w  approach for Question Answering, while Article 2 uses ASR for Question Answering. sent: Article 1 uses GA   feature   fix L w  approach for Question Answering, while Article 2 uses AS reader  greedy  for Question Answering. sent: Article 1 uses GA   feature   fix L w  approach for Question Answering, while Article 2 uses AS Reader  single model  for Question Answering. sent: Article 1 uses GA   feature   fix L w  approach for Question Answering, while Article 2 uses AS reader  avg  for Question Answering. sent: Article 1 uses GA   feature   fix L w  approach for Question Answering, while Article 2 uses AS Reader  ensemble model  for Question Answering. sent: Article 1 uses GA Reader approach for Question Answering, while Article 2 uses ASR for Question Answering. sent: Article 1 uses GA Reader approach for Question Answering, while Article 2 uses AS reader  greedy  for Question Answering. sent: Article 1 uses GA Reader approach for Question Answering, while Article 2 uses AS Reader  single model  for Question Answering. sent: Article 1 uses GA Reader approach for Question Answering, while Article 2 uses AS reader  avg  for Question Answering. sent: Article 1 uses GA Reader approach for Question Answering, while Article 2 uses AS Reader  ensemble model  for Question Answering. sent: Article 1 uses GA approach for Question Answering, while Article 2 uses ASR for Question Answering. sent: Article 1 uses GA approach for Question Answering, while Article 2 uses AS reader  greedy  for Question Answering. sent: Article 1 uses GA approach for Question Answering, while Article 2 uses AS Reader  single model  for Question Answering. sent: Article 1 uses GA approach for Question Answering, while Article 2 uses AS reader  avg  for Question Answering. sent: Article 1 uses GA approach for Question Answering, while Article 2 uses AS Reader  ensemble model  for Question Answering. sent: Article 1 uses GA approach for Open-Domain Question Answering, while Article 2 uses ASR for Open-Domain Question Answering.', 'sent: Article 1 uses ARC-II approach for Question Answering, while Article 2 uses GA reader for Question Answering. sent: Article 1 uses ARC-II approach for Question Answering, while Article 2 uses NSE for Question Answering. sent: Article 1 uses ARC-II approach for Question Answering, while Article 2 uses GA   feature   fix L w  for Question Answering. sent: Article 1 uses ARC-II approach for Question Answering, while Article 2 uses GA Reader for Question Answering. sent: Article 1 uses ARC-II approach for Question Answering, while Article 2 uses GA for Question Answering.', 'sent: Article 1 uses ARC-II approach for Question Answering, while Article 2 uses ASR for Question Answering. sent: Article 1 uses ARC-II approach for Question Answering, while Article 2 uses AS reader  greedy  for Question Answering. sent: Article 1 uses ARC-II approach for Question Answering, while Article 2 uses AS Reader  single model  for Question Answering. sent: Article 1 uses ARC-II approach for Question Answering, while Article 2 uses AS reader  avg  for Question Answering. sent: Article 1 uses ARC-II approach for Question Answering, while Article 2 uses AS Reader  ensemble model  for Question Answering.', 'sent: Article 1 uses ARC-II approach for Question Answering, while Article 2 uses LSTM for Question Answering. sent: Article 1 uses ARC-II approach for Question Answering, while Article 2 uses Attentive LSTM for Question Answering. sent: Article 1 uses ARC-II approach for Question Answering, while Article 2 uses LSTM  lexical overlap   dist output  for Question Answering.', 'sent: Article 1 uses Spectral Representations for Convolutional Neural Networks approach for Image Classification, while Article 2 uses ACN for Image Classification.', 'sent: Article 1 uses Spectral Representations for Convolutional Neural Networks approach for Image Classification, while Article 2 uses ResNet-101 for Image Classification. sent: Article 1 uses Spectral Representations for Convolutional Neural Networks approach for Image Classification, while Article 2 uses ResNet for Image Classification. sent: Article 1 uses Spectral Representations for Convolutional Neural Networks approach for Image Classification, while Article 2 uses Faster R-CNN   box refinement   context   multi-scale testing for Image Classification.', 'sent: Article 1 uses Spectral Representations for Convolutional Neural Networks approach for Image Classification, while Article 2 uses FLSCNN for Image Classification.', 'sent: Article 1 uses ACN approach for Image Classification, while Article 2 uses Spectral Representations for Convolutional Neural Networks for Image Classification.', 'sent: Article 1 uses ACN approach for Image Classification, while Article 2 uses ResNet-101 for Image Classification. sent: Article 1 uses ACN approach for Image Classification, while Article 2 uses ResNet for Image Classification. sent: Article 1 uses ACN approach for Image Classification, while Article 2 uses Faster R-CNN   box refinement   context   multi-scale testing for Image Classification.', 'sent: Article 1 uses ResNet-101 approach for Image Classification, while Article 2 uses FLSCNN for Image Classification. sent: Article 1 uses ResNet approach for Image Classification, while Article 2 uses FLSCNN for Image Classification. sent: Article 1 uses Faster R-CNN   box refinement   context   multi-scale testing approach for Image Classification, while Article 2 uses FLSCNN for Image Classification.', 'sent: Article 1 uses FLSCNN approach for Image Classification, while Article 2 uses ResNet-101 for Image Classification. sent: Article 1 uses FLSCNN approach for Image Classification, while Article 2 uses ResNet for Image Classification. sent: Article 1 uses FLSCNN approach for Image Classification, while Article 2 uses Faster R-CNN   box refinement   context   multi-scale testing for Image Classification.', 'sent: Article 1 uses FastText approach for Sentiment Analysis, while Article 2 uses MT-DNN for Sentiment Analysis. sent: Article 1 uses fastText approach for Sentiment Analysis, while Article 2 uses MT-DNN for Sentiment Analysis.', 'sent: Article 1 uses MT-DNN approach for Sentiment Analysis, while Article 2 uses S-LSTM for Sentiment Analysis.', 'sent: Article 1 uses MT-DNN approach for Sentiment Analysis, while Article 2 uses EXAM for Sentiment Analysis.', 'sent: Article 1 uses MT-DNN approach for Sentiment Analysis, while Article 2 uses Char-level CNN for Sentiment Analysis.', 'sent: Article 1 uses MT-DNN approach for Sentiment Analysis, while Article 2 uses seq2-bown-CNN for Sentiment Analysis.', 'sent: Article 1 uses MT-DNN approach for Sentiment Analysis, while Article 2 uses FastText for Sentiment Analysis. sent: Article 1 uses MT-DNN approach for Sentiment Analysis, while Article 2 uses fastText for Sentiment Analysis.', 'sent: Article 1 uses MT-DNN approach for Sentiment Analysis, while Article 2 uses Transformer  finetune  for Sentiment Analysis.', 'sent: Article 1 uses words-lvt5k-1sent approach for Text Summarization, while Article 2 uses FTSum g for Text Summarization.', 'sent: Article 1 uses FTSum g approach for Text Summarization, while Article 2 uses words-lvt5k-1sent for Text Summarization.', 'sent: Article 1 uses Bi-RNN   Attention approach for Speech Recognition, while Article 2 uses QCNN-10L-256FM for Speech Recognition.']"
2,2,wk_paper_2,wk_paper_3,12,13,"sent: Article 1 uses medical domain datasets sourced from different sources,  Article 2 uses different datasets from the medical domain sourced mainly from PubMed. sent: Article 1 uses 23 systematic review datasets, while Article 2 uses 20 systematic review datasets. ","sent: Article 1 and Article 2 use supervised learning approach. sent: Article 1 uses deep denoinsing encoder and feed forward neural networks for feature extraction, while Article 2 GLOVE word embeddings for feature extraction. Article 1 uses SVM classification for systematic reviews for binary relevance, while Articla 2 uses a Multi-Channel Convolutional Neural Network (CNN) clasification approach. ","[['1603.01547', '1503.03244'], ['1503.03244', '1603.01547'], ['1712.06116', '1609.05158'], ['1609.05158', '1511.04491'], ['1609.05158', '1712.06116'], ['1511.04491', '1609.05158'], ['1409.3215', '1705.03122'], ['1705.03122', '1409.3215'], ['1704.03373', '1603.05474'], ['1506.07503', '1806.07789']]","['sent: Article 1 uses multiple datasets:  CNN   Daily Mail,  SearchQA, and  Children s Book Test, while Article 2 uses SemEvalCQA dataset.', 'sent: Article 1 uses SemEvalCQA dataset, while Article 2 uses multiple datasets:  CNN   Daily Mail,  SearchQA, and  Children s Book Test.', 'sent: Article 1 and Article 2 use Set14 - 4x upscaling dataset.sent: Article 1 and Article 2 use BSD100 - 4x upscaling dataset.sent: Article 1 and Article 2 use Set5 - 4x upscaling dataset. sent: Article 1 uses Urban100 - 4x upscaling dataset, while Article 2 uses multiple datasets:  Ultra Video Group HD - 4x upscaling,  Vid4 - 4x upscaling, and  Xiph HD - 4x upscaling.', 'sent: Article 1 and Article 2 use Set14 - 4x upscaling dataset.sent: Article 1 and Article 2 use BSD100 - 4x upscaling dataset.sent: Article 1 and Article 2 use Set5 - 4x upscaling dataset. sent: Article 1 uses multiple datasets:  Ultra Video Group HD - 4x upscaling,  Vid4 - 4x upscaling, and  Xiph HD - 4x upscaling, while Article 2 does not use specific datasets for experiments.', 'sent: Article 1 and Article 2 use Set14 - 4x upscaling dataset.sent: Article 1 and Article 2 use BSD100 - 4x upscaling dataset.sent: Article 1 and Article 2 use Set5 - 4x upscaling dataset. sent: Article 1 uses multiple datasets:  Ultra Video Group HD - 4x upscaling,  Vid4 - 4x upscaling, and  Xiph HD - 4x upscaling, while Article 2 uses Urban100 - 4x upscaling dataset.', 'sent: Article 1 and Article 2 use Set14 - 4x upscaling dataset.sent: Article 1 and Article 2 use BSD100 - 4x upscaling dataset.sent: Article 1 and Article 2 use Set5 - 4x upscaling dataset. sent: Article 1 does not use specific datasets for experiments, while Article 2 uses multiple datasets:  Ultra Video Group HD - 4x upscaling,  Vid4 - 4x upscaling, and  Xiph HD - 4x upscaling.', 'sent: Article 1 and Article 2 use WMT2014 English-French dataset. sent: Article 1 does not use specific datasets for experiments, while Article 2 uses multiple datasets:  WMT2014 English-German,  WMT2016 English-Romanian,  IWSLT2015 English-German, and  IWSLT2015 German-English.', 'sent: Article 1 and Article 2 use WMT2014 English-French dataset. sent: Article 1 uses multiple datasets:  WMT2014 English-German,  WMT2016 English-Romanian,  IWSLT2015 English-German, and  IWSLT2015 German-English, while Article 2 does not use specific datasets for experiments.', 'sent: Article 1 uses YouTube Faces DB dataset, while Article 2 uses IJB-A dataset.', 'sent: Article 1 and Article 2 use TIMIT dataset.']","['sent: Article 1 uses ASR approach for Question Answering, while Article 2 uses ARC-II for Question Answering. sent: Article 1 uses AS reader  greedy  approach for Question Answering, while Article 2 uses ARC-II for Question Answering. sent: Article 1 uses AS Reader  single model  approach for Question Answering, while Article 2 uses ARC-II for Question Answering. sent: Article 1 uses AS reader  avg  approach for Question Answering, while Article 2 uses ARC-II for Question Answering. sent: Article 1 uses AS Reader  ensemble model  approach for Question Answering, while Article 2 uses ARC-II for Question Answering.', 'sent: Article 1 uses ARC-II approach for Question Answering, while Article 2 uses ASR for Question Answering. sent: Article 1 uses ARC-II approach for Question Answering, while Article 2 uses AS reader  greedy  for Question Answering. sent: Article 1 uses ARC-II approach for Question Answering, while Article 2 uses AS Reader  single model  for Question Answering. sent: Article 1 uses ARC-II approach for Question Answering, while Article 2 uses AS reader  avg  for Question Answering. sent: Article 1 uses ARC-II approach for Question Answering, while Article 2 uses AS Reader  ensemble model  for Question Answering.', 'sent: Article 1 uses SRMDNF approach for Image Super-Resolution, while Article 2 uses ESPCN for Image Super-Resolution. sent: Article 1 uses SRMDNF approach for Image Super-Resolution, while Article 2 uses bicubic for Image Super-Resolution.', 'sent: Article 1 uses ESPCN approach for Image Super-Resolution, while Article 2 uses DRCN for Image Super-Resolution. sent: Article 1 uses bicubic approach for Image Super-Resolution, while Article 2 uses DRCN for Image Super-Resolution.', 'sent: Article 1 uses ESPCN approach for Image Super-Resolution, while Article 2 uses SRMDNF for Image Super-Resolution. sent: Article 1 uses bicubic approach for Image Super-Resolution, while Article 2 uses SRMDNF for Image Super-Resolution.', 'sent: Article 1 uses DRCN approach for Image Super-Resolution, while Article 2 uses ESPCN for Image Super-Resolution. sent: Article 1 uses DRCN approach for Image Super-Resolution, while Article 2 uses bicubic for Image Super-Resolution.', 'sent: Article 1 uses LSTM approach for Machine Translation, while Article 2 uses ConvS2S  ensemble  for Machine Translation. sent: Article 1 uses LSTM approach for Machine Translation, while Article 2 uses ConvS2S for Machine Translation. sent: Article 1 uses LSTM approach for Machine Translation, while Article 2 uses ConvS2S BPE40k for Machine Translation. sent: Article 1 uses SMT LSTM5 approach for Machine Translation, while Article 2 uses ConvS2S  ensemble  for Machine Translation. sent: Article 1 uses SMT LSTM5 approach for Machine Translation, while Article 2 uses ConvS2S for Machine Translation. sent: Article 1 uses SMT LSTM5 approach for Machine Translation, while Article 2 uses ConvS2S BPE40k for Machine Translation.', 'sent: Article 1 uses ConvS2S  ensemble  approach for Machine Translation, while Article 2 uses LSTM for Machine Translation. sent: Article 1 uses ConvS2S  ensemble  approach for Machine Translation, while Article 2 uses SMT LSTM5 for Machine Translation. sent: Article 1 uses ConvS2S approach for Machine Translation, while Article 2 uses LSTM for Machine Translation. sent: Article 1 uses ConvS2S approach for Machine Translation, while Article 2 uses SMT LSTM5 for Machine Translation. sent: Article 1 uses ConvS2S BPE40k approach for Machine Translation, while Article 2 uses LSTM for Machine Translation. sent: Article 1 uses ConvS2S BPE40k approach for Machine Translation, while Article 2 uses SMT LSTM5 for Machine Translation.', 'sent: Article 1 uses QAN approach for Face Verification, while Article 2 uses NAN for Face Verification.', 'sent: Article 1 uses Bi-RNN   Attention approach for Speech Recognition, while Article 2 uses QCNN-10L-256FM for Speech Recognition.']"
3,3,an_paper_1,an_paper_2,31,32,sent: Article 1 and Article 2 use datasets sourced from AskApatient reviews and CADEC datasets sourced from SNOMED-CT. sent: Article 1 and Article 2 use medical domain datasets for infomal and formal text. sent: Article 1 and Article 2 use 5 folds of the datasets.,"sent: Article 1 uses semantic similarity approach for mapping informal medical terms to formal terms, Article 2 uses deep learning classification approach for mapping informal medical terms to formal terms. sent: Article 1 uses a bidirectional RNN with attention on top of the embedding layer (HealthVec and PubMedVec) for feature representation, while Article 2 uses HealthVec and Google News embeddings in combination  with ELMo ( HV, GN, GELMo, BELMo and CELMo) embeddings for feature representation. sent: Article 1 uses cosine similarity, while Article 2 uses a BiLSTM model for classification.","[['1511.06038', '1711.08028'], ['1802.05365', '1711.08028'], ['1603.01547', '1711.08028'], ['1606.01549', '1711.08028'], ['1711.08028', '1802.05365'], ['1711.08028', '1603.01547'], ['1711.08028', '1511.06038'], ['1711.08028', '1606.01549'], ['1509.08985', '1512.03385'], ['1509.08985', '1707.02968'], ['1509.08985', '1603.05027'], ['1512.03385', '1603.05027'], ['1512.03385', '1509.08985'], ['1707.02968', '1603.05027'], ['1707.02968', '1509.08985'], ['1603.05027', '1509.08985'], ['1603.05027', '1512.03385'], ['1603.05027', '1707.02968'], ['1409.3215', '1610.10099'], ['1610.10099', '1409.3215'], ['1610.10099', '1511.06732'], ['1610.10099', '1611.01576'], ['1511.06732', '1610.10099'], ['1611.01576', '1610.10099']]","['sent: Article 1 uses multiple datasets:  WikiQA, and  QASent, while Article 2 uses bAbi dataset.', 'sent: Article 1 uses multiple datasets:  OntoNotes,  CoNLL 2012,  SNLI,  SQuAD1 1,  CoNLL 2003  English ,  SQuAD2 0,  SST-5 Fine-grained classification, and  ACL-ARC, while Article 2 uses bAbi dataset.', 'sent: Article 1 uses multiple datasets:  CNN   Daily Mail,  SearchQA, and  Children s Book Test, while Article 2 uses bAbi dataset.', 'sent: Article 1 uses multiple datasets:  CNN   Daily Mail,  Quasar, and  Children s Book Test, while Article 2 uses bAbi dataset.', 'sent: Article 1 uses bAbi dataset, while Article 2 uses multiple datasets:  OntoNotes,  CoNLL 2012,  SNLI,  SQuAD1 1,  CoNLL 2003  English ,  SQuAD2 0,  SST-5 Fine-grained classification, and  ACL-ARC.', 'sent: Article 1 uses bAbi dataset, while Article 2 uses multiple datasets:  CNN   Daily Mail,  SearchQA, and  Children s Book Test.', 'sent: Article 1 uses bAbi dataset, while Article 2 uses multiple datasets:  WikiQA, and  QASent.', 'sent: Article 1 uses bAbi dataset, while Article 2 uses multiple datasets:  CNN   Daily Mail,  Quasar, and  Children s Book Test.', 'sent: Article 1 and Article 2 use CIFAR-10 dataset. sent: Article 1 uses multiple datasets:  SVHN,  MNIST, and  CIFAR-100, while Article 2 uses multiple datasets:  COCO, and  PASCAL VOC 2007.', 'sent: Article 1 uses multiple datasets:  CIFAR-10,  SVHN,  MNIST, and  CIFAR-100, while Article 2 uses multiple datasets:  ImageNet, and  PASCAL VOC 2012.', 'sent: Article 1 and Article 2 use CIFAR-10 dataset.sent: Article 1 and Article 2 use CIFAR-100 dataset. sent: Article 1 uses multiple datasets:  SVHN, and  MNIST, while Article 2 does not use specific datasets for experiments.', 'sent: Article 1 and Article 2 use CIFAR-10 dataset. sent: Article 1 uses multiple datasets:  COCO, and  PASCAL VOC 2007, while Article 2 uses CIFAR-100 dataset.', 'sent: Article 1 and Article 2 use CIFAR-10 dataset. sent: Article 1 uses multiple datasets:  COCO, and  PASCAL VOC 2007, while Article 2 uses multiple datasets:  SVHN,  MNIST, and  CIFAR-100.', 'sent: Article 1 uses multiple datasets:  ImageNet, and  PASCAL VOC 2012, while Article 2 uses multiple datasets:  CIFAR-10, and  CIFAR-100.', 'sent: Article 1 uses multiple datasets:  ImageNet, and  PASCAL VOC 2012, while Article 2 uses multiple datasets:  CIFAR-10,  SVHN,  MNIST, and  CIFAR-100.', 'sent: Article 1 and Article 2 use CIFAR-10 dataset.sent: Article 1 and Article 2 use CIFAR-100 dataset. sent: Article 1 does not use specific datasets for experiments, while Article 2 uses multiple datasets:  SVHN, and  MNIST.', 'sent: Article 1 and Article 2 use CIFAR-10 dataset. sent: Article 1 uses CIFAR-100 dataset, while Article 2 uses multiple datasets:  COCO, and  PASCAL VOC 2007.', 'sent: Article 1 uses multiple datasets:  CIFAR-10, and  CIFAR-100, while Article 2 uses multiple datasets:  ImageNet, and  PASCAL VOC 2012.', 'sent: Article 1 and Article 2 use WMT2014 English-French dataset. sent: Article 1 does not use specific datasets for experiments, while Article 2 uses multiple datasets:  WMT2014 English-German, and  WMT2015 English-German.', 'sent: Article 1 and Article 2 use WMT2014 English-French dataset. sent: Article 1 uses multiple datasets:  WMT2014 English-German, and  WMT2015 English-German, while Article 2 does not use specific datasets for experiments.', 'sent: Article 1 uses multiple datasets:  WMT2014 English-German,  WMT2014 English-French, and  WMT2015 English-German, while Article 2 uses IWSLT2015 German-English dataset.', 'sent: Article 1 uses multiple datasets:  WMT2014 English-German,  WMT2014 English-French, and  WMT2015 English-German, while Article 2 uses IWSLT2015 German-English dataset.', 'sent: Article 1 uses IWSLT2015 German-English dataset, while Article 2 uses multiple datasets:  WMT2014 English-German,  WMT2014 English-French, and  WMT2015 English-German.', 'sent: Article 1 uses IWSLT2015 German-English dataset, while Article 2 uses multiple datasets:  WMT2014 English-German,  WMT2014 English-French, and  WMT2015 English-German.']","['sent: Article 1 uses LSTM approach for Question Answering, while Article 2 uses  RR for Question Answering. sent: Article 1 uses Attentive LSTM approach for Question Answering, while Article 2 uses  RR for Question Answering. sent: Article 1 uses LSTM  lexical overlap   dist output  approach for Question Answering, while Article 2 uses  RR for Question Answering.', 'sent: Article 1 uses BiLSTM-CRF ELMo approach for Question Answering, while Article 2 uses  RR for Question Answering. sent: Article 1 uses BiDAF   Self Attention   ELMo  ensemble  approach for Question Answering, while Article 2 uses  RR for Question Answering. sent: Article 1 uses  Lee et al   2017  ELMo approach for Question Answering, while Article 2 uses  RR for Question Answering. sent: Article 1 uses BiDAF   Self Attention   ELMo  single model  approach for Question Answering, while Article 2 uses  RR for Question Answering. sent: Article 1 uses BCN ELMo approach for Question Answering, while Article 2 uses  RR for Question Answering. sent: Article 1 uses ESIM   ELMo Ensemble approach for Question Answering, while Article 2 uses  RR for Question Answering. sent: Article 1 uses  He et al   2017    ELMo approach for Question Answering, while Article 2 uses  RR for Question Answering. sent: Article 1 uses ESIM   ELMo approach for Question Answering, while Article 2 uses  RR for Question Answering. sent: Article 1 uses BiLSTM-Attention   ELMo approach for Question Answering, while Article 2 uses  RR for Question Answering.', 'sent: Article 1 uses ASR approach for Question Answering, while Article 2 uses  RR for Question Answering. sent: Article 1 uses AS reader  greedy  approach for Question Answering, while Article 2 uses  RR for Question Answering. sent: Article 1 uses AS Reader  single model  approach for Question Answering, while Article 2 uses  RR for Question Answering. sent: Article 1 uses AS reader  avg  approach for Question Answering, while Article 2 uses  RR for Question Answering. sent: Article 1 uses AS Reader  ensemble model  approach for Question Answering, while Article 2 uses  RR for Question Answering.', 'sent: Article 1 uses GA reader approach for Question Answering, while Article 2 uses  RR for Question Answering. sent: Article 1 uses NSE approach for Question Answering, while Article 2 uses  RR for Question Answering. sent: Article 1 uses GA   feature   fix L w  approach for Question Answering, while Article 2 uses  RR for Question Answering. sent: Article 1 uses GA Reader approach for Question Answering, while Article 2 uses  RR for Question Answering. sent: Article 1 uses GA approach for Question Answering, while Article 2 uses  RR for Question Answering.', 'sent: Article 1 uses  RR approach for Question Answering, while Article 2 uses BiLSTM-CRF ELMo for Question Answering. sent: Article 1 uses  RR approach for Question Answering, while Article 2 uses BiDAF   Self Attention   ELMo  ensemble  for Question Answering. sent: Article 1 uses  RR approach for Question Answering, while Article 2 uses  Lee et al   2017  ELMo for Question Answering. sent: Article 1 uses  RR approach for Question Answering, while Article 2 uses BiDAF   Self Attention   ELMo  single model  for Question Answering. sent: Article 1 uses  RR approach for Question Answering, while Article 2 uses BCN ELMo for Question Answering. sent: Article 1 uses  RR approach for Question Answering, while Article 2 uses ESIM   ELMo Ensemble for Question Answering. sent: Article 1 uses  RR approach for Question Answering, while Article 2 uses  He et al   2017    ELMo for Question Answering. sent: Article 1 uses  RR approach for Question Answering, while Article 2 uses ESIM   ELMo for Question Answering. sent: Article 1 uses  RR approach for Question Answering, while Article 2 uses BiLSTM-Attention   ELMo for Question Answering.', 'sent: Article 1 uses  RR approach for Question Answering, while Article 2 uses ASR for Question Answering. sent: Article 1 uses  RR approach for Question Answering, while Article 2 uses AS reader  greedy  for Question Answering. sent: Article 1 uses  RR approach for Question Answering, while Article 2 uses AS Reader  single model  for Question Answering. sent: Article 1 uses  RR approach for Question Answering, while Article 2 uses AS reader  avg  for Question Answering. sent: Article 1 uses  RR approach for Question Answering, while Article 2 uses AS Reader  ensemble model  for Question Answering.', 'sent: Article 1 uses  RR approach for Question Answering, while Article 2 uses LSTM for Question Answering. sent: Article 1 uses  RR approach for Question Answering, while Article 2 uses Attentive LSTM for Question Answering. sent: Article 1 uses  RR approach for Question Answering, while Article 2 uses LSTM  lexical overlap   dist output  for Question Answering.', 'sent: Article 1 uses  RR approach for Question Answering, while Article 2 uses GA reader for Question Answering. sent: Article 1 uses  RR approach for Question Answering, while Article 2 uses NSE for Question Answering. sent: Article 1 uses  RR approach for Question Answering, while Article 2 uses GA   feature   fix L w  for Question Answering. sent: Article 1 uses  RR approach for Question Answering, while Article 2 uses GA Reader for Question Answering. sent: Article 1 uses  RR approach for Question Answering, while Article 2 uses GA for Question Answering.', 'sent: Article 1 uses Tree Max-Avg pooling approach for Image Classification, while Article 2 uses ResNet-101 for Image Classification. sent: Article 1 uses Tree Max-Avg pooling approach for Image Classification, while Article 2 uses ResNet for Image Classification. sent: Article 1 uses Tree Max-Avg pooling approach for Image Classification, while Article 2 uses Faster R-CNN   box refinement   context   multi-scale testing for Image Classification.', 'sent: Article 1 uses Tree Max-Avg pooling approach for Image Classification, while Article 2 uses JFT-300M Finetuning for Image Classification. sent: Article 1 uses Tree Max-Avg pooling approach for Image Classification, while Article 2 uses ImageNet JFT-300M Initialization for Image Classification.', 'sent: Article 1 uses Tree Max-Avg pooling approach for Image Classification, while Article 2 uses ResNet-1001 for Image Classification.', 'sent: Article 1 uses ResNet-101 approach for Image Classification, while Article 2 uses ResNet-1001 for Image Classification. sent: Article 1 uses ResNet approach for Image Classification, while Article 2 uses ResNet-1001 for Image Classification. sent: Article 1 uses Faster R-CNN   box refinement   context   multi-scale testing approach for Image Classification, while Article 2 uses ResNet-1001 for Image Classification.', 'sent: Article 1 uses ResNet-101 approach for Image Classification, while Article 2 uses Tree Max-Avg pooling for Image Classification. sent: Article 1 uses ResNet approach for Image Classification, while Article 2 uses Tree Max-Avg pooling for Image Classification. sent: Article 1 uses Faster R-CNN   box refinement   context   multi-scale testing approach for Image Classification, while Article 2 uses Tree Max-Avg pooling for Image Classification.', 'sent: Article 1 uses JFT-300M Finetuning approach for Image Classification, while Article 2 uses ResNet-1001 for Image Classification. sent: Article 1 uses ImageNet JFT-300M Initialization approach for Image Classification, while Article 2 uses ResNet-1001 for Image Classification.', 'sent: Article 1 uses JFT-300M Finetuning approach for Image Classification, while Article 2 uses Tree Max-Avg pooling for Image Classification. sent: Article 1 uses ImageNet JFT-300M Initialization approach for Image Classification, while Article 2 uses Tree Max-Avg pooling for Image Classification.', 'sent: Article 1 uses ResNet-1001 approach for Image Classification, while Article 2 uses Tree Max-Avg pooling for Image Classification.', 'sent: Article 1 uses ResNet-1001 approach for Image Classification, while Article 2 uses ResNet-101 for Image Classification. sent: Article 1 uses ResNet-1001 approach for Image Classification, while Article 2 uses ResNet for Image Classification. sent: Article 1 uses ResNet-1001 approach for Image Classification, while Article 2 uses Faster R-CNN   box refinement   context   multi-scale testing for Image Classification.', 'sent: Article 1 uses ResNet-1001 approach for Image Classification, while Article 2 uses JFT-300M Finetuning for Image Classification. sent: Article 1 uses ResNet-1001 approach for Image Classification, while Article 2 uses ImageNet JFT-300M Initialization for Image Classification.', 'sent: Article 1 uses LSTM approach for Machine Translation, while Article 2 uses ByteNet for Machine Translation. sent: Article 1 uses SMT LSTM5 approach for Machine Translation, while Article 2 uses ByteNet for Machine Translation.', 'sent: Article 1 uses ByteNet approach for Machine Translation, while Article 2 uses LSTM for Machine Translation. sent: Article 1 uses ByteNet approach for Machine Translation, while Article 2 uses SMT LSTM5 for Machine Translation.', 'sent: Article 1 uses ByteNet approach for Machine Translation, while Article 2 uses Word-level LSTM w attn for Machine Translation.', 'sent: Article 1 uses ByteNet approach for Machine Translation, while Article 2 uses QRNN for Machine Translation.', 'sent: Article 1 uses Word-level LSTM w attn approach for Machine Translation, while Article 2 uses ByteNet for Machine Translation.', 'sent: Article 1 uses QRNN approach for Machine Translation, while Article 2 uses ByteNet for Machine Translation.']"
4,4,yg_paper_1,yg_paper_2,41,42,"sent: Article 1 uses datasets sourced from TREC Genomics collection, while Article 2 uses datasets sourced from TREC 2014 Web Track dataset. sent: Article 1 uses datasets from the gemomics domain, while Article 2 uses dataset from various domains. sent: Article 1 uses 4 topics for the datasets, while Article 2 uses 11 topics for the datasets. sent:  Article 1 48 participants were recruited, while Article 2 468 participants were recruited.",sent: Article 1 and Article 2 use supervised learning approach. sent: Article 1 and Article 2 use diffferent behaviour features. sent: Article 1 and Article 2 use regression models to predict user knowledge.,"[['1609.05284', '1706.02596'], ['1706.02596', '1609.05284'], ['1606.07947', '1610.10099'], ['1610.10099', '1606.07947'], ['1808.07018', '1802.04394'], ['1802.04394', '1808.07018'], ['1808.06281', '1703.05693'], ['1703.05693', '1808.06281']]","['sent: Article 1 uses multiple datasets:  CNN   Daily Mail, and  SQuAD1 1, while Article 2 uses TriviaQA dataset.', 'sent: Article 1 uses TriviaQA dataset, while Article 2 uses multiple datasets:  CNN   Daily Mail, and  SQuAD1 1.', 'sent: Article 1 and Article 2 use WMT2014 English-German dataset. sent: Article 1 uses IWSLT2015 Thai-English dataset, while Article 2 uses multiple datasets:  WMT2014 English-French, and  WMT2015 English-German.', 'sent: Article 1 and Article 2 use WMT2014 English-German dataset. sent: Article 1 uses multiple datasets:  WMT2014 English-French, and  WMT2015 English-German, while Article 2 uses IWSLT2015 Thai-English dataset.', 'sent: Article 1 and Article 2 use WN18RR dataset. sent: Article 1 uses multiple datasets:  FB15k-237,   FB15k, and  WN18, while Article 2 does not use specific datasets for experiments.', 'sent: Article 1 and Article 2 use WN18RR dataset. sent: Article 1 does not use specific datasets for experiments, while Article 2 uses multiple datasets:  FB15k-237,   FB15k, and  WN18.', 'sent: Article 1 and Article 2 use DukeMTMC-reID dataset.sent: Article 1 and Article 2 use Market-1501 dataset.', 'sent: Article 1 and Article 2 use DukeMTMC-reID dataset.sent: Article 1 and Article 2 use Market-1501 dataset.']","['sent: Article 1 uses ReasoNet  ensemble  approach for Question Answering, while Article 2 uses Reading Twice for NLU for Question Answering. sent: Article 1 uses ReasoNet approach for Question Answering, while Article 2 uses Reading Twice for NLU for Question Answering. sent: Article 1 uses ReasoNet  single model  approach for Question Answering, while Article 2 uses Reading Twice for NLU for Question Answering.', 'sent: Article 1 uses Reading Twice for NLU approach for Question Answering, while Article 2 uses ReasoNet  ensemble  for Question Answering. sent: Article 1 uses Reading Twice for NLU approach for Question Answering, while Article 2 uses ReasoNet for Question Answering. sent: Article 1 uses Reading Twice for NLU approach for Question Answering, while Article 2 uses ReasoNet  single model  for Question Answering.', 'sent: Article 1 uses Seq-KD   Seq-Inter   Word-KD approach for Machine Translation, while Article 2 uses ByteNet for Machine Translation.', 'sent: Article 1 uses ByteNet approach for Machine Translation, while Article 2 uses Seq-KD   Seq-Inter   Word-KD for Machine Translation.', 'sent: Article 1 uses HypER approach for Link Prediction, while Article 2 uses M-Walk for Link Prediction.', 'sent: Article 1 uses M-Walk approach for Link Prediction, while Article 2 uses HypER for Link Prediction.', 'sent: Article 1 uses Incremental Learning approach for Person Re-Identification, while Article 2 uses SVDNet for Person Re-Identification.', 'sent: Article 1 uses SVDNet approach for Person Re-Identification, while Article 2 uses Incremental Learning for Person Re-Identification.']"
5,5,yg_paper_1,yg_paper_4,41,44,"sent: Article 1 uses datasets sourced from TREC Genomics collection, while Article 2 uses datasets sourced from TREC 2014 Web Track dataset. sent: Article 1 uses datasets from the gemomics domain, while Article 2 uses dataset from various domains. sent: Article 1 uses 4 topics for the datasets, while Article 2 uses 11 topics for the datasets. sent:  Article 1 48 participants were recruited, while Article 2 1100 search sessions were included.","sent: Article 1 and Article 2 use supervised learning approach. sent: Article 1 uses diffferent behaviour features, while Article 2 uses resource-centric features and behaviour featuress . sent: Article 1 uses regression models to predict user knowledge, while Article 2 uses Naive Bayes, Logistic Regression, SVM and Random Forest modesl to predict user knowledge.","[['1606.07947', '1610.10099'], ['1610.10099', '1606.07947'], ['1808.07018', '1802.04394'], ['1802.04394', '1808.07018'], ['1808.06281', '1703.05693'], ['1703.05693', '1808.06281'], ['1809.02279', '1505.07818'], ['1505.07818', '1809.02279']]","['sent: Article 1 and Article 2 use WMT2014 English-German dataset. sent: Article 1 uses IWSLT2015 Thai-English dataset, while Article 2 uses multiple datasets:  WMT2014 English-French, and  WMT2015 English-German.', 'sent: Article 1 and Article 2 use WMT2014 English-German dataset. sent: Article 1 uses multiple datasets:  WMT2014 English-French, and  WMT2015 English-German, while Article 2 uses IWSLT2015 Thai-English dataset.', 'sent: Article 1 and Article 2 use WN18RR dataset. sent: Article 1 uses multiple datasets:  FB15k-237,   FB15k, and  WN18, while Article 2 does not use specific datasets for experiments.', 'sent: Article 1 and Article 2 use WN18RR dataset. sent: Article 1 does not use specific datasets for experiments, while Article 2 uses multiple datasets:  FB15k-237,   FB15k, and  WN18.', 'sent: Article 1 and Article 2 use DukeMTMC-reID dataset.sent: Article 1 and Article 2 use Market-1501 dataset.', 'sent: Article 1 and Article 2 use DukeMTMC-reID dataset.sent: Article 1 and Article 2 use Market-1501 dataset.', 'sent: Article 1 uses multiple datasets:  SST-2 Binary classification,  SNLI,  SST-5 Fine-grained classification, and  Quora Question Pairs, while Article 2 uses Multi-Domain Sentiment Dataset dataset.', 'sent: Article 1 uses Multi-Domain Sentiment Dataset dataset, while Article 2 uses multiple datasets:  SST-2 Binary classification,  SNLI,  SST-5 Fine-grained classification, and  Quora Question Pairs.']","['sent: Article 1 uses Seq-KD   Seq-Inter   Word-KD approach for Machine Translation, while Article 2 uses ByteNet for Machine Translation.', 'sent: Article 1 uses ByteNet approach for Machine Translation, while Article 2 uses Seq-KD   Seq-Inter   Word-KD for Machine Translation.', 'sent: Article 1 uses HypER approach for Link Prediction, while Article 2 uses M-Walk for Link Prediction.', 'sent: Article 1 uses M-Walk approach for Link Prediction, while Article 2 uses HypER for Link Prediction.', 'sent: Article 1 uses Incremental Learning approach for Person Re-Identification, while Article 2 uses SVDNet for Person Re-Identification.', 'sent: Article 1 uses SVDNet approach for Person Re-Identification, while Article 2 uses Incremental Learning for Person Re-Identification.', 'sent: Article 1 uses Bi-CAS-LSTM approach for Sentiment Analysis, while Article 2 uses DANN for Sentiment Analysis. sent: Article 1 uses 300D 2-layer Bi-CAS-LSTM approach for Sentiment Analysis, while Article 2 uses DANN for Sentiment Analysis.', 'sent: Article 1 uses DANN approach for Sentiment Analysis, while Article 2 uses Bi-CAS-LSTM for Sentiment Analysis. sent: Article 1 uses DANN approach for Sentiment Analysis, while Article 2 uses 300D 2-layer Bi-CAS-LSTM for Sentiment Analysis.']"
6,6,yg_paper_2,yg_paper_4,42,44,"sent: Article 1 and  Article 2 use datasets sourced from TREC 2014 Web Track dataset. sent: Article 1 and Article use datasets from various domains. sent: Article 1 and Article 2 use 11 topics for the datasets. sent:  Article 1 468 participants were recruited, while Article 2 1100 search sessions were included.","sent: Article 1 and Article 2 use supervised learning approach. sent: Article 1 uses diffferent behaviour features, while Article 2 uses resource-centric features and behaviour featuress . sent: Article 1 uses regression models to predict user knowledge, while Article 2 uses Naive Bayes, Logistic Regression, SVM and Random Forest modesl to predict user knowledge.","[['1609.05284', '1706.02596'], ['1706.02596', '1609.05284'], ['1707.02968', '1603.05027'], ['1603.05027', '1707.02968'], ['1606.07947', '1610.10099'], ['1610.10099', '1606.07947'], ['1808.07018', '1802.04394'], ['1802.04394', '1808.07018'], ['1611.00144', '1601.02376'], ['1601.02376', '1611.00144']]","['sent: Article 1 uses multiple datasets:  CNN   Daily Mail, and  SQuAD1 1, while Article 2 uses TriviaQA dataset.', 'sent: Article 1 uses TriviaQA dataset, while Article 2 uses multiple datasets:  CNN   Daily Mail, and  SQuAD1 1.', 'sent: Article 1 uses multiple datasets:  ImageNet, and  PASCAL VOC 2012, while Article 2 uses multiple datasets:  CIFAR-10, and  CIFAR-100.', 'sent: Article 1 uses multiple datasets:  CIFAR-10, and  CIFAR-100, while Article 2 uses multiple datasets:  ImageNet, and  PASCAL VOC 2012.', 'sent: Article 1 and Article 2 use WMT2014 English-German dataset. sent: Article 1 uses IWSLT2015 Thai-English dataset, while Article 2 uses multiple datasets:  WMT2014 English-French, and  WMT2015 English-German.', 'sent: Article 1 and Article 2 use WMT2014 English-German dataset. sent: Article 1 uses multiple datasets:  WMT2014 English-French, and  WMT2015 English-German, while Article 2 uses IWSLT2015 Thai-English dataset.', 'sent: Article 1 and Article 2 use WN18RR dataset. sent: Article 1 uses multiple datasets:  FB15k-237,   FB15k, and  WN18, while Article 2 does not use specific datasets for experiments.', 'sent: Article 1 and Article 2 use WN18RR dataset. sent: Article 1 does not use specific datasets for experiments, while Article 2 uses multiple datasets:  FB15k-237,   FB15k, and  WN18.', 'sent: Article 1 and Article 2 use Company  dataset.sent: Article 1 and Article 2 use iPinYou dataset.sent: Article 1 and Article 2 use Criteo dataset. sent: Article 1 uses multiple datasets:  Amazon,  Bing News,  Dianping, and  MovieLens 20M, while Article 2 does not use specific datasets for experiments.', 'sent: Article 1 and Article 2 use Company  dataset.sent: Article 1 and Article 2 use iPinYou dataset.sent: Article 1 and Article 2 use Criteo dataset. sent: Article 1 does not use specific datasets for experiments, while Article 2 uses multiple datasets:  Amazon,  Bing News,  Dianping, and  MovieLens 20M.']","['sent: Article 1 uses ReasoNet  ensemble  approach for Question Answering, while Article 2 uses Reading Twice for NLU for Question Answering. sent: Article 1 uses ReasoNet approach for Question Answering, while Article 2 uses Reading Twice for NLU for Question Answering. sent: Article 1 uses ReasoNet  single model  approach for Question Answering, while Article 2 uses Reading Twice for NLU for Question Answering.', 'sent: Article 1 uses Reading Twice for NLU approach for Question Answering, while Article 2 uses ReasoNet  ensemble  for Question Answering. sent: Article 1 uses Reading Twice for NLU approach for Question Answering, while Article 2 uses ReasoNet for Question Answering. sent: Article 1 uses Reading Twice for NLU approach for Question Answering, while Article 2 uses ReasoNet  single model  for Question Answering.', 'sent: Article 1 uses JFT-300M Finetuning approach for Image Classification, while Article 2 uses ResNet-1001 for Image Classification. sent: Article 1 uses ImageNet JFT-300M Initialization approach for Image Classification, while Article 2 uses ResNet-1001 for Image Classification.', 'sent: Article 1 uses ResNet-1001 approach for Image Classification, while Article 2 uses JFT-300M Finetuning for Image Classification. sent: Article 1 uses ResNet-1001 approach for Image Classification, while Article 2 uses ImageNet JFT-300M Initialization for Image Classification.', 'sent: Article 1 uses Seq-KD   Seq-Inter   Word-KD approach for Machine Translation, while Article 2 uses ByteNet for Machine Translation.', 'sent: Article 1 uses ByteNet approach for Machine Translation, while Article 2 uses Seq-KD   Seq-Inter   Word-KD for Machine Translation.', 'sent: Article 1 uses HypER approach for Link Prediction, while Article 2 uses M-Walk for Link Prediction.', 'sent: Article 1 uses M-Walk approach for Link Prediction, while Article 2 uses HypER for Link Prediction.', 'sent: Article 1 uses IPNN approach for Click-Through Rate Prediction, while Article 2 uses FNN for Click-Through Rate Prediction. sent: Article 1 uses PNN approach for Click-Through Rate Prediction, while Article 2 uses FNN for Click-Through Rate Prediction. sent: Article 1 uses PNN  approach for Click-Through Rate Prediction, while Article 2 uses FNN for Click-Through Rate Prediction. sent: Article 1 uses OPNN approach for Click-Through Rate Prediction, while Article 2 uses FNN for Click-Through Rate Prediction.', 'sent: Article 1 uses FNN approach for Click-Through Rate Prediction, while Article 2 uses IPNN for Click-Through Rate Prediction. sent: Article 1 uses FNN approach for Click-Through Rate Prediction, while Article 2 uses PNN for Click-Through Rate Prediction. sent: Article 1 uses FNN approach for Click-Through Rate Prediction, while Article 2 uses PNN  for Click-Through Rate Prediction. sent: Article 1 uses FNN approach for Click-Through Rate Prediction, while Article 2 uses OPNN for Click-Through Rate Prediction.']"
7,7,ae_paper_1,ae_paper_2,51,52,sent: Article 1 and Article 2 use datasets sourced from SciDTB corpus from the ACL Anthology. sent: Article 1 and Article 2 use scientific datasets from Computational Linguistics domain. Article 1 and Article 2 use a subset of the SciDTB corpus of 60 abstracts.,"sent: Article 1 and Article 2 propose a fine-grained annotation schema for argument mining. sent: Article 1 and Article 2 use supervised learining approaches for identifying argumentative units, types, functions and attachments. sent: Article 1 uses non-neural (CRF) and neural (BiLSTM-ST for single task and BiLSTM-MT for multi task), while Article 2 uses transfere learning approach to improve the perfomance of argument mining model trained on small corpus. sent: Article 1: uses positional, syntactic and discourse features, while Article 2 uses DEmb, ELMo, Glove and RSTEnc embeddings.","[['1609.05284', '1706.02596'], ['1706.02596', '1609.05284'], ['1711.07399', '1803.02188'], ['1803.02188', '1711.07399'], ['1409.3215', '1610.10099'], ['1606.07947', '1610.10099'], ['1610.10099', '1409.3215'], ['1610.10099', '1606.07947'], ['1711.00199', '1902.01275'], ['1903.09359', '1804.01005']]","['sent: Article 1 uses multiple datasets:  CNN   Daily Mail, and  SQuAD1 1, while Article 2 uses TriviaQA dataset.', 'sent: Article 1 uses TriviaQA dataset, while Article 2 uses multiple datasets:  CNN   Daily Mail, and  SQuAD1 1.', 'sent: Article 1 uses multiple datasets:   ITOP front-view,  MSRA Hands,  ICVL Hands,  NYU Hands,  HANDS 2017, and  ITOP top-view, while Article 2 uses DensePose-COCO dataset.', 'sent: Article 1 uses DensePose-COCO dataset, while Article 2 uses multiple datasets:   ITOP front-view,  MSRA Hands,  ICVL Hands,  NYU Hands,  HANDS 2017, and  ITOP top-view.', 'sent: Article 1 and Article 2 use WMT2014 English-French dataset. sent: Article 1 does not use specific datasets for experiments, while Article 2 uses multiple datasets:  WMT2014 English-German, and  WMT2015 English-German.', 'sent: Article 1 and Article 2 use WMT2014 English-German dataset. sent: Article 1 uses IWSLT2015 Thai-English dataset, while Article 2 uses multiple datasets:  WMT2014 English-French, and  WMT2015 English-German.', 'sent: Article 1 and Article 2 use WMT2014 English-French dataset. sent: Article 1 uses multiple datasets:  WMT2014 English-German, and  WMT2015 English-German, while Article 2 does not use specific datasets for experiments.', 'sent: Article 1 and Article 2 use WMT2014 English-German dataset. sent: Article 1 uses multiple datasets:  WMT2014 English-French, and  WMT2015 English-German, while Article 2 uses IWSLT2015 Thai-English dataset.', 'sent: Article 1 uses multiple datasets:  LineMOD,  YCB-Video, and  OccludedLINEMOD, while Article 2 uses T-LESS dataset.', 'sent: Article 1 and Article 2 use AFLW2000-3D dataset. sent: Article 1 does not use specific datasets for experiments, while Article 2 uses multiple datasets:  AFLW2000,  BIWI, and  Florence.']","['sent: Article 1 uses ReasoNet  ensemble  approach for Question Answering, while Article 2 uses Reading Twice for NLU for Question Answering. sent: Article 1 uses ReasoNet approach for Question Answering, while Article 2 uses Reading Twice for NLU for Question Answering. sent: Article 1 uses ReasoNet  single model  approach for Question Answering, while Article 2 uses Reading Twice for NLU for Question Answering.', 'sent: Article 1 uses Reading Twice for NLU approach for Question Answering, while Article 2 uses ReasoNet  ensemble  for Question Answering. sent: Article 1 uses Reading Twice for NLU approach for Question Answering, while Article 2 uses ReasoNet for Question Answering. sent: Article 1 uses Reading Twice for NLU approach for Question Answering, while Article 2 uses ReasoNet  single model  for Question Answering.', 'sent: Article 1 uses V2V-PoseNet approach for Pose Estimation, while Article 2 uses DensePose   keypoints for Pose Estimation.', 'sent: Article 1 uses DensePose   keypoints approach for Pose Estimation, while Article 2 uses V2V-PoseNet for Pose Estimation.', 'sent: Article 1 uses LSTM approach for Machine Translation, while Article 2 uses ByteNet for Machine Translation. sent: Article 1 uses SMT LSTM5 approach for Machine Translation, while Article 2 uses ByteNet for Machine Translation.', 'sent: Article 1 uses Seq-KD   Seq-Inter   Word-KD approach for Machine Translation, while Article 2 uses ByteNet for Machine Translation.', 'sent: Article 1 uses ByteNet approach for Machine Translation, while Article 2 uses LSTM for Machine Translation. sent: Article 1 uses ByteNet approach for Machine Translation, while Article 2 uses SMT LSTM5 for Machine Translation.', 'sent: Article 1 uses ByteNet approach for Machine Translation, while Article 2 uses Seq-KD   Seq-Inter   Word-KD for Machine Translation.', 'sent: Article 1 uses PoseCNN approach for 6D Pose Estimation, while Article 2 uses RetinaNet Augmented Autoencoders ICP for 6D Pose Estimation. sent: Article 1 uses PoseCNN   ICP approach for 6D Pose Estimation, while Article 2 uses RetinaNet Augmented Autoencoders ICP for 6D Pose Estimation.', 'sent: Article 1 uses 2DASL approach for Face Alignment, while Article 2 uses 3DDFA for Face Alignment. sent: Article 1 uses 2DASL approach for Face Alignment, while Article 2 uses 3DDFA   SDM for Face Alignment.']"
8,8,ae_paper_1,ae_paper_3,51,53,sent: Article 1 and Article 2 use datasets sourced from SciDTB corpus from the ACL Anthology. sent: Article 1 and Article 2 use scientific datasets from Computational Linguistics domain. Article 1 and Article 2 use a subset of the SciDTB corpus of 60 abstracts.,"sent: Article 1 and Article 2 propose a fine-grained annotation schema for argument mining. sent: Article 1 and Article 2 use supervised learining approaches for identifying argumentative units, types, functions and attachments. sent: Article 1 uses non-neural (CRF) and neural (BiLSTM-ST for single task and BiLSTM-MT for multi task), while Article 2 uses two transfere learning approaches (multi-task learning and sequential learning) to improve the perfomance of argument mining model trained on small corpus. sent: Article 1: uses positional, syntactic and discourse features, while Article 2 uses DEmb, ELMo, and RSTEnc embeddings.","[['1509.08985', '1603.05027'], ['1707.02968', '1603.05027'], ['1603.05027', '1509.08985'], ['1603.05027', '1707.02968'], ['1603.06147', '1610.10099'], ['1606.07947', '1610.10099'], ['1610.10099', '1511.06732'], ['1610.10099', '1603.06147'], ['1610.10099', '1606.07947'], ['1610.10099', '1711.01068'], ['1511.06732', '1610.10099'], ['1711.01068', '1610.10099']]","['sent: Article 1 and Article 2 use CIFAR-10 dataset.sent: Article 1 and Article 2 use CIFAR-100 dataset. sent: Article 1 uses multiple datasets:  SVHN, and  MNIST, while Article 2 does not use specific datasets for experiments.', 'sent: Article 1 uses multiple datasets:  ImageNet, and  PASCAL VOC 2012, while Article 2 uses multiple datasets:  CIFAR-10, and  CIFAR-100.', 'sent: Article 1 and Article 2 use CIFAR-10 dataset.sent: Article 1 and Article 2 use CIFAR-100 dataset. sent: Article 1 does not use specific datasets for experiments, while Article 2 uses multiple datasets:  SVHN, and  MNIST.', 'sent: Article 1 uses multiple datasets:  CIFAR-10, and  CIFAR-100, while Article 2 uses multiple datasets:  ImageNet, and  PASCAL VOC 2012.', 'sent: Article 1 and Article 2 use WMT2015 English-German dataset. sent: Article 1 does not use specific datasets for experiments, while Article 2 uses multiple datasets:  WMT2014 English-German, and  WMT2014 English-French.', 'sent: Article 1 and Article 2 use WMT2014 English-German dataset. sent: Article 1 uses IWSLT2015 Thai-English dataset, while Article 2 uses multiple datasets:  WMT2014 English-French, and  WMT2015 English-German.', 'sent: Article 1 uses multiple datasets:  WMT2014 English-German,  WMT2014 English-French, and  WMT2015 English-German, while Article 2 uses IWSLT2015 German-English dataset.', 'sent: Article 1 and Article 2 use WMT2015 English-German dataset. sent: Article 1 uses multiple datasets:  WMT2014 English-German, and  WMT2014 English-French, while Article 2 does not use specific datasets for experiments.', 'sent: Article 1 and Article 2 use WMT2014 English-German dataset. sent: Article 1 uses multiple datasets:  WMT2014 English-French, and  WMT2015 English-German, while Article 2 uses IWSLT2015 Thai-English dataset.', 'sent: Article 1 uses multiple datasets:  WMT2014 English-German,  WMT2014 English-French, and  WMT2015 English-German, while Article 2 uses IWSLT2015 German-English dataset.', 'sent: Article 1 uses IWSLT2015 German-English dataset, while Article 2 uses multiple datasets:  WMT2014 English-German,  WMT2014 English-French, and  WMT2015 English-German.', 'sent: Article 1 uses IWSLT2015 German-English dataset, while Article 2 uses multiple datasets:  WMT2014 English-German,  WMT2014 English-French, and  WMT2015 English-German.']","['sent: Article 1 uses Tree Max-Avg pooling approach for Image Classification, while Article 2 uses ResNet-1001 for Image Classification.', 'sent: Article 1 uses JFT-300M Finetuning approach for Image Classification, while Article 2 uses ResNet-1001 for Image Classification. sent: Article 1 uses ImageNet JFT-300M Initialization approach for Image Classification, while Article 2 uses ResNet-1001 for Image Classification.', 'sent: Article 1 uses ResNet-1001 approach for Image Classification, while Article 2 uses Tree Max-Avg pooling for Image Classification.', 'sent: Article 1 uses ResNet-1001 approach for Image Classification, while Article 2 uses JFT-300M Finetuning for Image Classification. sent: Article 1 uses ResNet-1001 approach for Image Classification, while Article 2 uses ImageNet JFT-300M Initialization for Image Classification.', 'sent: Article 1 uses Enc-Dec Att  char  approach for Machine Translation, while Article 2 uses ByteNet for Machine Translation. sent: Article 1 uses Enc-Dec Att  BPE  approach for Machine Translation, while Article 2 uses ByteNet for Machine Translation.', 'sent: Article 1 uses Seq-KD   Seq-Inter   Word-KD approach for Machine Translation, while Article 2 uses ByteNet for Machine Translation.', 'sent: Article 1 uses ByteNet approach for Machine Translation, while Article 2 uses Word-level LSTM w attn for Machine Translation.', 'sent: Article 1 uses ByteNet approach for Machine Translation, while Article 2 uses Enc-Dec Att  char  for Machine Translation. sent: Article 1 uses ByteNet approach for Machine Translation, while Article 2 uses Enc-Dec Att  BPE  for Machine Translation.', 'sent: Article 1 uses ByteNet approach for Machine Translation, while Article 2 uses Seq-KD   Seq-Inter   Word-KD for Machine Translation.', 'sent: Article 1 uses ByteNet approach for Machine Translation, while Article 2 uses DCCL for Machine Translation.', 'sent: Article 1 uses Word-level LSTM w attn approach for Machine Translation, while Article 2 uses ByteNet for Machine Translation.', 'sent: Article 1 uses DCCL approach for Machine Translation, while Article 2 uses ByteNet for Machine Translation.']"
9,9,ae_paper_1,ae_paper_4,51,54,"sent: Article 1 uses datasets sourced from SciDTB corpus from the ACL Anthology, while Article 2 uses SciArg corpus sourced from ACL Anthology and MEDLINE/PubMed. sent: Article 1 uses scientific datasets from Computational Linguistics domain, while Article 2 uses scientific datasets from Computational Linguistics and Biomedical domain. Article 1 uses a subset of the SciDTB corpus of 60 abstracts, while Article 2 uses 510 scientific abstracts (225 from Computation Linguistics and 285 from Biomedicine).","sent: Article 1 proposes a fine-grained annotation schema for argument mining, while Article 2 uses a refined annotation schema on sentence level for argument mining. sent: Article 1 and Article 2 use supervised learining approaches for identifying argumentative units, types, functions and attachments. sent: Article 1 uses non-neural (CRF) and neural (BiLSTM-ST for single task and BiLSTM-MT for multi task), while Article 2 uses fine-tune and evaluate BERT-based argument mining models (in single and muti-task settings). sent: Article 1: uses positional, syntactic and discourse features, while Article 2 uses BERT representations.","[['1804.01005', '1703.07834'], ['1509.08985', '1603.05027'], ['1707.02968', '1603.05027'], ['1603.05027', '1509.08985'], ['1603.05027', '1707.02968'], ['1711.07399', '1803.02188'], ['1803.02188', '1711.07399'], ['1409.3215', '1610.10099'], ['1705.03122', '1610.10099'], ['1610.10099', '1705.03122'], ['1610.10099', '1409.3215'], ['1711.00199', '1902.01275'], ['1903.09359', '1804.01005']]","['sent: Article 1 and Article 2 use Florence dataset. sent: Article 1 uses multiple datasets:  AFLW2000,  BIWI, and  AFLW2000-3D, while Article 2 does not use specific datasets for experiments.', 'sent: Article 1 and Article 2 use CIFAR-10 dataset.sent: Article 1 and Article 2 use CIFAR-100 dataset. sent: Article 1 uses multiple datasets:  SVHN, and  MNIST, while Article 2 does not use specific datasets for experiments.', 'sent: Article 1 uses multiple datasets:  ImageNet, and  PASCAL VOC 2012, while Article 2 uses multiple datasets:  CIFAR-10, and  CIFAR-100.', 'sent: Article 1 and Article 2 use CIFAR-10 dataset.sent: Article 1 and Article 2 use CIFAR-100 dataset. sent: Article 1 does not use specific datasets for experiments, while Article 2 uses multiple datasets:  SVHN, and  MNIST.', 'sent: Article 1 uses multiple datasets:  CIFAR-10, and  CIFAR-100, while Article 2 uses multiple datasets:  ImageNet, and  PASCAL VOC 2012.', 'sent: Article 1 uses multiple datasets:   ITOP front-view,  MSRA Hands,  ICVL Hands,  NYU Hands,  HANDS 2017, and  ITOP top-view, while Article 2 uses DensePose-COCO dataset.', 'sent: Article 1 uses DensePose-COCO dataset, while Article 2 uses multiple datasets:   ITOP front-view,  MSRA Hands,  ICVL Hands,  NYU Hands,  HANDS 2017, and  ITOP top-view.', 'sent: Article 1 and Article 2 use WMT2014 English-French dataset. sent: Article 1 does not use specific datasets for experiments, while Article 2 uses multiple datasets:  WMT2014 English-German, and  WMT2015 English-German.', 'sent: Article 1 and Article 2 use WMT2014 English-German dataset.sent: Article 1 and Article 2 use WMT2014 English-French dataset. sent: Article 1 uses multiple datasets:  IWSLT2015 German-English,  WMT2016 English-Romanian, and  IWSLT2015 English-German, while Article 2 uses WMT2015 English-German dataset.', 'sent: Article 1 and Article 2 use WMT2014 English-German dataset.sent: Article 1 and Article 2 use WMT2014 English-French dataset. sent: Article 1 uses WMT2015 English-German dataset, while Article 2 uses multiple datasets:  IWSLT2015 German-English,  WMT2016 English-Romanian, and  IWSLT2015 English-German.', 'sent: Article 1 and Article 2 use WMT2014 English-French dataset. sent: Article 1 uses multiple datasets:  WMT2014 English-German, and  WMT2015 English-German, while Article 2 does not use specific datasets for experiments.', 'sent: Article 1 uses multiple datasets:  LineMOD,  YCB-Video, and  OccludedLINEMOD, while Article 2 uses T-LESS dataset.', 'sent: Article 1 and Article 2 use AFLW2000-3D dataset. sent: Article 1 does not use specific datasets for experiments, while Article 2 uses multiple datasets:  AFLW2000,  BIWI, and  Florence.']","['sent: Article 1 uses 3DDFA approach for 3D Face Reconstruction, while Article 2 uses VRN-Guided for 3D Face Reconstruction. sent: Article 1 uses 3DDFA   SDM approach for 3D Face Reconstruction, while Article 2 uses VRN-Guided for 3D Face Reconstruction.', 'sent: Article 1 uses Tree Max-Avg pooling approach for Image Classification, while Article 2 uses ResNet-1001 for Image Classification.', 'sent: Article 1 uses JFT-300M Finetuning approach for Image Classification, while Article 2 uses ResNet-1001 for Image Classification. sent: Article 1 uses ImageNet JFT-300M Initialization approach for Image Classification, while Article 2 uses ResNet-1001 for Image Classification.', 'sent: Article 1 uses ResNet-1001 approach for Image Classification, while Article 2 uses Tree Max-Avg pooling for Image Classification.', 'sent: Article 1 uses ResNet-1001 approach for Image Classification, while Article 2 uses JFT-300M Finetuning for Image Classification. sent: Article 1 uses ResNet-1001 approach for Image Classification, while Article 2 uses ImageNet JFT-300M Initialization for Image Classification.', 'sent: Article 1 uses V2V-PoseNet approach for Pose Estimation, while Article 2 uses DensePose   keypoints for Pose Estimation.', 'sent: Article 1 uses DensePose   keypoints approach for Pose Estimation, while Article 2 uses V2V-PoseNet for Pose Estimation.', 'sent: Article 1 uses LSTM approach for Machine Translation, while Article 2 uses ByteNet for Machine Translation. sent: Article 1 uses SMT LSTM5 approach for Machine Translation, while Article 2 uses ByteNet for Machine Translation.', 'sent: Article 1 uses ConvS2S  ensemble  approach for Machine Translation, while Article 2 uses ByteNet for Machine Translation. sent: Article 1 uses ConvS2S approach for Machine Translation, while Article 2 uses ByteNet for Machine Translation. sent: Article 1 uses ConvS2S BPE40k approach for Machine Translation, while Article 2 uses ByteNet for Machine Translation.', 'sent: Article 1 uses ByteNet approach for Machine Translation, while Article 2 uses ConvS2S  ensemble  for Machine Translation. sent: Article 1 uses ByteNet approach for Machine Translation, while Article 2 uses ConvS2S for Machine Translation. sent: Article 1 uses ByteNet approach for Machine Translation, while Article 2 uses ConvS2S BPE40k for Machine Translation.', 'sent: Article 1 uses ByteNet approach for Machine Translation, while Article 2 uses LSTM for Machine Translation. sent: Article 1 uses ByteNet approach for Machine Translation, while Article 2 uses SMT LSTM5 for Machine Translation.', 'sent: Article 1 uses PoseCNN approach for 6D Pose Estimation, while Article 2 uses RetinaNet Augmented Autoencoders ICP for 6D Pose Estimation. sent: Article 1 uses PoseCNN   ICP approach for 6D Pose Estimation, while Article 2 uses RetinaNet Augmented Autoencoders ICP for 6D Pose Estimation.', 'sent: Article 1 uses 2DASL approach for Face Alignment, while Article 2 uses 3DDFA for Face Alignment. sent: Article 1 uses 2DASL approach for Face Alignment, while Article 2 uses 3DDFA   SDM for Face Alignment.']"
10,10,ae_paper_2,ae_paper_3,52,53,sent: Article 1 and Article 2 use datasets sourced from SciDTB corpus from the ACL Anthology. sent: Article 1 and Article 2 use scientific datasets from Computational Linguistics domain. Article 1 and Article 2 use a subset of the SciDTB corpus of 60 abstracts.,"sent: Article 1 and Article 2 propose a fine-grained annotation schema for argument mining. sent: Article 1 and Article 2 use supervised learining approaches for identifying argumentative units, types, functions and attachments. sent: Article 1 uses transfere learning approach to improve the perfomance of argument mining model trained on small corpus, while Article 2 uses two transfere learning approaches (multi-task learning and sequential learning) to improve the perfomance of argument mining model trained on small corpus. sent: Article 1: DEmb, ELMo, Glove and RSTEnc embeddings, while Article 2 uses DEmb, ELMo, and RSTEnc embeddings.","[['1609.05284', '1706.02596'], ['1706.02596', '1609.05284'], ['1603.06147', '1409.3215'], ['1603.06147', '1606.07947'], ['1409.3215', '1606.07947'], ['1409.3215', '1610.10099'], ['1409.3215', '1511.06732'], ['1409.3215', '1603.06147'], ['1409.3215', '1711.01068'], ['1606.07947', '1610.10099'], ['1606.07947', '1409.3215'], ['1606.07947', '1511.06732'], ['1606.07947', '1603.06147'], ['1606.07947', '1711.01068'], ['1610.10099', '1409.3215'], ['1610.10099', '1606.07947'], ['1511.06732', '1606.07947'], ['1808.07018', '1606.06357'], ['1606.06357', '1808.07018']]","['sent: Article 1 uses multiple datasets:  CNN   Daily Mail, and  SQuAD1 1, while Article 2 uses TriviaQA dataset.', 'sent: Article 1 uses TriviaQA dataset, while Article 2 uses multiple datasets:  CNN   Daily Mail, and  SQuAD1 1.', 'sent: Article 1 uses WMT2015 English-German dataset, while Article 2 uses WMT2014 English-French dataset.', 'sent: Article 1 uses WMT2015 English-German dataset, while Article 2 uses multiple datasets:  WMT2014 English-German, and  IWSLT2015 Thai-English.', 'sent: Article 1 uses WMT2014 English-French dataset, while Article 2 uses multiple datasets:  WMT2014 English-German, and  IWSLT2015 Thai-English.', 'sent: Article 1 and Article 2 use WMT2014 English-French dataset. sent: Article 1 does not use specific datasets for experiments, while Article 2 uses multiple datasets:  WMT2014 English-German, and  WMT2015 English-German.', 'sent: Article 1 uses WMT2014 English-French dataset, while Article 2 uses IWSLT2015 German-English dataset.', 'sent: Article 1 uses WMT2014 English-French dataset, while Article 2 uses WMT2015 English-German dataset.', 'sent: Article 1 uses WMT2014 English-French dataset, while Article 2 uses IWSLT2015 German-English dataset.', 'sent: Article 1 and Article 2 use WMT2014 English-German dataset. sent: Article 1 uses IWSLT2015 Thai-English dataset, while Article 2 uses multiple datasets:  WMT2014 English-French, and  WMT2015 English-German.', 'sent: Article 1 uses multiple datasets:  WMT2014 English-German, and  IWSLT2015 Thai-English, while Article 2 uses WMT2014 English-French dataset.', 'sent: Article 1 uses multiple datasets:  WMT2014 English-German, and  IWSLT2015 Thai-English, while Article 2 uses IWSLT2015 German-English dataset.', 'sent: Article 1 uses multiple datasets:  WMT2014 English-German, and  IWSLT2015 Thai-English, while Article 2 uses WMT2015 English-German dataset.', 'sent: Article 1 uses multiple datasets:  WMT2014 English-German, and  IWSLT2015 Thai-English, while Article 2 uses IWSLT2015 German-English dataset.', 'sent: Article 1 and Article 2 use WMT2014 English-French dataset. sent: Article 1 uses multiple datasets:  WMT2014 English-German, and  WMT2015 English-German, while Article 2 does not use specific datasets for experiments.', 'sent: Article 1 and Article 2 use WMT2014 English-German dataset. sent: Article 1 uses multiple datasets:  WMT2014 English-French, and  WMT2015 English-German, while Article 2 uses IWSLT2015 Thai-English dataset.', 'sent: Article 1 uses IWSLT2015 German-English dataset, while Article 2 uses multiple datasets:  WMT2014 English-German, and  IWSLT2015 Thai-English.', 'sent: Article 1 and Article 2 use WN18 dataset. sent: Article 1 uses multiple datasets:  FB15k-237,   FB15k, and  WN18RR, while Article 2 does not use specific datasets for experiments.', 'sent: Article 1 and Article 2 use WN18 dataset. sent: Article 1 does not use specific datasets for experiments, while Article 2 uses multiple datasets:  FB15k-237,   FB15k, and  WN18RR.']","['sent: Article 1 uses ReasoNet  ensemble  approach for Question Answering, while Article 2 uses Reading Twice for NLU for Question Answering. sent: Article 1 uses ReasoNet approach for Question Answering, while Article 2 uses Reading Twice for NLU for Question Answering. sent: Article 1 uses ReasoNet  single model  approach for Question Answering, while Article 2 uses Reading Twice for NLU for Question Answering.', 'sent: Article 1 uses Reading Twice for NLU approach for Question Answering, while Article 2 uses ReasoNet  ensemble  for Question Answering. sent: Article 1 uses Reading Twice for NLU approach for Question Answering, while Article 2 uses ReasoNet for Question Answering. sent: Article 1 uses Reading Twice for NLU approach for Question Answering, while Article 2 uses ReasoNet  single model  for Question Answering.', 'sent: Article 1 uses Enc-Dec Att  char  approach for Machine Translation, while Article 2 uses LSTM for Machine Translation. sent: Article 1 uses Enc-Dec Att  char  approach for Machine Translation, while Article 2 uses SMT LSTM5 for Machine Translation. sent: Article 1 uses Enc-Dec Att  BPE  approach for Machine Translation, while Article 2 uses LSTM for Machine Translation. sent: Article 1 uses Enc-Dec Att  BPE  approach for Machine Translation, while Article 2 uses SMT LSTM5 for Machine Translation.', 'sent: Article 1 uses Enc-Dec Att  char  approach for Machine Translation, while Article 2 uses Seq-KD   Seq-Inter   Word-KD for Machine Translation. sent: Article 1 uses Enc-Dec Att  BPE  approach for Machine Translation, while Article 2 uses Seq-KD   Seq-Inter   Word-KD for Machine Translation.', 'sent: Article 1 uses LSTM approach for Machine Translation, while Article 2 uses Seq-KD   Seq-Inter   Word-KD for Machine Translation. sent: Article 1 uses SMT LSTM5 approach for Machine Translation, while Article 2 uses Seq-KD   Seq-Inter   Word-KD for Machine Translation.', 'sent: Article 1 uses LSTM approach for Machine Translation, while Article 2 uses ByteNet for Machine Translation. sent: Article 1 uses SMT LSTM5 approach for Machine Translation, while Article 2 uses ByteNet for Machine Translation.', 'sent: Article 1 uses LSTM approach for Machine Translation, while Article 2 uses Word-level LSTM w attn for Machine Translation. sent: Article 1 uses SMT LSTM5 approach for Machine Translation, while Article 2 uses Word-level LSTM w attn for Machine Translation.', 'sent: Article 1 uses LSTM approach for Machine Translation, while Article 2 uses Enc-Dec Att  char  for Machine Translation. sent: Article 1 uses LSTM approach for Machine Translation, while Article 2 uses Enc-Dec Att  BPE  for Machine Translation. sent: Article 1 uses SMT LSTM5 approach for Machine Translation, while Article 2 uses Enc-Dec Att  char  for Machine Translation. sent: Article 1 uses SMT LSTM5 approach for Machine Translation, while Article 2 uses Enc-Dec Att  BPE  for Machine Translation.', 'sent: Article 1 uses LSTM approach for Machine Translation, while Article 2 uses DCCL for Machine Translation. sent: Article 1 uses SMT LSTM5 approach for Machine Translation, while Article 2 uses DCCL for Machine Translation.', 'sent: Article 1 uses Seq-KD   Seq-Inter   Word-KD approach for Machine Translation, while Article 2 uses ByteNet for Machine Translation.', 'sent: Article 1 uses Seq-KD   Seq-Inter   Word-KD approach for Machine Translation, while Article 2 uses LSTM for Machine Translation. sent: Article 1 uses Seq-KD   Seq-Inter   Word-KD approach for Machine Translation, while Article 2 uses SMT LSTM5 for Machine Translation.', 'sent: Article 1 uses Seq-KD   Seq-Inter   Word-KD approach for Machine Translation, while Article 2 uses Word-level LSTM w attn for Machine Translation.', 'sent: Article 1 uses Seq-KD   Seq-Inter   Word-KD approach for Machine Translation, while Article 2 uses Enc-Dec Att  char  for Machine Translation. sent: Article 1 uses Seq-KD   Seq-Inter   Word-KD approach for Machine Translation, while Article 2 uses Enc-Dec Att  BPE  for Machine Translation.', 'sent: Article 1 uses Seq-KD   Seq-Inter   Word-KD approach for Machine Translation, while Article 2 uses DCCL for Machine Translation.', 'sent: Article 1 uses ByteNet approach for Machine Translation, while Article 2 uses LSTM for Machine Translation. sent: Article 1 uses ByteNet approach for Machine Translation, while Article 2 uses SMT LSTM5 for Machine Translation.', 'sent: Article 1 uses ByteNet approach for Machine Translation, while Article 2 uses Seq-KD   Seq-Inter   Word-KD for Machine Translation.', 'sent: Article 1 uses Word-level LSTM w attn approach for Machine Translation, while Article 2 uses Seq-KD   Seq-Inter   Word-KD for Machine Translation.', 'sent: Article 1 uses HypER approach for Link Prediction, while Article 2 uses ComplEx for Link Prediction.', 'sent: Article 1 uses ComplEx approach for Link Prediction, while Article 2 uses HypER for Link Prediction.']"
11,11,ae_paper_2,ae_paper_4,52,54,"sent: Article 1 uses datasets sourced from SciDTB corpus from the ACL Anthology, while Article 2 uses SciArg corpus sourced from ACL Anthology and MEDLINE/PubMed. sent: Article 1 uses scientific datasets from Computational Linguistics domain, while Article 2 uses scientific datasets from Computational Linguistics and Biomedical domain. Article 1 uses a subset of the SciDTB corpus of 60 abstracts, while Article 2 uses 510 scientific abstracts (225 from Computation Linguistics and 285 from Biomedicine).","sent: Article 1 proposes a fine-grained annotation schema for argument mining, while Article 2 uses a refined annotation schema on sentence level for argument mining. sent: Article 1 and Article 2 use supervised learining approaches for identifying argumentative units, types, functions and attachments. sent: Article 1 uses transfere learning approach to improve the perfomance of argument mining model trained on small corpus, while Article 2 uses fine-tune and evaluate BERT-based argument mining models (in single and muti-task settings). sent: Article 1: DEmb, ELMo, Glove and RSTEnc embeddings, while Article 2 uses BERT representations.","[['1609.05284', '1706.02596'], ['1706.02596', '1609.05284'], ['1409.3215', '1606.07947'], ['1409.3215', '1705.03122'], ['1409.3215', '1610.10099'], ['1606.07947', '1705.03122'], ['1606.07947', '1610.10099'], ['1606.07947', '1409.3215'], ['1705.03122', '1409.3215'], ['1705.03122', '1606.07947'], ['1610.10099', '1409.3215'], ['1610.10099', '1606.07947']]","['sent: Article 1 uses multiple datasets:  CNN   Daily Mail, and  SQuAD1 1, while Article 2 uses TriviaQA dataset.', 'sent: Article 1 uses TriviaQA dataset, while Article 2 uses multiple datasets:  CNN   Daily Mail, and  SQuAD1 1.', 'sent: Article 1 uses WMT2014 English-French dataset, while Article 2 uses multiple datasets:  WMT2014 English-German, and  IWSLT2015 Thai-English.', 'sent: Article 1 and Article 2 use WMT2014 English-French dataset. sent: Article 1 does not use specific datasets for experiments, while Article 2 uses multiple datasets:  WMT2014 English-German,  WMT2016 English-Romanian,  IWSLT2015 English-German, and  IWSLT2015 German-English.', 'sent: Article 1 and Article 2 use WMT2014 English-French dataset. sent: Article 1 does not use specific datasets for experiments, while Article 2 uses multiple datasets:  WMT2014 English-German, and  WMT2015 English-German.', 'sent: Article 1 and Article 2 use WMT2014 English-German dataset. sent: Article 1 uses IWSLT2015 Thai-English dataset, while Article 2 uses multiple datasets:  IWSLT2015 German-English,  WMT2016 English-Romanian,  WMT2014 English-French, and  IWSLT2015 English-German.', 'sent: Article 1 and Article 2 use WMT2014 English-German dataset. sent: Article 1 uses IWSLT2015 Thai-English dataset, while Article 2 uses multiple datasets:  WMT2014 English-French, and  WMT2015 English-German.', 'sent: Article 1 uses multiple datasets:  WMT2014 English-German, and  IWSLT2015 Thai-English, while Article 2 uses WMT2014 English-French dataset.', 'sent: Article 1 and Article 2 use WMT2014 English-French dataset. sent: Article 1 uses multiple datasets:  WMT2014 English-German,  WMT2016 English-Romanian,  IWSLT2015 English-German, and  IWSLT2015 German-English, while Article 2 does not use specific datasets for experiments.', 'sent: Article 1 and Article 2 use WMT2014 English-German dataset. sent: Article 1 uses multiple datasets:  IWSLT2015 German-English,  WMT2016 English-Romanian,  WMT2014 English-French, and  IWSLT2015 English-German, while Article 2 uses IWSLT2015 Thai-English dataset.', 'sent: Article 1 and Article 2 use WMT2014 English-French dataset. sent: Article 1 uses multiple datasets:  WMT2014 English-German, and  WMT2015 English-German, while Article 2 does not use specific datasets for experiments.', 'sent: Article 1 and Article 2 use WMT2014 English-German dataset. sent: Article 1 uses multiple datasets:  WMT2014 English-French, and  WMT2015 English-German, while Article 2 uses IWSLT2015 Thai-English dataset.']","['sent: Article 1 uses ReasoNet  ensemble  approach for Question Answering, while Article 2 uses Reading Twice for NLU for Question Answering. sent: Article 1 uses ReasoNet approach for Question Answering, while Article 2 uses Reading Twice for NLU for Question Answering. sent: Article 1 uses ReasoNet  single model  approach for Question Answering, while Article 2 uses Reading Twice for NLU for Question Answering.', 'sent: Article 1 uses Reading Twice for NLU approach for Question Answering, while Article 2 uses ReasoNet  ensemble  for Question Answering. sent: Article 1 uses Reading Twice for NLU approach for Question Answering, while Article 2 uses ReasoNet for Question Answering. sent: Article 1 uses Reading Twice for NLU approach for Question Answering, while Article 2 uses ReasoNet  single model  for Question Answering.', 'sent: Article 1 uses LSTM approach for Machine Translation, while Article 2 uses Seq-KD   Seq-Inter   Word-KD for Machine Translation. sent: Article 1 uses SMT LSTM5 approach for Machine Translation, while Article 2 uses Seq-KD   Seq-Inter   Word-KD for Machine Translation.', 'sent: Article 1 uses LSTM approach for Machine Translation, while Article 2 uses ConvS2S  ensemble  for Machine Translation. sent: Article 1 uses LSTM approach for Machine Translation, while Article 2 uses ConvS2S for Machine Translation. sent: Article 1 uses LSTM approach for Machine Translation, while Article 2 uses ConvS2S BPE40k for Machine Translation. sent: Article 1 uses SMT LSTM5 approach for Machine Translation, while Article 2 uses ConvS2S  ensemble  for Machine Translation. sent: Article 1 uses SMT LSTM5 approach for Machine Translation, while Article 2 uses ConvS2S for Machine Translation. sent: Article 1 uses SMT LSTM5 approach for Machine Translation, while Article 2 uses ConvS2S BPE40k for Machine Translation.', 'sent: Article 1 uses LSTM approach for Machine Translation, while Article 2 uses ByteNet for Machine Translation. sent: Article 1 uses SMT LSTM5 approach for Machine Translation, while Article 2 uses ByteNet for Machine Translation.', 'sent: Article 1 uses Seq-KD   Seq-Inter   Word-KD approach for Machine Translation, while Article 2 uses ConvS2S  ensemble  for Machine Translation. sent: Article 1 uses Seq-KD   Seq-Inter   Word-KD approach for Machine Translation, while Article 2 uses ConvS2S for Machine Translation. sent: Article 1 uses Seq-KD   Seq-Inter   Word-KD approach for Machine Translation, while Article 2 uses ConvS2S BPE40k for Machine Translation.', 'sent: Article 1 uses Seq-KD   Seq-Inter   Word-KD approach for Machine Translation, while Article 2 uses ByteNet for Machine Translation.', 'sent: Article 1 uses Seq-KD   Seq-Inter   Word-KD approach for Machine Translation, while Article 2 uses LSTM for Machine Translation. sent: Article 1 uses Seq-KD   Seq-Inter   Word-KD approach for Machine Translation, while Article 2 uses SMT LSTM5 for Machine Translation.', 'sent: Article 1 uses ConvS2S  ensemble  approach for Machine Translation, while Article 2 uses LSTM for Machine Translation. sent: Article 1 uses ConvS2S  ensemble  approach for Machine Translation, while Article 2 uses SMT LSTM5 for Machine Translation. sent: Article 1 uses ConvS2S approach for Machine Translation, while Article 2 uses LSTM for Machine Translation. sent: Article 1 uses ConvS2S approach for Machine Translation, while Article 2 uses SMT LSTM5 for Machine Translation. sent: Article 1 uses ConvS2S BPE40k approach for Machine Translation, while Article 2 uses LSTM for Machine Translation. sent: Article 1 uses ConvS2S BPE40k approach for Machine Translation, while Article 2 uses SMT LSTM5 for Machine Translation.', 'sent: Article 1 uses ConvS2S  ensemble  approach for Machine Translation, while Article 2 uses Seq-KD   Seq-Inter   Word-KD for Machine Translation. sent: Article 1 uses ConvS2S approach for Machine Translation, while Article 2 uses Seq-KD   Seq-Inter   Word-KD for Machine Translation. sent: Article 1 uses ConvS2S BPE40k approach for Machine Translation, while Article 2 uses Seq-KD   Seq-Inter   Word-KD for Machine Translation.', 'sent: Article 1 uses ByteNet approach for Machine Translation, while Article 2 uses LSTM for Machine Translation. sent: Article 1 uses ByteNet approach for Machine Translation, while Article 2 uses SMT LSTM5 for Machine Translation.', 'sent: Article 1 uses ByteNet approach for Machine Translation, while Article 2 uses Seq-KD   Seq-Inter   Word-KD for Machine Translation.']"
12,12,ae_paper_3,ae_paper_4,53,54,"sent: Article 1 uses datasets sourced from SciDTB corpus from the ACL Anthology, while Article 2 uses SciArg corpus sourced from ACL Anthology and MEDLINE/PubMed. sent: Article 1 uses scientific datasets from Computational Linguistics domain, while Article 2 uses scientific datasets from Computational Linguistics and Biomedical domain. Article 1 uses a subset of the SciDTB corpus of 60 abstracts, while Article 2 uses 510 scientific abstracts (225 from Computation Linguistics and 285 from Biomedicine).","sent: Article 1 proposes a fine-grained annotation schema for argument mining, while Article 2 uses a refined annotation schema on sentence level for argument mining. sent: Article 1 and Article 2 use supervised learining approaches for identifying argumentative units, types, functions and attachments. sent: Article 1 uses two transfere learning approaches (multi-task learning and sequential learning) to improve the perfomance of argument mining model trained on small corpus, while Article 2 uses fine-tune and evaluate BERT-based argument mining models (in single and muti-task settings). sent: Article 1:  uses DEmb, ELMo, and RSTEnc embeddings, while Article 2 uses BERT representations.","[['1603.06147', '1409.3215'], ['1603.06147', '1705.03122'], ['1603.06147', '1610.10099'], ['1409.3215', '1606.07947'], ['1409.3215', '1610.10099'], ['1409.3215', '1511.06732'], ['1409.3215', '1603.06147'], ['1409.3215', '1711.01068'], ['1606.07947', '1705.03122'], ['1606.07947', '1610.10099'], ['1606.07947', '1409.3215'], ['1705.03122', '1610.10099'], ['1705.03122', '1511.06732'], ['1705.03122', '1603.06147'], ['1705.03122', '1606.07947'], ['1705.03122', '1711.01068'], ['1610.10099', '1705.03122'], ['1610.10099', '1409.3215'], ['1610.10099', '1511.06732'], ['1610.10099', '1603.06147'], ['1610.10099', '1606.07947'], ['1610.10099', '1711.01068'], ['1511.06732', '1705.03122'], ['1511.06732', '1610.10099'], ['1711.01068', '1610.10099'], ['1711.01068', '1705.03122']]","['sent: Article 1 uses WMT2015 English-German dataset, while Article 2 uses WMT2014 English-French dataset.', 'sent: Article 1 uses WMT2015 English-German dataset, while Article 2 uses multiple datasets:  WMT2014 English-German,  IWSLT2015 German-English,  IWSLT2015 English-German,  WMT2014 English-French, and  WMT2016 English-Romanian.', 'sent: Article 1 and Article 2 use WMT2015 English-German dataset. sent: Article 1 does not use specific datasets for experiments, while Article 2 uses multiple datasets:  WMT2014 English-German, and  WMT2014 English-French.', 'sent: Article 1 uses WMT2014 English-French dataset, while Article 2 uses multiple datasets:  WMT2014 English-German, and  IWSLT2015 Thai-English.', 'sent: Article 1 and Article 2 use WMT2014 English-French dataset. sent: Article 1 does not use specific datasets for experiments, while Article 2 uses multiple datasets:  WMT2014 English-German, and  WMT2015 English-German.', 'sent: Article 1 uses WMT2014 English-French dataset, while Article 2 uses IWSLT2015 German-English dataset.', 'sent: Article 1 uses WMT2014 English-French dataset, while Article 2 uses WMT2015 English-German dataset.', 'sent: Article 1 uses WMT2014 English-French dataset, while Article 2 uses IWSLT2015 German-English dataset.', 'sent: Article 1 and Article 2 use WMT2014 English-German dataset. sent: Article 1 uses IWSLT2015 Thai-English dataset, while Article 2 uses multiple datasets:  IWSLT2015 German-English,  WMT2016 English-Romanian,  WMT2014 English-French, and  IWSLT2015 English-German.', 'sent: Article 1 and Article 2 use WMT2014 English-German dataset. sent: Article 1 uses IWSLT2015 Thai-English dataset, while Article 2 uses multiple datasets:  WMT2014 English-French, and  WMT2015 English-German.', 'sent: Article 1 uses multiple datasets:  WMT2014 English-German, and  IWSLT2015 Thai-English, while Article 2 uses WMT2014 English-French dataset.', 'sent: Article 1 and Article 2 use WMT2014 English-German dataset.sent: Article 1 and Article 2 use WMT2014 English-French dataset. sent: Article 1 uses multiple datasets:  IWSLT2015 German-English,  WMT2016 English-Romanian, and  IWSLT2015 English-German, while Article 2 uses WMT2015 English-German dataset.', 'sent: Article 1 and Article 2 use IWSLT2015 German-English dataset. sent: Article 1 uses multiple datasets:  WMT2014 English-German,  WMT2016 English-Romanian,  WMT2014 English-French, and  IWSLT2015 English-German, while Article 2 does not use specific datasets for experiments.', 'sent: Article 1 uses multiple datasets:  WMT2014 English-German,  IWSLT2015 German-English,  IWSLT2015 English-German,  WMT2014 English-French, and  WMT2016 English-Romanian, while Article 2 uses WMT2015 English-German dataset.', 'sent: Article 1 and Article 2 use WMT2014 English-German dataset. sent: Article 1 uses multiple datasets:  IWSLT2015 German-English,  WMT2016 English-Romanian,  WMT2014 English-French, and  IWSLT2015 English-German, while Article 2 uses IWSLT2015 Thai-English dataset.', 'sent: Article 1 and Article 2 use IWSLT2015 German-English dataset. sent: Article 1 uses multiple datasets:  WMT2014 English-German,  WMT2016 English-Romanian,  WMT2014 English-French, and  IWSLT2015 English-German, while Article 2 does not use specific datasets for experiments.', 'sent: Article 1 and Article 2 use WMT2014 English-German dataset.sent: Article 1 and Article 2 use WMT2014 English-French dataset. sent: Article 1 uses WMT2015 English-German dataset, while Article 2 uses multiple datasets:  IWSLT2015 German-English,  WMT2016 English-Romanian, and  IWSLT2015 English-German.', 'sent: Article 1 and Article 2 use WMT2014 English-French dataset. sent: Article 1 uses multiple datasets:  WMT2014 English-German, and  WMT2015 English-German, while Article 2 does not use specific datasets for experiments.', 'sent: Article 1 uses multiple datasets:  WMT2014 English-German,  WMT2014 English-French, and  WMT2015 English-German, while Article 2 uses IWSLT2015 German-English dataset.', 'sent: Article 1 and Article 2 use WMT2015 English-German dataset. sent: Article 1 uses multiple datasets:  WMT2014 English-German, and  WMT2014 English-French, while Article 2 does not use specific datasets for experiments.', 'sent: Article 1 and Article 2 use WMT2014 English-German dataset. sent: Article 1 uses multiple datasets:  WMT2014 English-French, and  WMT2015 English-German, while Article 2 uses IWSLT2015 Thai-English dataset.', 'sent: Article 1 uses multiple datasets:  WMT2014 English-German,  WMT2014 English-French, and  WMT2015 English-German, while Article 2 uses IWSLT2015 German-English dataset.', 'sent: Article 1 and Article 2 use IWSLT2015 German-English dataset. sent: Article 1 does not use specific datasets for experiments, while Article 2 uses multiple datasets:  WMT2014 English-German,  WMT2016 English-Romanian,  WMT2014 English-French, and  IWSLT2015 English-German.', 'sent: Article 1 uses IWSLT2015 German-English dataset, while Article 2 uses multiple datasets:  WMT2014 English-German,  WMT2014 English-French, and  WMT2015 English-German.', 'sent: Article 1 uses IWSLT2015 German-English dataset, while Article 2 uses multiple datasets:  WMT2014 English-German,  WMT2014 English-French, and  WMT2015 English-German.', 'sent: Article 1 and Article 2 use IWSLT2015 German-English dataset. sent: Article 1 does not use specific datasets for experiments, while Article 2 uses multiple datasets:  WMT2014 English-German,  WMT2016 English-Romanian,  WMT2014 English-French, and  IWSLT2015 English-German.']","['sent: Article 1 uses Enc-Dec Att  char  approach for Machine Translation, while Article 2 uses LSTM for Machine Translation. sent: Article 1 uses Enc-Dec Att  char  approach for Machine Translation, while Article 2 uses SMT LSTM5 for Machine Translation. sent: Article 1 uses Enc-Dec Att  BPE  approach for Machine Translation, while Article 2 uses LSTM for Machine Translation. sent: Article 1 uses Enc-Dec Att  BPE  approach for Machine Translation, while Article 2 uses SMT LSTM5 for Machine Translation.', 'sent: Article 1 uses Enc-Dec Att  char  approach for Machine Translation, while Article 2 uses ConvS2S  ensemble  for Machine Translation. sent: Article 1 uses Enc-Dec Att  char  approach for Machine Translation, while Article 2 uses ConvS2S for Machine Translation. sent: Article 1 uses Enc-Dec Att  char  approach for Machine Translation, while Article 2 uses ConvS2S BPE40k for Machine Translation. sent: Article 1 uses Enc-Dec Att  BPE  approach for Machine Translation, while Article 2 uses ConvS2S  ensemble  for Machine Translation. sent: Article 1 uses Enc-Dec Att  BPE  approach for Machine Translation, while Article 2 uses ConvS2S for Machine Translation. sent: Article 1 uses Enc-Dec Att  BPE  approach for Machine Translation, while Article 2 uses ConvS2S BPE40k for Machine Translation.', 'sent: Article 1 uses Enc-Dec Att  char  approach for Machine Translation, while Article 2 uses ByteNet for Machine Translation. sent: Article 1 uses Enc-Dec Att  BPE  approach for Machine Translation, while Article 2 uses ByteNet for Machine Translation.', 'sent: Article 1 uses LSTM approach for Machine Translation, while Article 2 uses Seq-KD   Seq-Inter   Word-KD for Machine Translation. sent: Article 1 uses SMT LSTM5 approach for Machine Translation, while Article 2 uses Seq-KD   Seq-Inter   Word-KD for Machine Translation.', 'sent: Article 1 uses LSTM approach for Machine Translation, while Article 2 uses ByteNet for Machine Translation. sent: Article 1 uses SMT LSTM5 approach for Machine Translation, while Article 2 uses ByteNet for Machine Translation.', 'sent: Article 1 uses LSTM approach for Machine Translation, while Article 2 uses Word-level LSTM w attn for Machine Translation. sent: Article 1 uses SMT LSTM5 approach for Machine Translation, while Article 2 uses Word-level LSTM w attn for Machine Translation.', 'sent: Article 1 uses LSTM approach for Machine Translation, while Article 2 uses Enc-Dec Att  char  for Machine Translation. sent: Article 1 uses LSTM approach for Machine Translation, while Article 2 uses Enc-Dec Att  BPE  for Machine Translation. sent: Article 1 uses SMT LSTM5 approach for Machine Translation, while Article 2 uses Enc-Dec Att  char  for Machine Translation. sent: Article 1 uses SMT LSTM5 approach for Machine Translation, while Article 2 uses Enc-Dec Att  BPE  for Machine Translation.', 'sent: Article 1 uses LSTM approach for Machine Translation, while Article 2 uses DCCL for Machine Translation. sent: Article 1 uses SMT LSTM5 approach for Machine Translation, while Article 2 uses DCCL for Machine Translation.', 'sent: Article 1 uses Seq-KD   Seq-Inter   Word-KD approach for Machine Translation, while Article 2 uses ConvS2S  ensemble  for Machine Translation. sent: Article 1 uses Seq-KD   Seq-Inter   Word-KD approach for Machine Translation, while Article 2 uses ConvS2S for Machine Translation. sent: Article 1 uses Seq-KD   Seq-Inter   Word-KD approach for Machine Translation, while Article 2 uses ConvS2S BPE40k for Machine Translation.', 'sent: Article 1 uses Seq-KD   Seq-Inter   Word-KD approach for Machine Translation, while Article 2 uses ByteNet for Machine Translation.', 'sent: Article 1 uses Seq-KD   Seq-Inter   Word-KD approach for Machine Translation, while Article 2 uses LSTM for Machine Translation. sent: Article 1 uses Seq-KD   Seq-Inter   Word-KD approach for Machine Translation, while Article 2 uses SMT LSTM5 for Machine Translation.', 'sent: Article 1 uses ConvS2S  ensemble  approach for Machine Translation, while Article 2 uses ByteNet for Machine Translation. sent: Article 1 uses ConvS2S approach for Machine Translation, while Article 2 uses ByteNet for Machine Translation. sent: Article 1 uses ConvS2S BPE40k approach for Machine Translation, while Article 2 uses ByteNet for Machine Translation.', 'sent: Article 1 uses ConvS2S  ensemble  approach for Machine Translation, while Article 2 uses Word-level LSTM w attn for Machine Translation. sent: Article 1 uses ConvS2S approach for Machine Translation, while Article 2 uses Word-level LSTM w attn for Machine Translation. sent: Article 1 uses ConvS2S BPE40k approach for Machine Translation, while Article 2 uses Word-level LSTM w attn for Machine Translation.', 'sent: Article 1 uses ConvS2S  ensemble  approach for Machine Translation, while Article 2 uses Enc-Dec Att  char  for Machine Translation. sent: Article 1 uses ConvS2S  ensemble  approach for Machine Translation, while Article 2 uses Enc-Dec Att  BPE  for Machine Translation. sent: Article 1 uses ConvS2S approach for Machine Translation, while Article 2 uses Enc-Dec Att  char  for Machine Translation. sent: Article 1 uses ConvS2S approach for Machine Translation, while Article 2 uses Enc-Dec Att  BPE  for Machine Translation. sent: Article 1 uses ConvS2S BPE40k approach for Machine Translation, while Article 2 uses Enc-Dec Att  char  for Machine Translation. sent: Article 1 uses ConvS2S BPE40k approach for Machine Translation, while Article 2 uses Enc-Dec Att  BPE  for Machine Translation.', 'sent: Article 1 uses ConvS2S  ensemble  approach for Machine Translation, while Article 2 uses Seq-KD   Seq-Inter   Word-KD for Machine Translation. sent: Article 1 uses ConvS2S approach for Machine Translation, while Article 2 uses Seq-KD   Seq-Inter   Word-KD for Machine Translation. sent: Article 1 uses ConvS2S BPE40k approach for Machine Translation, while Article 2 uses Seq-KD   Seq-Inter   Word-KD for Machine Translation.', 'sent: Article 1 uses ConvS2S  ensemble  approach for Machine Translation, while Article 2 uses DCCL for Machine Translation. sent: Article 1 uses ConvS2S approach for Machine Translation, while Article 2 uses DCCL for Machine Translation. sent: Article 1 uses ConvS2S BPE40k approach for Machine Translation, while Article 2 uses DCCL for Machine Translation.', 'sent: Article 1 uses ByteNet approach for Machine Translation, while Article 2 uses ConvS2S  ensemble  for Machine Translation. sent: Article 1 uses ByteNet approach for Machine Translation, while Article 2 uses ConvS2S for Machine Translation. sent: Article 1 uses ByteNet approach for Machine Translation, while Article 2 uses ConvS2S BPE40k for Machine Translation.', 'sent: Article 1 uses ByteNet approach for Machine Translation, while Article 2 uses LSTM for Machine Translation. sent: Article 1 uses ByteNet approach for Machine Translation, while Article 2 uses SMT LSTM5 for Machine Translation.', 'sent: Article 1 uses ByteNet approach for Machine Translation, while Article 2 uses Word-level LSTM w attn for Machine Translation.', 'sent: Article 1 uses ByteNet approach for Machine Translation, while Article 2 uses Enc-Dec Att  char  for Machine Translation. sent: Article 1 uses ByteNet approach for Machine Translation, while Article 2 uses Enc-Dec Att  BPE  for Machine Translation.', 'sent: Article 1 uses ByteNet approach for Machine Translation, while Article 2 uses Seq-KD   Seq-Inter   Word-KD for Machine Translation.', 'sent: Article 1 uses ByteNet approach for Machine Translation, while Article 2 uses DCCL for Machine Translation.', 'sent: Article 1 uses Word-level LSTM w attn approach for Machine Translation, while Article 2 uses ConvS2S  ensemble  for Machine Translation. sent: Article 1 uses Word-level LSTM w attn approach for Machine Translation, while Article 2 uses ConvS2S for Machine Translation. sent: Article 1 uses Word-level LSTM w attn approach for Machine Translation, while Article 2 uses ConvS2S BPE40k for Machine Translation.', 'sent: Article 1 uses Word-level LSTM w attn approach for Machine Translation, while Article 2 uses ByteNet for Machine Translation.', 'sent: Article 1 uses DCCL approach for Machine Translation, while Article 2 uses ByteNet for Machine Translation.', 'sent: Article 1 uses DCCL approach for Machine Translation, while Article 2 uses ConvS2S  ensemble  for Machine Translation. sent: Article 1 uses DCCL approach for Machine Translation, while Article 2 uses ConvS2S for Machine Translation. sent: Article 1 uses DCCL approach for Machine Translation, while Article 2 uses ConvS2S BPE40k for Machine Translation.']"
